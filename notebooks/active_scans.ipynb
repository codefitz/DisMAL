{"cells":[{"cell_type":"markdown","id":"aa1ec2ee","metadata":{},"source":["# Active Scans Report (BMC Discovery)\n","\n","This notebook fetches discovery run activity from a BMC Discovery appliance using the REST API and loads the results into pandas for inspection and export."]},{"cell_type":"code","execution_count":null,"id":"f1281e01-c1f2-432d-a6e1-8613f23de2e4","metadata":{},"outputs":[],"source":["# TODO: Fix report headers"]},{"cell_type":"markdown","id":"333928ec","metadata":{},"source":["## Requirements\n","\n","We use `requests` for HTTP, `pandas` for tabular data, and `PyYAML` to read configuration. If they are not installed, uncomment the install cell below."]},{"cell_type":"code","execution_count":null,"id":"2f00d3dd","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"source":["# %pip install -q tideway pandas pyyaml\n","\n","import pandas as pd\n","import yaml\n","from pathlib import Path\n","from typing import Any, Dict, Optional\n","import xml.etree.ElementTree as ET\n","import tideway\n"]},{"cell_type":"code","execution_count":null,"id":"44b9eddc","metadata":{},"outputs":[],"source":["APPLIANCE_NAME: Optional[str] = None\n","APPLIANCE_INDEX: int = 0\n"]},{"cell_type":"markdown","id":"bde04bc0","metadata":{},"source":["## Select Appliance (optional)\n","\n","If your `config.yaml` defines multiple appliances under the `appliances:` list, set `APPLIANCE_NAME` to one of their names (recommended) or set `APPLIANCE_INDEX` to pick by position. Leave both as-is to default to the first appliance."]},{"cell_type":"code","execution_count":null,"id":"03073f9c","metadata":{},"outputs":[],"source":["from pathlib import Path\n","\n","def load_config_params(start: Path, appliance_name: Optional[str] = None, appliance_index: int = 0) -> Dict[str, Any]:\n","    def _find_repo_root(start_path: Path) -> Path:\n","        for p in [start_path] + list(start_path.parents):\n","            if (p / \"config.yaml\").exists():\n","                return p\n","        return start_path.parent\n","\n","    repo_root = _find_repo_root(start)\n","    config_path = repo_root / \"config.yaml\"\n","    with open(config_path, \"r\") as fh:\n","        cfg = yaml.safe_load(fh) or {}\n","\n","    apps = cfg.get(\"appliances\") or []\n","    selected = None\n","    if isinstance(apps, list) and apps:\n","        if appliance_name:\n","            selected = next((a for a in apps if a.get(\"name\") == appliance_name), None)\n","            if selected is None:\n","                raise ValueError(f\"No appliance named '{appliance_name}' in config.yaml\")\n","        else:\n","            try:\n","                selected = apps[int(appliance_index)]\n","            except Exception:\n","                selected = apps[0]\n","\n","    target = ((selected or {}).get(\"target\") or cfg.get(\"target\") or \"\").strip()\n","    if not target:\n","        raise ValueError('config.yaml missing \"target\"')\n","\n","    token = (((selected or {}).get(\"token\") or cfg.get(\"token\") or \"\").strip())\n","    token_file = (selected or {}).get(\"token_file\") or cfg.get(\"token_file\") or cfg.get(\"f_token\")\n","    if not token and token_file:\n","        tf_path = Path(token_file)\n","        if not tf_path.is_absolute():\n","            tf_path = repo_root / tf_path\n","        with open(tf_path, \"r\") as tf:\n","            token = tf.read().strip()\n","    if not token:\n","        raise ValueError(\"API token not found in config.yaml (token or token_file)\")\n","\n","    api_version = str((selected or {}).get(\"api_version\") or cfg.get(\"api_version\") or \"v1.14\")\n","    verify_ssl = bool((selected or {}).get(\"verify_ssl\", cfg.get(\"verify_ssl\", True)))\n","\n","    sanitized = target.replace('.', '_').replace(':', '_').replace('/', '_')\n","    output_dir = repo_root / f\"output_{sanitized}\"\n","    output_dir.mkdir(parents=True, exist_ok=True)\n","\n","    return {\n","        \"repo_root\": repo_root,\n","        \"config_path\": config_path,\n","        \"cfg\": cfg,\n","        \"selected\": selected,\n","        \"target\": target,\n","        \"token\": token,\n","        \"api_version\": api_version,\n","        \"verify_ssl\": verify_ssl,\n","        \"output_dir\": output_dir,\n","    }\n"]},{"cell_type":"code","execution_count":null,"id":"d9fa49bf","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["def init_appliance(appliance_name: Optional[str] = \"prod\") -> Dict[str, Any]:\n","    params = load_config_params(Path.cwd(), appliance_name=appliance_name)\n","    target = params[\"target\"]\n","    api_number = params[\"api_version\"].lstrip('v')\n","\n","    print('Base Host     :', target)\n","    print('API Version   :', api_number)\n","    print('Verify SSL    :', params[\"verify_ssl\"])\n","    print('Output folder :', params[\"output_dir\"])\n","\n","    app = tideway.appliance(target, params[\"token\"], api_version=api_number, ssl_verify=params[\"verify_ssl\"])\n","    twsearch = app.data()\n","\n","    try:\n","        about = app.api_about\n","        print('Appliance reachable:', getattr(about, 'status_code', 'ok'))\n","    except Exception as exc:\n","        print('Warning: failed to contact appliance /api/about:', exc)\n","\n","    return {\n","        \"params\": params,\n","        \"target\": target,\n","        \"app\": app,\n","        \"search\": twsearch,\n","        \"api_version\": api_number,\n","        \"output_dir\": params[\"output_dir\"],\n","        \"name\": (params[\"selected\"] or {}).get(\"name\") or (appliance_name or target),\n","    }\n"]},{"cell_type":"code","execution_count":null,"id":"4d32f84d","metadata":{},"outputs":[],"source":["def load_query(title: str) -> str:\n","    xml_path = Path('../queries/dismal_queries.xml')\n","    tree = ET.parse(xml_path)\n","    root = tree.getroot()\n","    for query in root.findall('query'):\n","        if query.get('title') == title:\n","            search = query.find('search')\n","            if search is not None and search.text:\n","                return search.text\n","    raise ValueError(f\"Query '{title}' not found in dismal_queries.xml\")\n","\n","qry_active_runs = load_query('Discovery Run Analysis')\n"]},{"cell_type":"code","execution_count":null,"id":"06e26905-3c44-417f-b4a1-14cc84a66680","metadata":{},"outputs":[],"source":["instances: list[Dict[str, Any]] = []\n","\n","def _attempt_init(name: Optional[str]):\n","    label = name if name else 'default'\n","    try:\n","        print(f\"Initialise {label.capitalize()}:\")\n","        inst = init_appliance(name)\n","        instances.append(inst)\n","    except Exception as exc:\n","        print(f\"Skipping {label}: {exc}\")\n","\n","_attempt_init('prod')\n","_attempt_init('dev')\n","\n","if not instances:\n","    _attempt_init(None)\n","\n","if not instances:\n","    raise RuntimeError('No appliances could be initialised from config.yaml')\n"]},{"cell_type":"code","execution_count":null,"id":"13aaaf4e","metadata":{},"outputs":[],"source":["def fetch_active_runs(instance: Dict[str, Any]) -> pd.DataFrame:\n","    search = instance['search']\n","    try:\n","        results = search.search({'query': qry_active_runs}, format='object', limit=200)\n","    except Exception as exc:\n","        print(f\"TW search failed for {instance['target']}: {exc}\")\n","        results = []\n","\n","    df = pd.DataFrame(results) if results else pd.DataFrame()\n","    df.insert(0, 'Discovery Instance', instance['target'])\n","\n","    column_map = {\n","        'Scan Label': 'Label',\n","        'End Time': 'End Time',\n","        'Explicit Ranges': 'Explicit Ranges',\n","        'Outpost Name': 'Outpost',\n","        'Scan Level': 'Scan Level',\n","        'Scan Type': 'Scan Type',\n","        'Range': 'Range Summary',\n","        'Total Endpoints': 'Total Endpoints',\n","        'Active Endpoints': 'Active Endpoints',\n","        'Dropped': 'Dropped',\n","        'Scan Kinds': 'Scan Kinds',\n","    }\n","    df = df.rename(columns=column_map)\n","\n","    return df\n","\n","\n","def convert_numeric_columns(frame: pd.DataFrame) -> pd.DataFrame:\n","    numeric_columns = ['Total Endpoints', 'Active Endpoints', 'Dropped']\n","    converted = frame.copy()\n","    for col in numeric_columns:\n","        if col in converted.columns:\n","            converted[col] = pd.to_numeric(converted[col], errors='coerce').astype('Int64')\n","    return converted\n"]},{"cell_type":"markdown","id":"e71dab36","metadata":{},"source":["## Fetch discovery runs\n","\n","Call the Discovery API endpoint that lists discovery runs. We normalize the JSON into a pandas DataFrame."]},{"cell_type":"code","execution_count":null,"id":"a9e48dbd","metadata":{},"outputs":[],"source":["runs_by_instance: list[dict[str, Any]] = []\n","for inst in instances:\n","    df_runs = fetch_active_runs(inst)\n","    runs_by_instance.append({'instance': inst, 'data': df_runs})\n","    print(inst['target'])\n","    if not df_runs.empty:\n","        display(df_runs.head(10))\n","    else:\n","        print('No runs returned.')\n"]},{"cell_type":"markdown","id":"31393ee5","metadata":{},"source":["## Inspect common fields\n","\n","Show a few relevant columns such as labels, timing and counts when present."]},{"cell_type":"code","execution_count":null,"id":"1e50d0cf","metadata":{},"outputs":[],"source":["processed_runs: list[dict[str, Any]] = []\n","for item in runs_by_instance:\n","    inst = item['instance']\n","    df_runs = convert_numeric_columns(item['data'])\n","    other_cols = [c for c in df_runs.columns if c != 'Discovery Instance']\n","    if other_cols:\n","        df_runs = df_runs[['Discovery Instance'] + other_cols]\n","    processed_runs.append({'instance': inst, 'data': df_runs})\n","\n","if processed_runs:\n","    combined_df = pd.concat([item['data'] for item in processed_runs], ignore_index=True)\n","else:\n","    combined_df = pd.DataFrame(columns=['Discovery Instance'])\n","\n","display(combined_df.head(10))\n"]},{"cell_type":"markdown","id":"0c43d4a5","metadata":{},"source":["## Save to CSV (optional)\n","\n","Persist the full dataset to the project output directory (`output_<target>`).\n","\n","This cell formats the output to match the DisMAL CLI report for Active Scans by:\n","- Inserting a 'Discovery Instance' column as the first column.\n","- Casting numeric fields (done, pre_scanning, scanning, total) to integers when present.\n","- Sorting remaining columns alphabetically to mirror json2csv header ordering."]},{"cell_type":"code","execution_count":null,"id":"9085b03e-0e3b-4326-bee1-f63b14ad3cf0","metadata":{},"outputs":[],"source":["for item in processed_runs:\n","    inst = item['instance']\n","    df_runs = item['data']\n","    output_csv = inst['output_dir'] / 'active_scans.csv'\n","    df_runs.to_csv(output_csv, index=False)\n","    print(f'Saved to {output_csv}')\n"]},{"cell_type":"markdown","id":"5702bc1b","metadata":{},"source":["---\n","### Notes\n","- If your appliance uses a self-signed certificate, set `VERIFY_SSL = False`.\n","- If the appliance exposes a different API version, update `API_VERSION`.\n","- You can further transform the dataset with `pandas.json_normalize` or additional joins if needed."]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":5}