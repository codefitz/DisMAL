{"cells":[{"cell_type":"markdown","id":"aa1ec2ee","metadata":{},"source":["# Active Scans Report (BMC Discovery)\n","\n","This notebook fetches discovery run activity from a BMC Discovery appliance using the REST API and loads the results into pandas for inspection and export."]},{"cell_type":"markdown","id":"333928ec","metadata":{},"source":["## Requirements\n","\n","We use `requests` for HTTP, `pandas` for tabular data, and `PyYAML` to read configuration. If they are not installed, uncomment the install cell below."]},{"cell_type":"code","execution_count":null,"id":"2f00d3dd","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"source":["# If needed, install dependencies\n","# %pip install -q requests pandas pyyaml\n","\n","import pandas as pd\n","import requests\n","import yaml\n","from pathlib import Path\n","from urllib.parse import urljoin\n","import json, os"]},{"cell_type":"markdown","id":"bde04bc0","metadata":{},"source":["## Select Appliance (optional)\n","\n","If your `config.yaml` defines multiple appliances under the `appliances:` list, set `APPLIANCE_NAME` to one of their names (recommended) or set `APPLIANCE_INDEX` to pick by position. Leave both as-is to default to the first appliance."]},{"cell_type":"code","execution_count":null,"id":"03073f9c","metadata":{},"outputs":[],"source":["APPLIANCE_NAME = None   # e.g., 'prod' or 'dev'\n","APPLIANCE_INDEX = 0     # integer index if not using name selection\n","#APPLIANCE_INDEX = 1"]},{"cell_type":"markdown","id":"d9fa49bf","metadata":{},"source":["## Configuration (from config.yaml)\n","\n","This cell reads settings from `config.yaml` in the project root (one level above this notebooks directory). Expected keys:\n","- `target`: hostname or base URL of the Discovery appliance (scheme optional)\n","- `token` or `token_file`: API token string or path to a file containing it (without the 'Bearer' prefix)\n","- `api_version` (optional): defaults to `v1.14` if not provided\n","- `verify_ssl` (optional): boolean, defaults to `True`\n","\n","The report CSV is saved to `output_<target>` in the project root, matching the CLI tool's layout."]},{"cell_type":"code","execution_count":null,"id":"768ab2a9","metadata":{},"outputs":[],"source":["# Locate config.yaml relative to this notebook (../config.yaml)\n","# Robustly locate the project root (directory containing config.yaml) without using Path.resolve()\n","def _find_repo_root(start: Path) -> Path:\n","    for p in [start] + list(start.parents):\n","        if (p / 'config.yaml').exists():\n","            return p\n","    # Fallback to parent of CWD (useful when running from notebooks/)\n","    return start.parent\n","\n","repo_root = _find_repo_root(Path.cwd())\n","config_path = repo_root / 'config.yaml'\n","if not config_path.exists():\n","    raise FileNotFoundError(f'config.yaml not found at {config_path}')\n","\n","with open(config_path, 'r') as fh:\n","    cfg = yaml.safe_load(fh) or {}\n","\n","# Select appliance from list if present\n","selected = None\n","apps = cfg.get('appliances') or []\n","if isinstance(apps, list) and apps:\n","    if APPLIANCE_NAME:\n","        selected = next((a for a in apps if a.get('name') == APPLIANCE_NAME), None)\n","        if selected is None:\n","            raise ValueError(f\"No appliance named '{APPLIANCE_NAME}' in config.yaml\")\n","    else:\n","        try:\n","            selected = apps[int(APPLIANCE_INDEX)]\n","        except Exception:\n","            selected = apps[0]\n","\n","# Resolve target and base URL\n","target = ((selected or {}).get('target') or cfg.get('target') or '').strip()\n","if not target:\n","    raise ValueError('config.yaml missing \"target\"')\n","BASE_URL = target if ('://' in target) else f'https://{target}'\n","\n","# Resolve token or token file\n","token = (((selected or {}).get('token') or cfg.get('token') or '').strip())\n","token_file = (selected or {}).get('token_file') or cfg.get('token_file') or cfg.get('f_token')\n","if not token and token_file:\n","    tf_path = Path(token_file)\n","    if not tf_path.is_absolute():\n","        tf_path = repo_root / tf_path\n","    with open(tf_path, 'r') as tf:\n","        token = tf.read().strip()\n","if not token:\n","    raise ValueError('API token not found in config.yaml (token or token_file)')\n","\n","API_VERSION = str((selected or {}).get('api_version') or cfg.get('api_version') or 'v1.14')\n","VERIFY_SSL = bool((selected or {}).get('verify_ssl', cfg.get('verify_ssl', True)))\n","\n","# Prepare output directory consistent with CLI naming\n","sanitized = target.replace('.', '_').replace(':', '_').replace('/', '_')\n","output_dir = repo_root / f'output_{sanitized}'\n","output_dir.mkdir(parents=True, exist_ok=True)\n","\n","print('Appliance     :', (selected or {}).get('name', '(single)'))\n","print('Base URL      :', BASE_URL)\n","print('API Version   :', API_VERSION)\n","print('Verify SSL    :', VERIFY_SSL)\n","print('Output folder :', output_dir)"]},{"cell_type":"markdown","id":"cd105928","metadata":{},"source":["## Create a session and helper functions\n","\n","Set up a `requests` session with the Authorization header. Add small helpers to build API URLs and safely parse JSON responses."]},{"cell_type":"code","execution_count":null,"id":"13aaaf4e","metadata":{},"outputs":[],"source":["session = requests.Session()\n","# Allow token with or without 'Bearer ' prefix\n","auth_value = token if token.lower().startswith('bearer ') else f'Bearer {token}'\n","session.headers.update({\n","    'Authorization': auth_value,\n","    'Accept': 'application/json'\n","})\n","session.verify = VERIFY_SSL\n","\n","def api_url(path: str) -> str:\n","    base = BASE_URL.rstrip('/') + f'/api/{API_VERSION}/'\n","    return urljoin(base, path.lstrip('/'))\n","\n","def get_json(url: str, **kwargs):\n","    resp = session.get(url, **kwargs)\n","    if resp.status_code != 200:\n","        print(f'Error {resp.status_code} fetching {url}: {resp.text[:200]}')\n","        return {}\n","    try:\n","        return resp.json()\n","    except Exception as e:\n","        print(f'Failed to decode JSON: {e}')\n","        return {}"]},{"cell_type":"markdown","id":"e71dab36","metadata":{},"source":["## Fetch discovery runs\n","\n","Call the Discovery API endpoint that lists discovery runs. We normalize the JSON into a pandas DataFrame."]},{"cell_type":"code","execution_count":null,"id":"a9e48dbd","metadata":{},"outputs":[],"source":["runs_url = api_url('discovery/runs')\n","raw = get_json(runs_url)\n","\n","# Handle either a list response or an object with a 'results' list\n","if isinstance(raw, dict) and 'results' in raw:\n","    records = raw['results']\n","elif isinstance(raw, list):\n","    records = raw\n","else:\n","    records = []\n","\n","df = pd.json_normalize(records)\n","print(f'Total runs retrieved: {len(df)}')\n","df.head()"]},{"cell_type":"markdown","id":"31393ee5","metadata":{},"source":["## Inspect common fields\n","\n","Show a few relevant columns such as labels, timing and counts when present."]},{"cell_type":"code","execution_count":null,"id":"08032323","metadata":{},"outputs":[],"source":["if not df.empty:\n","    cols = [c for c in ['label','starttime','outpost_name','done','total','finished','scan_level','scan_type'] if c in df.columns]\n","    display(df[cols].head(20) if cols else df.head(20))\n","else:\n","    print('No runs returned.')"]},{"cell_type":"markdown","id":"63158689","metadata":{},"source":["## Filter in-progress runs\n","\n","Filter the DataFrame to show only runs that are not yet finished (when the `finished` field is present)."]},{"cell_type":"code","execution_count":null,"id":"1e50d0cf","metadata":{},"outputs":[],"source":["if not df.empty and 'finished' in df.columns:\n","    in_progress = df.loc[df['finished'] == False]\n","    print(f'In-progress runs: {len(in_progress)}')\n","    display(in_progress.head(10))\n","else:\n","    print('The dataset has no \"finished\" column or is empty.')"]},{"cell_type":"markdown","id":"0c43d4a5","metadata":{},"source":["## Save to CSV (optional)\n","\n","Persist the full dataset to the project output directory (`output_<target>`).\n","\n","This cell formats the output to match the DisMAL CLI report for Active Scans by:\n","- Inserting a 'Discovery Instance' column as the first column.\n","- Casting numeric fields (done, pre_scanning, scanning, total) to integers when present.\n","- Sorting remaining columns alphabetically to mirror json2csv header ordering."]},{"cell_type":"code","execution_count":null,"id":"9085b03e-0e3b-4326-bee1-f63b14ad3cf0","metadata":{},"outputs":[],"source":["# Prepare output\n","df_out = df.copy()\n","# Cast numeric columns when present\n","for col in ['done', 'pre_scanning', 'scanning', 'total']:\n","    if col in df_out.columns:\n","        df_out[col] = pd.to_numeric(df_out[col], errors='coerce').astype('Int64')\n","\n","# Insert 'Discovery Instance' first\n","df_out.insert(0, 'Discovery Instance', target)\n","\n","# Reorder columns: 'Discovery Instance' + sorted remaining\n","other_cols = sorted([c for c in df_out.columns if c != 'Discovery Instance'])\n","df_out = df_out[['Discovery Instance'] + other_cols]\n","\n","# Check Results\n","display(df_out.head(10))"]},{"cell_type":"code","execution_count":null,"id":"7a057df2","metadata":{},"outputs":[],"source":["# Save CSV\n","OUTPUT_CSV = str(output_dir / 'active_scans.csv')\n","df_out.to_csv(OUTPUT_CSV, index=False)\n","print(f'Saved to {OUTPUT_CSV}')"]},{"cell_type":"markdown","id":"5702bc1b","metadata":{},"source":["---\n","### Notes\n","- If your appliance uses a self-signed certificate, set `VERIFY_SSL = False`.\n","- If the appliance exposes a different API version, update `API_VERSION`.\n","- You can further transform the dataset with `pandas.json_normalize` or additional joins if needed."]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":5}