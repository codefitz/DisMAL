{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa1ec2ee",
   "metadata": {},
   "source": [
    "# Active Scans Report (BMC Discovery)\n",
    "\n",
    "This notebook fetches discovery run activity from a BMC Discovery appliance using the REST API and loads the results into pandas for inspection and export."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333928ec",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "We use `requests` for HTTP, `pandas` for tabular data, and `PyYAML` to read configuration. If they are not installed, uncomment the install cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f00d3dd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# %pip install -q requests pandas pyyaml\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b9eddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "APPLIANCE_NAME: Optional[str] = None\n",
    "APPLIANCE_INDEX: int = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde04bc0",
   "metadata": {},
   "source": [
    "## Select Appliance (optional)\n",
    "\n",
    "If your `config.yaml` defines multiple appliances under the `appliances:` list, set `APPLIANCE_NAME` to one of their names (recommended) or set `APPLIANCE_INDEX` to pick by position. Leave both as-is to default to the first appliance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03073f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def load_config_params(start: Path, appliance_name: Optional[str] = None, appliance_index: int = 0) -> Dict[str, Any]:\n",
    "    def _find_repo_root(start_path: Path) -> Path:\n",
    "        for p in [start_path] + list(start_path.parents):\n",
    "            if (p / \"config.yaml\").exists():\n",
    "                return p\n",
    "        return start_path.parent\n",
    "\n",
    "    repo_root = _find_repo_root(start)\n",
    "    config_path = repo_root / \"config.yaml\"\n",
    "    with open(config_path, \"r\") as fh:\n",
    "        cfg = yaml.safe_load(fh) or {}\n",
    "\n",
    "    apps = cfg.get(\"appliances\") or []\n",
    "    selected = None\n",
    "    if isinstance(apps, list) and apps:\n",
    "        if appliance_name:\n",
    "            selected = next((a for a in apps if a.get(\"name\") == appliance_name), None)\n",
    "            if selected is None:\n",
    "                raise ValueError(f\"No appliance named '{appliance_name}' in config.yaml\")\n",
    "        else:\n",
    "            try:\n",
    "                selected = apps[int(appliance_index)]\n",
    "            except Exception:\n",
    "                selected = apps[0]\n",
    "\n",
    "    target = ((selected or {}).get(\"target\") or cfg.get(\"target\") or \"\").strip()\n",
    "    if not target:\n",
    "        raise ValueError('config.yaml missing \"target\"')\n",
    "\n",
    "    token = (((selected or {}).get(\"token\") or cfg.get(\"token\") or \"\").strip())\n",
    "    token_file = (selected or {}).get(\"token_file\") or cfg.get(\"token_file\") or cfg.get(\"f_token\")\n",
    "    if not token and token_file:\n",
    "        tf_path = Path(token_file)\n",
    "        if not tf_path.is_absolute():\n",
    "            tf_path = repo_root / tf_path\n",
    "        with open(tf_path, \"r\") as tf:\n",
    "            token = tf.read().strip()\n",
    "    if not token:\n",
    "        raise ValueError(\"API token not found in config.yaml (token or token_file)\")\n",
    "\n",
    "    api_version = str((selected or {}).get(\"api_version\") or cfg.get(\"api_version\") or \"v1.14\")\n",
    "    verify_ssl = bool((selected or {}).get(\"verify_ssl\", cfg.get(\"verify_ssl\", True)))\n",
    "\n",
    "    sanitized = target.replace('.', '_').replace(':', '_').replace('/', '_')\n",
    "    output_dir = repo_root / f\"output_{sanitized}\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return {\n",
    "        \"repo_root\": repo_root,\n",
    "        \"config_path\": config_path,\n",
    "        \"cfg\": cfg,\n",
    "        \"selected\": selected,\n",
    "        \"target\": target,\n",
    "        \"token\": token,\n",
    "        \"api_version\": api_version,\n",
    "        \"verify_ssl\": verify_ssl,\n",
    "        \"output_dir\": output_dir,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fa49bf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def init_appliance(appliance_name: Optional[str] = \"prod\") -> Dict[str, Any]:\n",
    "    params = load_config_params(Path.cwd(), appliance_name=appliance_name)\n",
    "    target = params[\"target\"]\n",
    "    base_url = target if (\"://\" in target) else f\"https://{target}\"\n",
    "    api_version = params[\"api_version\"]\n",
    "    if not api_version.startswith('v'):\n",
    "        api_version = f\"v{api_version}\"\n",
    "\n",
    "    session = requests.Session()\n",
    "    token = params[\"token\"]\n",
    "    auth_value = token if token.lower().startswith('bearer ') else f\"Bearer {token}\"\n",
    "    session.headers.update({\n",
    "        \"Authorization\": auth_value,\n",
    "        \"Accept\": \"application/json\",\n",
    "    })\n",
    "    session.verify = params[\"verify_ssl\"]\n",
    "\n",
    "    api_base = base_url.rstrip('/') + f\"/api/{api_version}/\"\n",
    "\n",
    "    print('Base Host     :', target)\n",
    "    print('API Version   :', api_version)\n",
    "    print('Verify SSL    :', params[\"verify_ssl\"])\n",
    "    print('Output folder :', params[\"output_dir\"])\n",
    "\n",
    "    return {\n",
    "        \"params\": params,\n",
    "        \"target\": target,\n",
    "        \"session\": session,\n",
    "        \"api_base\": api_base,\n",
    "        \"api_version\": api_version,\n",
    "        \"output_dir\": params[\"output_dir\"],\n",
    "        \"name\": (params[\"selected\"] or {}).get(\"name\") or (appliance_name or target),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768ab2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate config.yaml relative to this notebook (../config.yaml)\n",
    "# Robustly locate the project root (directory containing config.yaml) without using Path.resolve()\n",
    "def _find_repo_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / 'config.yaml').exists():\n",
    "            return p\n",
    "    # Fallback to parent of CWD (useful when running from notebooks/)\n",
    "    return start.parent\n",
    "\n",
    "repo_root = _find_repo_root(Path.cwd())\n",
    "config_path = repo_root / 'config.yaml'\n",
    "if not config_path.exists():\n",
    "    raise FileNotFoundError(f'config.yaml not found at {config_path}')\n",
    "\n",
    "with open(config_path, 'r') as fh:\n",
    "    cfg = yaml.safe_load(fh) or {}\n",
    "\n",
    "# Select appliance from list if present\n",
    "selected = None\n",
    "apps = cfg.get('appliances') or []\n",
    "if isinstance(apps, list) and apps:\n",
    "    if APPLIANCE_NAME:\n",
    "        selected = next((a for a in apps if a.get('name') == APPLIANCE_NAME), None)\n",
    "        if selected is None:\n",
    "            raise ValueError(f\"No appliance named '{APPLIANCE_NAME}' in config.yaml\")\n",
    "    else:\n",
    "        try:\n",
    "            selected = apps[int(APPLIANCE_INDEX)]\n",
    "        except Exception:\n",
    "            selected = apps[0]\n",
    "\n",
    "# Resolve target and base URL\n",
    "target = ((selected or {}).get('target') or cfg.get('target') or '').strip()\n",
    "if not target:\n",
    "    raise ValueError('config.yaml missing \"target\"')\n",
    "BASE_URL = target if ('://' in target) else f'https://{target}'\n",
    "\n",
    "# Resolve token or token file\n",
    "token = (((selected or {}).get('token') or cfg.get('token') or '').strip())\n",
    "token_file = (selected or {}).get('token_file') or cfg.get('token_file') or cfg.get('f_token')\n",
    "if not token and token_file:\n",
    "    tf_path = Path(token_file)\n",
    "    if not tf_path.is_absolute():\n",
    "        tf_path = repo_root / tf_path\n",
    "    with open(tf_path, 'r') as tf:\n",
    "        token = tf.read().strip()\n",
    "if not token:\n",
    "    raise ValueError('API token not found in config.yaml (token or token_file)')\n",
    "\n",
    "API_VERSION = str((selected or {}).get('api_version') or cfg.get('api_version') or 'v1.14')\n",
    "VERIFY_SSL = bool((selected or {}).get('verify_ssl', cfg.get('verify_ssl', True)))\n",
    "\n",
    "# Prepare output directory consistent with CLI naming\n",
    "sanitized = target.replace('.', '_').replace(':', '_').replace('/', '_')\n",
    "output_dir = repo_root / f'output_{sanitized}'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Appliance     :', (selected or {}).get('name', '(single)'))\n",
    "print('Base URL      :', BASE_URL)\n",
    "print('API Version   :', API_VERSION)\n",
    "print('Verify SSL    :', VERIFY_SSL)\n",
    "print('Output folder :', output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e26905-3c44-417f-b4a1-14cc84a66680",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances: list[Dict[str, Any]] = []\n",
    "\n",
    "def _attempt_init(name: Optional[str]):\n",
    "    label = name if name else 'default'\n",
    "    try:\n",
    "        print(f\"Initialise {label.capitalize()}:\")\n",
    "        inst = init_appliance(name)\n",
    "        instances.append(inst)\n",
    "    except Exception as exc:\n",
    "        print(f\"Skipping {label}: {exc}\")\n",
    "\n",
    "_attempt_init('prod')\n",
    "_attempt_init('dev')\n",
    "\n",
    "if not instances:\n",
    "    _attempt_init(None)\n",
    "\n",
    "if not instances:\n",
    "    raise RuntimeError('No appliances could be initialised from config.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aaaf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_active_runs(instance: Dict[str, Any]) -> pd.DataFrame:\n",
    "    url = instance['api_base'] + 'discovery/runs'\n",
    "    try:\n",
    "        resp = instance['session'].get(url, timeout=30)\n",
    "    except Exception as exc:\n",
    "        print(f\"Request to {url} failed: {exc}\")\n",
    "        df_empty = pd.DataFrame()\n",
    "        df_empty.insert(0, 'Discovery Instance', instance['target'])\n",
    "        return df_empty\n",
    "    if resp.status_code != 200:\n",
    "        print(f\"Error {resp.status_code} fetching {url}: {resp.text[:200]}\")\n",
    "        df_empty = pd.DataFrame()\n",
    "        df_empty.insert(0, 'Discovery Instance', instance['target'])\n",
    "        return df_empty\n",
    "    try:\n",
    "        payload = resp.json()\n",
    "    except Exception as exc:\n",
    "        print(f\"Failed to decode JSON for {instance['target']}: {exc}\")\n",
    "        payload = []\n",
    "\n",
    "    if isinstance(payload, dict) and 'results' in payload:\n",
    "        records = payload['results']\n",
    "    elif isinstance(payload, list):\n",
    "        records = payload\n",
    "    else:\n",
    "        records = []\n",
    "\n",
    "    df = pd.json_normalize(records) if records else pd.DataFrame()\n",
    "    df.insert(0, 'Discovery Instance', instance['target'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_numeric_columns(frame: pd.DataFrame) -> pd.DataFrame:\n",
    "    numeric_columns = ['done', 'pre_scanning', 'scanning', 'total']\n",
    "    converted = frame.copy()\n",
    "    for col in numeric_columns:\n",
    "        if col in converted.columns:\n",
    "            converted[col] = pd.to_numeric(converted[col], errors='coerce').astype('Int64')\n",
    "    return converted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71dab36",
   "metadata": {},
   "source": [
    "## Fetch discovery runs\n",
    "\n",
    "Call the Discovery API endpoint that lists discovery runs. We normalize the JSON into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e48dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_by_instance: list[dict[str, Any]] = []\n",
    "for inst in instances:\n",
    "    df_runs = fetch_active_runs(inst)\n",
    "    runs_by_instance.append({'instance': inst, 'data': df_runs})\n",
    "    print(inst['target'])\n",
    "    if not df_runs.empty:\n",
    "        display(df_runs.head(10))\n",
    "    else:\n",
    "        print('No runs returned.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31393ee5",
   "metadata": {},
   "source": [
    "## Inspect common fields\n",
    "\n",
    "Show a few relevant columns such as labels, timing and counts when present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08032323",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in runs_by_instance:\n",
    "    inst = item['instance']\n",
    "    df_runs = item['data']\n",
    "    if df_runs.empty:\n",
    "        print(f\"No runs for {inst['target']}\")\n",
    "        continue\n",
    "    if 'finished' in df_runs.columns:\n",
    "        in_progress = df_runs[df_runs['finished'] == False]\n",
    "        print(f\"In-progress runs for {inst['target']}: {len(in_progress)}\")\n",
    "        if not in_progress.empty:\n",
    "            display(in_progress.head(10))\n",
    "    else:\n",
    "        print(f\"{inst['target']} dataset has no 'finished' column.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63158689",
   "metadata": {},
   "source": [
    "## Filter in-progress runs\n",
    "\n",
    "Filter the DataFrame to show only runs that are not yet finished (when the `finished` field is present)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e50d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_runs: list[dict[str, Any]] = []\n",
    "for item in runs_by_instance:\n",
    "    inst = item['instance']\n",
    "    df_runs = convert_numeric_columns(item['data'])\n",
    "    other_cols = [c for c in df_runs.columns if c != 'Discovery Instance']\n",
    "    if other_cols:\n",
    "        df_runs = df_runs[['Discovery Instance'] + other_cols]\n",
    "    processed_runs.append({'instance': inst, 'data': df_runs})\n",
    "\n",
    "if processed_runs:\n",
    "    combined_df = pd.concat([item['data'] for item in processed_runs], ignore_index=True)\n",
    "else:\n",
    "    combined_df = pd.DataFrame(columns=['Discovery Instance'])\n",
    "\n",
    "display(combined_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c43d4a5",
   "metadata": {},
   "source": [
    "## Save to CSV (optional)\n",
    "\n",
    "Persist the full dataset to the project output directory (`output_<target>`).\n",
    "\n",
    "This cell formats the output to match the DisMAL CLI report for Active Scans by:\n",
    "- Inserting a 'Discovery Instance' column as the first column.\n",
    "- Casting numeric fields (done, pre_scanning, scanning, total) to integers when present.\n",
    "- Sorting remaining columns alphabetically to mirror json2csv header ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9085b03e-0e3b-4326-bee1-f63b14ad3cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in processed_runs:\n",
    "    inst = item['instance']\n",
    "    df_runs = item['data']\n",
    "    output_csv = inst['output_dir'] / 'active_scans.csv'\n",
    "    df_runs.to_csv(output_csv, index=False)\n",
    "    print(f'Saved to {output_csv}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5702bc1b",
   "metadata": {},
   "source": [
    "---\n",
    "### Notes\n",
    "- If your appliance uses a self-signed certificate, set `VERIFY_SSL = False`.\n",
    "- If the appliance exposes a different API version, update `API_VERSION`.\n",
    "- You can further transform the dataset with `pandas.json_normalize` or additional joins if needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
