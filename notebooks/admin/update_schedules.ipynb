{"cells":[{"cell_type":"markdown","id":"ee50644c","metadata":{},"source":["# Update Scheduled Scans\n","\n","This notebook finds discovery runs whose schedule is \"Every day, starting at HH:00 every 8 hours until complete\" and updates them to every 12 hours, preserving the original start hour (e.g., 01:00 â†’ [01:00, 13:00]).\n","\n","- Preview the proposed changes first.\n","- Toggle `APPLY_CHANGES = True` to patch schedules on the appliance.\n","- Schedules not matching the exact 8-hour cadence are left unchanged."]},{"cell_type":"markdown","id":"acf41b8f","metadata":{},"source":["## Requirements\n","Uses `requests`, `pandas`, and `PyYAML`. If needed, uncomment below to install."]},{"cell_type":"code","execution_count":null,"id":"85c5ae1c","metadata":{},"outputs":[],"source":["# %pip install -q requests pandas pyyaml\n","import pandas as pd\n","import requests\n","import yaml\n","from pathlib import Path\n","from urllib.parse import urljoin\n","import json, os"]},{"cell_type":"markdown","id":"8a2754e8","metadata":{},"source":["## Select Appliance and Apply Toggle\n","Set one of `APPLIANCE_NAME` or `APPLIANCE_INDEX` if you have multiple entries in `config.yaml`. Leave as-is to use the first appliance.\n","\n","Set `APPLY_CHANGES = True` to perform the updates. When `False`, the notebook previews the changes only."]},{"cell_type":"code","execution_count":null,"id":"5cd6a743","metadata":{},"outputs":[],"source":["APPLIANCE_NAME = None   # e.g., 'prod' or 'dev'\n","APPLIANCE_INDEX = 0     # integer index if not using name selection\n","#APPLIANCE_INDEX = 1\n","APPLY_CHANGES  = True  # toggle to True to PATCH schedules"]},{"cell_type":"markdown","id":"7a17b1af","metadata":{},"source":["## Load configuration (from ../config.yaml)\n","This mirrors the other DisMAL notebooks: it resolves `target`, `token` or `token_file`, optional `api_version` and `verify_ssl`, and prepares an output folder (`output_<target>`)."]},{"cell_type":"code","execution_count":null,"id":"c11c65a7","metadata":{},"outputs":[],"source":["def _find_repo_root(start: Path) -> Path:\n","    for p in [start] + list(start.parents):\n","        if (p / 'config.yaml').exists():\n","            return p\n","    return start.parent\n","\n","repo_root = _find_repo_root(Path.cwd())\n","config_path = repo_root / 'config.yaml'\n","if not config_path.exists():\n","    raise FileNotFoundError(f'config.yaml not found at {config_path}')\n","\n","with open(config_path, 'r') as fh:\n","    cfg = yaml.safe_load(fh) or {}\n","\n","# Select appliance from list if present\n","selected = None\n","apps = cfg.get('appliances') or []\n","if isinstance(apps, list) and apps:\n","    if APPLIANCE_NAME:\n","        selected = next((a for a in apps if a.get('name') == APPLIANCE_NAME), None)\n","        if selected is None:\n","            raise ValueError(f\"No appliance named '{APPLIANCE_NAME}' in config.yaml\")\n","    else:\n","        try:\n","            selected = apps[int(APPLIANCE_INDEX)]\n","        except Exception:\n","            selected = apps[0]\n","\n","# Resolve target and base URL\n","target = ((selected or {}).get('target') or cfg.get('target') or '').strip()\n","if not target:\n","    raise ValueError('config.yaml missing \"target\"')\n","BASE_URL = target if ('://' in target) else f'https://{target}'\n","\n","# Resolve token or token file\n","token = (((selected or {}).get('token') or cfg.get('token') or '').strip())\n","token_file = (selected or {}).get('token_file') or cfg.get('token_file') or cfg.get('f_token')\n","if not token and token_file:\n","    tf_path = Path(token_file)\n","    if not tf_path.is_absolute():\n","        tf_path = repo_root / tf_path\n","    with open(tf_path, 'r') as tf:\n","        token = tf.read().strip()\n","if not token:\n","    raise ValueError('API token not found in config.yaml (token or token_file)')\n","\n","API_VERSION = str((selected or {}).get('api_version') or cfg.get('api_version') or 'v1.14')\n","VERIFY_SSL = bool((selected or {}).get('verify_ssl', cfg.get('verify_ssl', True)))\n","\n","# Prepare output directory consistent with CLI naming\n","sanitized = target.replace('.', '_').replace(':', '_').replace('/', '_')\n","output_dir = repo_root / f'output_{sanitized}'\n","output_dir.mkdir(parents=True, exist_ok=True)\n","\n","print('Appliance     :', (selected or {}).get('name', '(single)'))\n","print('Base URL      :', BASE_URL)\n","print('API Version   :', API_VERSION)\n","print('Verify SSL    :', VERIFY_SSL)\n","print('Output folder :', output_dir)"]},{"cell_type":"markdown","id":"60fb432f","metadata":{},"source":["## Session and helpers\n","Build API URLs, fetch JSON, and PATCH JSON with Authorization header."]},{"cell_type":"code","execution_count":null,"id":"cf1e947f","metadata":{},"outputs":[],"source":["session = requests.Session()\n","auth_value = token if token.lower().startswith('bearer ') else f'Bearer {token}'\n","session.headers.update({\n","    'Authorization': auth_value,\n","    'Accept': 'application/json',\n","    'Content-Type': 'application/json'\n","})\n","session.verify = VERIFY_SSL\n","\n","def api_url(path: str) -> str:\n","    base = BASE_URL.rstrip('/') + f'/api/{API_VERSION}/'\n","    return urljoin(base, path.lstrip('/'))\n","\n","def get_json(url: str, **kwargs):\n","    resp = session.get(url, **kwargs)\n","    if resp.status_code != 200:\n","        print(f'Error {resp.status_code} GET {url}: {resp.text[:200]}')\n","        return {}\n","    try:\n","        return resp.json()\n","    except Exception as e:\n","        print(f'Failed to decode JSON: {e}')\n","        return {}\n","\n","def patch_json(url: str, payload: dict):\n","    resp = session.patch(url, data=json.dumps(payload))\n","    ok = 200 <= resp.status_code < 300\n","    if not ok:\n","        print(f'Error {resp.status_code} PATCH {url}: {resp.text[:300]}')\n","        return ok, None\n","    try:\n","        return ok, (resp.json() if resp.text else None)\n","    except Exception:\n","        return ok, None"]},{"cell_type":"markdown","id":"41687990","metadata":{},"source":["## Find 8-hour daily schedules and compute new times\n","We detect the cadence from `schedule.start_times`: three times equally spaced by 8 hours. The update keeps the first hour and switches to 12-hour cadence (two times per day)."]},{"cell_type":"code","execution_count":null,"id":"9e071e9c","metadata":{},"outputs":[],"source":["from typing import List, Optional\n","\n","def normalize_times(times) -> List[int]:\n","    try:\n","        ints = sorted({int(t) % 24 for t in times if t is not None})\n","        return [t for t in ints if 0 <= t <= 23]\n","    except Exception:\n","        return []\n","\n","def is_every_8_hours(times: List[int]) -> bool:\n","    t = normalize_times(times)\n","    if len(t) != 3:\n","        return False\n","    # Check circular diffs sum to 24 with each gap == 8\n","    diffs = [(t[(i+1)%3] - t[i]) % 24 for i in range(3)]\n","    return all(d == 8 for d in diffs)\n","\n","def to_every_12_hours(times: List[int]) -> Optional[List[int]]:\n","    t = normalize_times(times)\n","    if not t:\n","        return None\n","    start = t[0]  # preserve earliest hour as the 'starting at'\n","    return [start, (start + 12) % 24]\n","\n","# Fetch discovery runs\n","raw = get_json(api_url('discovery/runs/scheduled'))\n","records = (raw.get('results') if isinstance(raw, dict) else raw) or []\n","\n","proposals = []\n","for r in records:\n","    schedule = (r.get('schedule') or {}) if isinstance(r, dict) else {}\n","    times = schedule.get('start_times') or []\n","    if not isinstance(times, (list, tuple)):\n","        continue\n","    if is_every_8_hours(times):\n","        rid = r.get('range_id') or r.get('id') or r.get('run_id')\n","        label = r.get('label') or r.get('name') or str(rid)\n","        new_times = to_every_12_hours(times)\n","        proposals.append({\n","            'run_id': rid,\n","            'label': label,\n","            'old_times': normalize_times(times),\n","            'new_times': new_times,\n","        })\n","\n","df_changes = pd.DataFrame(proposals)\n","print(f'Total discovery runs: {len(records)}')\n","print(f'Candidates with 8-hour cadence: {len(df_changes)}')\n","df_changes.head(20)"]},{"cell_type":"markdown","id":"d21e2d76","metadata":{},"source":["## Apply changes (toggle above)\n","When `APPLY_CHANGES` is True, each candidate run is patched with `{'schedule': {'start_times': [H, H+12]}}`.\n","A CSV backup of proposed changes is saved under the standard output directory."]},{"cell_type":"code","execution_count":null,"id":"cf50126a","metadata":{},"outputs":[],"source":["updated, failed = 0, []\n","if not df_changes.empty:\n","    # Save preview/backup CSV\n","    out_csv = output_dir / 'schedule_updates_8_to_12.csv'\n","    df_out = df_changes.copy()\n","    df_out.insert(0, 'Discovery Instance', target)\n","    df_out.to_csv(out_csv, index=False)\n","    print(f'Preview saved to {out_csv}')\n","\n","if APPLY_CHANGES and not df_changes.empty:\n","    for _, row in df_changes.iterrows():\n","        rid = row['run_id']\n","        new_times = row['new_times']\n","        if not rid or not new_times:\n","            continue\n","        url = api_url(f'/discovery/runs/scheduled/{rid}')\n","        payload = {'schedule': {'start_times': new_times}}\n","        ok, _ = patch_json(url, payload)\n","        if ok:\n","            updated += 1\n","        else:\n","            failed.append(rid)\n","    print(f'Updated: {updated} succeeded, {len(failed)} failed')\n","    if failed:\n","        print('Failed run IDs:', failed)\n","else:\n","    if df_changes.empty:\n","        print('No 8-hour schedules found; nothing to update.')\n","    else:\n","        print('APPLY_CHANGES is False; no updates performed.')"]},{"cell_type":"code","execution_count":null,"id":"627b0d08-0e60-45c4-984d-087c43b8d7d3","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":5}