{"cells":[{"cell_type":"markdown","id":"4f4c9dca","metadata":{},"source":["# Credential Success Report (BMC Discovery)\n","\n","This notebook reproduces the DisMAL `credential_success` report using the REST API.\n","It reads connection details from `config.yaml`, executes Discovery queries,\n","and assembles a CSV matching the CLI’s headers and formatting.\n","\n","> **NOTE:** This can take a little while to run if you have lots of DiscoveryAccesses"]},{"cell_type":"markdown","id":"82bcd7ef","metadata":{},"source":["## Requirements\n","\n","We use `requests` for HTTP, `pandas` for tabular data, and `PyYAML` to read configuration.\n","Uncomment the following to install them in your environment."]},{"cell_type":"code","execution_count":null,"id":"61b133c8","metadata":{},"outputs":[],"source":["# %pip install -q requests pandas pyyaml\n","\n","import pandas as pd\n","import requests\n","import yaml\n","from pathlib import Path\n","from urllib.parse import urljoin\n","import ipaddress\n","import json, os\n","import math"]},{"cell_type":"markdown","id":"94eb3387","metadata":{},"source":["## Select Appliance (optional)\n","\n","If your `config.yaml` defines multiple appliances under the `appliances:` list,\n","set `APPLIANCE_NAME` to one of their names (e.g., 'prod' or 'dev') or use the index.\n","Defaults to the first appliance if neither is set."]},{"cell_type":"code","execution_count":null,"id":"f71970ae","metadata":{},"outputs":[],"source":["APPLIANCE_NAME = None   # e.g., 'prod' or 'dev'\n","APPLIANCE_INDEX = 0     # integer index if not using name selection"]},{"cell_type":"markdown","id":"43fff079","metadata":{},"source":["## Configuration (from config.yaml)\n","\n","Reads settings from `../config.yaml` including target, token/token_file,\n","API version, and SSL verification preference.\n","Saves the CSV to `../output_<target>/credential_success.csv`."]},{"cell_type":"code","execution_count":null,"id":"98a071bd","metadata":{},"outputs":[],"source":["# Locate config.yaml relative to this notebook (../config.yaml)\n","def _find_repo_root(start: Path) -> Path:\n","    for p in [start] + list(start.parents):\n","        if (p / 'config.yaml').exists():\n","            return p\n","    return start.parent\n","\n","repo_root = _find_repo_root(Path.cwd())\n","config_path = repo_root / 'config.yaml'\n","with open(config_path, 'r') as fh:\n","    cfg = yaml.safe_load(fh) or {}\n","\n","# Appliance selection\n","apps = cfg.get('appliances') or []\n","selected = None\n","if isinstance(apps, list) and apps:\n","    if APPLIANCE_NAME:\n","        selected = next((a for a in apps if a.get('name') == APPLIANCE_NAME), None)\n","        if selected is None:\n","            raise ValueError(f\"No appliance named '{APPLIANCE_NAME}' in config.yaml\")\n","    else:\n","        try:\n","            selected = apps[int(APPLIANCE_INDEX)]\n","        except Exception:\n","            selected = apps[0]\n","\n","target = ((selected or {}).get('target') or cfg.get('target') or '').strip()\n","if not target:\n","    raise ValueError('config.yaml missing \"target\"')\n","BASE_URL = target if ('://' in target) else f'https://{target}'\n","\n","token = (((selected or {}).get('token') or cfg.get('token') or '').strip())\n","token_file = (selected or {}).get('token_file') or cfg.get('token_file') or cfg.get('f_token')\n","if not token and token_file:\n","    tf_path = Path(token_file)\n","    if not tf_path.is_absolute():\n","        tf_path = repo_root / tf_path\n","    with open(tf_path, 'r') as tf:\n","        token = tf.read().strip()\n","if not token:\n","    raise ValueError('API token not found in config.yaml (token or token_file)')\n","\n","API_VERSION = str((selected or {}).get('api_version') or cfg.get('api_version') or 'v1.14')\n","VERIFY_SSL = bool((selected or {}).get('verify_ssl', cfg.get('verify_ssl', True)))\n","\n","sanitized = target.replace('.', '_').replace(':', '_').replace('/', '_')\n","output_dir = repo_root / f'output_{sanitized}'\n","output_dir.mkdir(parents=True, exist_ok=True)\n","\n","print('Appliance     :', (selected or {}).get('name', '(single)'))\n","print('Base URL      :', BASE_URL)\n","print('API Version   :', API_VERSION)\n","print('Verify SSL    :', VERIFY_SSL)\n","print('Output folder :', output_dir)\n","print('Token:', token)"]},{"cell_type":"markdown","id":"2da97a6a","metadata":{},"source":["## Session and API helpers\n","\n","We create an authenticated session and small helpers to call endpoints:\n","- `api_url(path)` builds full URLs\n","- `get_json(url)` fetches JSON via GET\n","- `post_search(query)` executes TWQL via the Data Search API\n","- `normalize_results(payload)` returns a list of dicts from varied formats"]},{"cell_type":"code","execution_count":null,"id":"d7915af6","metadata":{},"outputs":[],"source":["session = requests.Session()\n","auth_value = token if token.lower().startswith('bearer ') else f'Bearer {token}'\n","session.headers.update({'Authorization': auth_value, 'Accept': 'application/json'})\n","session.verify = VERIFY_SSL\n","\n","def api_url(path: str) -> str:\n","    base = BASE_URL.rstrip('/') + f'/api/{API_VERSION}/'\n","    return urljoin(base, path.lstrip('/'))\n","\n","def get_json(url: str, **kwargs):\n","    r = session.get(url, **kwargs)\n","    if r.status_code != 200:\n","        print(f'Error {r.status_code} GET {url}: {r.text[:200]}')\n","        return {}\n","    try:\n","        return r.json()\n","    except Exception as e:\n","        print('Failed to decode JSON:', e)\n","        return {}\n","\n","def normalize_results(raw):\n","    # Normalize a variety of Discovery API search response shapes into\n","    # a flat list of dictionaries.\n","    rows = []\n","    if isinstance(raw, dict):\n","        res = raw.get('results')\n","        # Newer servers may return a nested table object\n","        if isinstance(res, dict):\n","            headers = res.get('headers') or res.get('columns')\n","            rws = res.get('rows') or res.get('data')\n","            if isinstance(headers, list) and isinstance(rws, list):\n","                return [dict(zip(headers, r)) for r in rws]\n","        # Common case: results is a list (either list of dicts, or table)\n","        if isinstance(res, list):\n","            rows = res\n","        elif isinstance(raw, list):\n","            rows = raw\n","        else:\n","            # Sometimes the response is already a list under another key\n","            # fall through with empty rows.\n","            rows = []\n","    elif isinstance(raw, list):\n","        rows = raw\n","    else:\n","        rows = []\n","    # Convert table format (list of lists) into list of dicts\n","    if rows and isinstance(rows[0], list):\n","        headers = rows[0]\n","        return [dict(zip(headers, r)) for r in rows[1:]]\n","    return rows\n","\n","def post_search(query: str, *, limit: int | None = None, page_size: int = 500):\n","    \"\"\"Execute TWQL with simple pagination.\n","    When limit is 0, fetch all rows by paging; when None, defer to server default.\n","    Returns a list of dict rows.\n","    \"\"\"\n","    url = api_url('data/search')\n","    rows_all = []\n","    offset = 0\n","    fetch_all = (limit == 0)\n","    while True:\n","        payload = {'query': query, 'format': 'object'}\n","        if fetch_all:\n","            payload['limit'] = page_size\n","            if offset:\n","                payload['offset'] = offset\n","        elif limit is not None:\n","            payload['limit'] = limit\n","        r = session.post(url, json=payload)\n","        if r.status_code >= 400:\n","            print(f'Error {r.status_code} POST {url}: {r.text[:200]}')\n","            try:\n","                data = r.json()\n","            except Exception:\n","                data = []\n","            return normalize_results(data)\n","        try:\n","            data = r.json()\n","        except Exception:\n","            data = []\n","        rows = normalize_results(data)\n","        if not fetch_all:\n","            return rows\n","        rows_all.extend(rows)\n","        if not rows or len(rows) < page_size:\n","            break\n","        offset += page_size\n","    return rows_all"]},{"cell_type":"markdown","id":"9b486772","metadata":{},"source":["## Queries used by the report\n","\n","These TWQL queries mirror DisMAL’s credential success workflow."]},{"cell_type":"code","execution_count":null,"id":"d2eb25a0","metadata":{},"outputs":[],"source":["qry_credential_success = '''\n","search SessionResult where success\n","show (credential or slave) as 'SessionResult.credential_or_slave',\n","     (credential or slave) as 'uuid',\n","     session_type as 'SessionResult.session_type',\n","     outpost as 'SessionResult.outpost'\n","processwith countUnique(1,0)\n","'''\n","qry_credential_failure = '''\n","search SessionResult where not success\n","show (credential or slave) as 'SessionResult.credential_or_slave',\n","     (credential or slave) as 'uuid',\n","     session_type as 'SessionResult.session_type',\n","     outpost as 'SessionResult.outpost'\n","processwith countUnique(1,0)\n","'''\n","qry_deviceinfo_success = '''\n","search DeviceInfo where method_success\n","  and nodecount(traverse DiscoveryResult:DiscoveryAccessResult:DiscoveryAccess:DiscoveryAccess\n","                traverse DiscoveryAccess:Metadata:Detail:SessionResult) = 0\n","show (last_credential or last_slave) as 'DeviceInfo.last_credential',\n","     (last_credential or last_slave) as 'uuid',\n","     access_method as 'DeviceInfo.access_method'\n","process with countUnique(1,0)\n","'''\n","qry_credential_success_7d = '''\n","search SessionResult where success and time_index > (currentTime() - 7*24*3600*10000000)\n","show (credential or slave) as 'SessionResult.credential_or_slave',\n","     (credential or slave) as 'uuid',\n","     session_type as 'SessionResult.session_type',\n","     outpost as 'SessionResult.outpost'\n","processwith countUnique(1,0)\n","'''\n","qry_credential_failure_7d = '''\n","search SessionResult where not success and time_index > (currentTime() - 7*24*3600*10000000)\n","show (credential or slave) as 'SessionResult.credential_or_slave',\n","     (credential or slave) as 'uuid',\n","     session_type as 'SessionResult.session_type',\n","     outpost as 'SessionResult.outpost'\n","processwith countUnique(1,0)\n","'''\n","qry_deviceinfo_success_7d = '''\n","search DeviceInfo where method_success\n","  and nodecount(traverse DiscoveryResult:DiscoveryAccessResult:DiscoveryAccess:DiscoveryAccess\n","                traverse DiscoveryAccess:Metadata:Detail:SessionResult) = 0\n","  and time_index > (currentTime() - 7*24*3600*10000000)\n","show (last_credential or last_slave) as 'DeviceInfo.last_credential',\n","     (last_credential or last_slave) as 'uuid',\n","     access_method as 'DeviceInfo.access_method'\n","process with countUnique(1,0)\n","'''\n","qry_scanrange = '''\n","search ScanRange where scan_type = 'Scheduled'\n","show range_id as 'ID', label as 'Label', (range_strings or provider) as 'Scan_Range',\n","     scan_level as 'Level', recurrenceDescription(schedule) as 'Date_Rules'\n","'''\n","qry_excludes = '''\n","search in '_System' ExcludeRange\n","show exrange_id as 'ID', name as 'Label', range_strings as 'Scan_Range',\n","     recurrenceDescription(schedule) as 'Date_Rules'\n","'''"]},{"cell_type":"markdown","id":"fd777943","metadata":{},"source":["## Helper functions (formatting and scan membership)\n","\n","- `session_get(rows)` aggregates counts by credential UUID and stores an access method hint\n","- `parse_ranges(range_str)` parses comma-separated CIDRs into ipaddress networks\n","- `labels_covering_ranges(entries, cred_ranges)` returns scan labels that include any credential range"]},{"cell_type":"code","execution_count":null,"id":"c6138c54","metadata":{},"outputs":[],"source":["def search_to_df(results):\n","    \"\"\"\n","    Convert a post_search() response into a DataFrame with proper headings.\n","    Falls back to a simple DataFrame(results) if structure is unexpected.\n","    \"\"\"\n","    if not results or not isinstance(results, list):\n","        return pd.DataFrame()\n","    first = results[0]\n","    if isinstance(first, dict) and \"results\" in first and \"headings\" in first:\n","        return pd.DataFrame(first[\"results\"], columns=first[\"headings\"])\n","    # Fallback (rare)\n","    return pd.DataFrame(results)\n","\n","def preview_search(results, n=10):\n","    \"\"\"\n","    Display the first n rows of the first result block as a DataFrame.\n","    \"\"\"\n","    df = search_to_df(results)\n","    display(df.head(n))\n","    return df\n","\n","def build_map_from_search(results, dedupe=True):\n","    \"\"\"\n","    Build the {uuid: [restype, count]} map from a post_search() response.\n","    Uses your existing session_get().\n","    \"\"\"\n","    df = search_to_df(results)\n","    if df.empty:\n","        return {}\n","    if dedupe:\n","        df = df.drop_duplicates()\n","    return session_get(df)\n","\n","def show_map_sample(mapping, k=5):\n","    \"\"\"\n","    Quick peek at the mapping: length + first k items.\n","    \"\"\"\n","    print(len(mapping))\n","    print(dict(list(mapping.items())[:k]))\n","\n","def session_get(results):\n","    # Accept either a DataFrame or a list of dicts\n","    if isinstance(results, pd.DataFrame):\n","        # Replace NaN with None to make .get logic work\n","        rows = results.replace({pd.NA: None}).where(pd.notna(results), None).to_dict(orient='records')\n","    else:\n","        rows = results\n","\n","    mapping = {}\n","    for r in rows:\n","        if not isinstance(r, dict):\n","            continue\n","\n","        uuid = (\n","            r.get('SessionResult.credential_or_slave')\n","            or r.get('DeviceInfo.last_credential')\n","            or r.get('uuid')\n","        )\n","        if not uuid:\n","            continue\n","\n","        key = str(uuid).split('/')[-1].lower()\n","\n","        restype = r.get('SessionResult.session_type') or r.get('DeviceInfo.access_method')\n","        # Count can be labelled differently; try common variants\n","        raw_count = r.get('Count', r.get('count', 0)) or 0\n","        try:\n","            count = int(raw_count)\n","        except (TypeError, ValueError):\n","            count = 0\n","\n","        mapping[key] = [restype, count]\n","\n","    return mapping\n","\n","import pandas as pd\n","from ipaddress import ip_network\n","\n","def parse_ranges(ranges):\n","    \"\"\"\n","    Accepts a string like '10.0.0.0/8,192.168.0.0/16,::/0' or a list of strings.\n","    Returns a list of ip_network objects, skipping invalids.\n","    \"\"\"\n","    if ranges is None or (isinstance(ranges, float) and pd.isna(ranges)):\n","        return []\n","\n","    if isinstance(ranges, str):\n","        parts = [p.strip() for p in ranges.replace(';', ',').split(',') if p.strip()]\n","    elif isinstance(ranges, list):\n","        parts = []\n","        for r in ranges:\n","            if r is None or (isinstance(r, float) and pd.isna(r)):\n","                continue\n","            parts.extend([p.strip() for p in str(r).replace(';', ',').split(',') if p.strip()])\n","    else:\n","        parts = [str(ranges).strip()]\n","\n","    # normalise common typos\n","    norm = []\n","    for p in parts:\n","        if p == '::0':\n","            p = '::/0'\n","        norm.append(p)\n","\n","    nets = []\n","    for p in norm:\n","        try:\n","            nets.append(ip_network(p, strict=False))\n","        except Exception:\n","            # skip malformed/non-CIDR entries\n","            continue\n","    return nets\n","\n","def to_rows(entries):\n","    \"\"\"\n","    Converts post_search(...) output to a list of row dicts using the first block's headings/results.\n","    Accepts a DataFrame, list[dict], or raw dict.\n","    \"\"\"\n","    if isinstance(entries, pd.DataFrame):\n","        # if they gave us a df of the 'first page', just return its records\n","        return entries.replace({pd.NA: None}).where(pd.notna(entries), None).to_dict(orient='records')\n","\n","    if isinstance(entries, list) and entries and isinstance(entries[0], dict):\n","        block = entries[0]\n","        if 'headings' in block and 'results' in block:\n","            df = pd.DataFrame(block['results'], columns=block['headings'])\n","            return df.replace({pd.NA: None}).where(pd.notna(df), None).to_dict(orient='records')\n","\n","    if isinstance(entries, dict) and 'headings' in entries and 'results' in entries:\n","        df = pd.DataFrame(entries['results'], columns=entries['headings'])\n","        return df.replace({pd.NA: None}).where(pd.notna(df), None).to_dict(orient='records')\n","\n","    # fallback: assume it's already list[dict]\n","    return entries if isinstance(entries, list) else []\n","\n","def labels_covering_ranges(entries, cred_ranges):\n","    \"\"\"\n","    Returns sorted unique labels whose Scan_Range overlaps any of the cred_ranges networks.\n","    entries: post_search(...) result or a DataFrame/list[dict] with columns: Label, Scan_Range\n","    cred_ranges: string '10.0.0.0/8,::/0' or list of CIDR strings\n","    \"\"\"\n","    labels = []\n","    cred_nets = parse_ranges(cred_ranges)\n","    if not cred_nets:\n","        return labels\n","\n","    rows = to_rows(entries)\n","    for row in rows:\n","        label = row.get('Label')\n","        scan_rs = row.get('Scan_Range')  # may be str or list\n","        scan_nets = parse_ranges(scan_rs)\n","        if not scan_nets or not label:\n","            continue\n","\n","        # overlap check (IPv4 vs IPv6 mismatches are naturally non-overlapping here)\n","        found = False\n","        for cn in cred_nets:\n","            for sn in scan_nets:\n","                # only compare same address family\n","                if cn.version != sn.version:\n","                    continue\n","                if cn.overlaps(sn):\n","                    found = True\n","                    break\n","            if found:\n","                break\n","\n","        if found:\n","            labels.append(label)\n","\n","    return sorted(set(labels))"]},{"cell_type":"markdown","id":"dfecd54a","metadata":{},"source":["## Fetch reference data\n","\n","- Vault credentials (labels, usernames, ranges, enabled/usage)\n","- Scan ranges and Exclude ranges\n","- Outpost list and (credential -> outpost) mappings"]},{"cell_type":"code","execution_count":null,"id":"a636642c-82a5-45b7-80b4-dbf6d1666621","metadata":{},"outputs":[],"source":["# Vault credentials\n","vault_url = api_url('/vault/credentials')\n","vault_creds = normalize_results(get_json(vault_url))\n","if not isinstance(vault_creds, list) or not vault_creds:\n","    print('Warning: vault credentials not returned; report may be incomplete.')\n","else:\n","    df = pd.DataFrame(vault_creds)\n","    display(df.head(10))"]},{"cell_type":"code","execution_count":null,"id":"8e97841a-f8e4-41df-8335-08d277cf9f53","metadata":{},"outputs":[],"source":["# Scan ranges and excludes\n","scan_ranges = post_search(qry_scanrange, limit=0)\n","df = pd.DataFrame(scan_ranges)\n","display(df.head(10))\n","exclude_ranges = post_search(qry_excludes, limit=0)\n","df = pd.DataFrame(exclude_ranges)\n","display(df.head(10))"]},{"cell_type":"code","execution_count":null,"id":"6e36a338-039a-4edd-8f71-e367e250dfe4","metadata":{},"outputs":[],"source":["# Outposts list and mapping\n","outposts = normalize_results(get_json(api_url('discovery/outposts?deleted=false')))\n","id_to_url = {}\n","for op in outposts:\n","    op_id = op.get('id') or op.get('outpost') or op.get('outpost_id') or op.get('uuid')\n","    if op_id:\n","        id_to_url[str(op_id)] = op.get('url')\n","\n","df = pd.DataFrame(outposts)\n","display(df.head(10))"]},{"cell_type":"code","execution_count":null,"id":"7d29e7b4-ebd1-41d3-b775-57ade1c0ad78","metadata":{},"outputs":[],"source":["# We're going to run this again without countUnique as this can be intensive and cuase the API to timeout\n","qry_outpost_credentials = '''\n","search SessionResult\n","show credential, credential as 'uuid', outpost\n","'''\n","cred_outpost_map = {}  # uuid -> {'id': outpost_id, 'url': url}\n","op_creds = post_search(qry_outpost_credentials, limit=0)\n","\n","data = op_creds[0]  # grab the first object\n","df = pd.DataFrame(data[\"results\"], columns=data[\"headings\"])\n","\n","# drop duplicates\n","df_unique = df.drop_duplicates()\n","\n","display(df_unique.head(10))  # show first 10 unique rows"]},{"cell_type":"code","execution_count":null,"id":"b33bbea6","metadata":{},"outputs":[],"source":["for row in df_unique.itertuples(index=False):\n","    uuid = getattr(row, 'credential') or getattr(row, 'uuid')\n","    opid = getattr(row, 'outpost')\n","    if uuid and opid:\n","        info = {'id': str(opid), 'url': id_to_url.get(str(opid))}\n","        cred_outpost_map[str(uuid).lower()] = info\n","\n","df_map = pd.DataFrame.from_dict(cred_outpost_map, orient='index')\n","display(df_map.head(10))"]},{"cell_type":"markdown","id":"e051b43f","metadata":{},"source":["## Execute success/failure queries\n","\n","We gather counts for all time and for the last 7 days, from SessionResult and DeviceInfo."]},{"cell_type":"code","execution_count":null,"id":"6ff82094-0dba-490a-be25-26af430234da","metadata":{},"outputs":[],"source":["# Success (all time)\n","credsux_results = post_search(qry_credential_success, limit=0)\n","preview_search(credsux_results)  # optional: see head(10)\n","suxCreds = build_map_from_search(credsux_results)\n","show_map_sample(suxCreds)"]},{"cell_type":"code","execution_count":null,"id":"6c9d169a-4a40-4178-9338-e54163adce75","metadata":{},"outputs":[],"source":["# DeviceInfo success (all time)\n","devinfosux = post_search(qry_deviceinfo_success, limit=0)\n","preview_search(devinfosux)       # optional\n","suxDev = build_map_from_search(devinfosux)\n","show_map_sample(suxDev)"]},{"cell_type":"code","execution_count":null,"id":"94eaeeb6-6f9f-4a61-b5de-26fa94c31264","metadata":{},"outputs":[],"source":["# Credential failure (all time)\n","credfail_results = post_search(qry_credential_failure, limit=0)\n","preview_search(credfail_results) # optional\n","failCreds = build_map_from_search(credfail_results)\n","show_map_sample(failCreds)"]},{"cell_type":"code","execution_count":null,"id":"fec83473-0985-470f-8fa8-f65ecef8acb8","metadata":{},"outputs":[],"source":["# Success (last 7d)\n","credsux7_results = post_search(qry_credential_success_7d, limit=0)\n","preview_search(credsux7_results) # optional\n","suxCreds7 = build_map_from_search(credsux7_results)\n","show_map_sample(suxCreds7)"]},{"cell_type":"code","execution_count":null,"id":"adc60c19-28f2-4ad3-b184-42d837342eb6","metadata":{},"outputs":[],"source":["# DeviceInfo success (last 7d)\n","devinfosux7 = post_search(qry_deviceinfo_success_7d, limit=0)\n","preview_search(devinfosux7)      # optional\n","suxDev7 = build_map_from_search(devinfosux7)\n","show_map_sample(suxDev7)"]},{"cell_type":"code","execution_count":null,"id":"73250b74","metadata":{},"outputs":[],"source":["# Credential failure (last 7d)\n","credfail7_results = post_search(qry_credential_failure_7d, limit=0)\n","preview_search(credfail7_results) # optional\n","failCreds7 = build_map_from_search(credfail7_results)\n","show_map_sample(failCreds7)"]},{"cell_type":"markdown","id":"1fba0425","metadata":{},"source":["## Build the report rows\n","\n","Loop through vault credentials, compute success/failure counts and percentages,\n","attach scheduling/exclusion coverage, and outpost info."]},{"cell_type":"code","execution_count":null,"id":"a67b86f5","metadata":{},"outputs":[],"source":["rows = []\n","for cred in vault_creds or []:\n","    if not isinstance(cred, dict):\n","        continue\n","    idx = cred.get('index')\n","    uuid = (cred.get('uuid') or '').strip()\n","    if not uuid:\n","        continue\n","    uuid_key = uuid.split('/')[-1].lower()\n","    label = cred.get('label')\n","    enabled = bool(cred.get('enabled'))\n","    types = cred.get('types')\n","    usage = cred.get('usage')\n","    # best-effort username field\n","    username = cred.get('username') or cred.get('snmp.v3.securityname') or cred.get('aws.access_key_id') or cred.get('azure.application_id')\n","    ip_range = cred.get('ip_range')\n","    ip_exclusion = cred.get('ip_exclusion')\n","    status = 'Enabled' if enabled else 'Disabled'\n","\n","    sessions = suxCreds.get(uuid_key, [None, 0])\n","    devinfos = suxDev.get(uuid_key, [None, 0])\n","    failure = failCreds.get(uuid_key, [None, 0])\n","    sessions7 = suxCreds7.get(uuid_key, [None, 0])\n","    devinfos7 = suxDev7.get(uuid_key, [None, 0])\n","    failure7 = failCreds7.get(uuid_key, [None, 0])\n","\n","    # Active if present in any mapping or any count present\n","    active = (uuid_key in suxCreds or uuid_key in suxDev or uuid_key in failCreds or\n","              uuid_key in suxCreds7 or uuid_key in suxDev7 or uuid_key in failCreds7 or\n","              any(x[1] for x in [sessions, devinfos, failure, sessions7, devinfos7, failure7]))\n","\n","    success_all = int((sessions[1] or 0)) + int((devinfos[1] or 0))\n","    fails_all = int(failure[1] or 0)\n","    total = success_all + fails_all\n","    percent_all = (success_all / total) if total else 0.0\n","    success7 = int((sessions7[1] or 0)) + int((devinfos7[1] or 0))\n","    fails7 = int(failure7[1] or 0)\n","    total7 = success7 + fails7\n","    percent7 = (success7 / total7) if total7 else 0.0\n","\n","    scheduled_scans = labels_covering_ranges(scan_ranges, ip_range)\n","    excluded_scans = labels_covering_ranges(exclude_ranges, ip_range)\n","\n","    op_info = cred_outpost_map.get(uuid_key, {})\n","    outpost_id = op_info.get('id')\n","    outpost_url = op_info.get('url')\n","    proto = sessions[0] or failure[0] or types\n","\n","    if active:\n","        rows.append([\n","            label, idx, uuid, username, proto, success_all, fails_all, percent_all, percent7,\n","            status, usage, ip_range, ip_exclusion, scheduled_scans or None, excluded_scans or None,\n","            outpost_id, outpost_url\n","        ])\n","    else:\n","        rows.append([\n","            label, idx, uuid, username, types, 0, 0, 0.0, 0.0,\n","            f'Credential appears to not be in use ({status})', usage, ip_range, ip_exclusion,\n","            scheduled_scans or None, excluded_scans or None, outpost_id, outpost_url\n","        ])\n","\n","headers = [\n","    'Discovery Instance', 'Credential', 'Index', 'UUID', 'Login ID', 'Protocol',\n","    'Successes', 'Failures', 'Success % All Time', 'Success % 7 Days', 'State',\n","    'Usage', 'Ranges', 'Excludes', 'Scheduled Scans', 'Exclusion Lists',\n","    'Outpost', 'Outpost URL'\n","]\n","df_out = pd.DataFrame(rows, columns=headers[1:])\n","df_out.insert(0, 'Discovery Instance', target)\n","df_out.head()"]},{"cell_type":"markdown","id":"716a14a4","metadata":{},"source":["## Save to CSV\n","\n","Writes the report to the standard output folder as used by the CLI."]},{"cell_type":"code","execution_count":null,"id":"06b575d3","metadata":{},"outputs":[],"source":["OUTPUT_CSV = str(output_dir / 'credential_success.csv')\n","df_out.to_csv(OUTPUT_CSV, index=False)\n","print(f'Saved to {OUTPUT_CSV}')"]},{"cell_type":"code","execution_count":null,"id":"fe853b7f-1213-4e7e-82a1-39e15c8f2a78","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":5}