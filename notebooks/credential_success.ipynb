{"cells":[{"cell_type":"markdown","id":"4f4c9dca","metadata":{},"source":["# Credential Success Report (BMC Discovery)\n","\n","This notebook reproduces the DisMAL `credential_success` report using the Tideway API for vault metadata and the pre-generated query exports.\n","Vault data still comes directly from the appliance, while query results are read from `raw_exports/<appliance>/<query>.csv`.\n","\n","> **NOTE:** This can take a little while to run if you have lots of DiscoveryAccesses\n"]},{"cell_type":"code","execution_count":null,"id":"dc01e1ba-d0b1-410a-abce-e2b75caa2875","metadata":{},"outputs":[],"source":["# TODO: Fix report headers\n","# TODO: Fix success calc.\n","# TODO: Fix scheduled scans, excluded scans, outpost id, oupost url"]},{"cell_type":"markdown","id":"82bcd7ef","metadata":{},"source":["## Requirements\n","\n","We rely on `pandas` for tabular wrangling, `PyYAML` for configuration, and the Tideway SDK for vault access.\n","Uncomment the next cell to install them in your environment if needed.\n"]},{"cell_type":"code","execution_count":null,"id":"61b133c8","metadata":{},"outputs":[],"source":["# %pip install -q pandas pyyaml tideway\n","\n","import re\n","from pathlib import Path\n","from ipaddress import ip_network\n","\n","import pandas as pd\n","import yaml\n","import tideway\n"]},{"cell_type":"markdown","id":"43fff079","metadata":{},"source":["## Configuration (from config.yaml)\n","\n","Reads settings from `../config.yaml` including target, token/token_file,\n","API version, and SSL verification preference.\n","Saves the CSV to `../output_<target>/credential_success.csv`."]},{"cell_type":"code","execution_count":null,"id":"98a071bd","metadata":{},"outputs":[],"source":["from pathlib import Path\n","import re\n","import yaml\n","\n","def load_config_params(\n","    start: Path,\n","    appliance_name: str = None,\n","    appliance_index: int = 0,\n",") -> dict:\n","    def _find_repo_root(start: Path) -> Path:\n","        for p in [start] + list(start.parents):\n","            if (p / 'config.yaml').exists():\n","                return p\n","        return start.parent\n","\n","    def _slugify(value: str) -> str:\n","        return re.sub(r'[^A-Za-z0-9]+', '_', value).strip('_').lower() or 'default'\n","\n","    repo_root = _find_repo_root(start)\n","    config_path = repo_root / 'config.yaml'\n","\n","    with open(config_path, 'r') as fh:\n","        cfg = yaml.safe_load(fh) or {}\n","\n","    apps = cfg.get('appliances') or []\n","    selected = None\n","    if isinstance(apps, list) and apps:\n","        if appliance_name:\n","            selected = next((a for a in apps if a.get('name') == appliance_name), None)\n","            if selected is None:\n","                raise ValueError(f\"No appliance named '{appliance_name}' in config.yaml\")\n","        else:\n","            try:\n","                selected = apps[int(appliance_index)]\n","            except Exception:\n","                selected = apps[0]\n","\n","    target = ((selected or {}).get('target') or cfg.get('target') or '').strip()\n","    if not target:\n","        raise ValueError('config.yaml missing \"target\"')\n","\n","    token = (((selected or {}).get('token') or cfg.get('token') or '').strip())\n","    token_file = (selected or {}).get('token_file') or cfg.get('token_file') or cfg.get('f_token')\n","    if not token and token_file:\n","        tf_path = Path(token_file)\n","        if not tf_path.is_absolute():\n","            tf_path = repo_root / tf_path\n","        with open(tf_path, 'r') as tf:\n","            token = tf.read().strip()\n","    if not token:\n","        raise ValueError('API token not found in config.yaml (token or token_file)')\n","\n","    api_version = str((selected or {}).get('api_version') or cfg.get('api_version') or 'v1.14')\n","    verify_ssl = bool((selected or {}).get('verify_ssl', cfg.get('verify_ssl', True)))\n","\n","    sanitized = target.replace('.', '_').replace(':', '_').replace('/', '_')\n","    output_dir = repo_root / f'output_{sanitized}'\n","    output_dir.mkdir(parents=True, exist_ok=True)\n","\n","    export_name = ((selected or {}).get('name') or appliance_name or sanitized)\n","    raw_export_dir = repo_root / 'raw_exports' / _slugify(export_name)\n","\n","    return {\n","        \"repo_root\": repo_root,\n","        \"config_path\": config_path,\n","        \"cfg\": cfg,\n","        \"selected\": selected,\n","        \"target\": target,\n","        \"token\": token,\n","        \"api_version\": api_version,\n","        \"verify_ssl\": verify_ssl,\n","        \"output_dir\": output_dir,\n","        \"raw_export_dir\": raw_export_dir,\n","    }\n"]},{"cell_type":"code","execution_count":null,"id":"48bb49e8-07f6-4dcc-9ab3-60433b3093dc","metadata":{},"outputs":[],"source":["def init_appliance(appliance_name: str = \"prod\"):\n","    params = load_config_params(Path.cwd(), appliance_name=appliance_name)\n","\n","    target = params[\"target\"]\n","    api_version = params[\"api_version\"]\n","    verify_ssl = params[\"verify_ssl\"]\n","    output_dir = params[\"output_dir\"]\n","    raw_export_dir = params[\"raw_export_dir\"]\n","\n","    print('Appliance Name :', appliance_name)\n","    print('Target         :', target)\n","    print('API Version    :', api_version)\n","    print('Verify SSL     :', verify_ssl)\n","    print('Raw CSV folder :', raw_export_dir)\n","    print('Output folder  :', output_dir)\n","\n","    api_number = api_version.lstrip('vV')\n","\n","    app = tideway.appliance(target, params[\"token\"], api_version=api_number, ssl_verify=verify_ssl)\n","\n","    try:\n","        about = app.api_about\n","        print('Appliance reachable:', about.status_code)\n","    except Exception as e:\n","        print('Warning: failed to contact appliance /api/about:', e)\n","\n","    return {\n","        \"params\": params,\n","        \"target\": target,\n","        \"app\": app,\n","        \"api_version\": api_number,\n","        \"output_dir\": output_dir,\n","        \"raw_export_dir\": raw_export_dir,\n","        \"appliance_name\": appliance_name,\n","    }\n"]},{"cell_type":"markdown","id":"1a4f81c6-a36a-4544-8b74-938d8072b362","metadata":{},"source":["# Initialise Instances"]},{"cell_type":"code","execution_count":null,"id":"4f371f86-a693-4ecd-a821-a98307444a39","metadata":{},"outputs":[],"source":["print(\"Initialise Prod:\")\n","twprod = init_appliance(\"prod\")\n","\n","print(\"Initialise Dev:\")\n","twdev = init_appliance(\"dev\")"]},{"cell_type":"code","execution_count":null,"id":"c676be4a-6788-4b13-ba0b-1d389c5febea","metadata":{},"outputs":[],"source":["# bootstrapping variables\n","\n","token = twprod[\"params\"][\"token\"]\n","tokendev = twdev[\"params\"][\"token\"]\n","VERIFY_SSL = twprod[\"params\"][\"verify_ssl\"]\n","verify_ssl_dev = twdev[\"params\"][\"verify_ssl\"]\n","target = twprod[\"target\"]\n","target_dev = twdev[\"target\"]\n","api_version = twprod[\"api_version\"]\n","api_version_dev = twdev[\"api_version\"]\n","output_dir = twprod[\"output_dir\"]\n","output_dir_dev = twdev[\"output_dir\"]\n","\n","BASE_URL = target if ('://' in target) else f'https://{target}'\n","API_VERSION = api_version"]},{"cell_type":"markdown","id":"dfecd54a","metadata":{},"source":["## Fetch reference data\n","\n","- Vault credentials (labels, usernames, ranges, enabled/usage) via API\n","- Scan ranges and Exclude ranges from raw query exports\n","- Outpost list and (credential -> outpost) mappings\n"]},{"cell_type":"code","execution_count":null,"id":"a636642c-82a5-45b7-80b4-dbf6d1666621","metadata":{},"outputs":[],"source":["# Vault credentials\n","prodvault = twprod[\"app\"].credentials()\n","devvault = twdev[\"app\"].credentials()\n","\n","print(twprod['target'])\n","vault_prod = prodvault.get_vault_credentials.json()\n","df = pd.DataFrame(vault_prod)\n","display(df.head(10))\n","\n","print(twdev['target'])\n","vault_dev = devvault.get_vault_credentials.json()\n","df = pd.DataFrame(vault_dev)\n","display(df.head(10))"]},{"cell_type":"code","execution_count":null,"id":"8e97841a-f8e4-41df-8335-08d277cf9f53","metadata":{},"outputs":[],"source":["BASE_EXPORT_COLUMNS = ['Appliance Target', 'Appliance Name', 'Query Title']\n","_SLUG_PATTERN = re.compile(r'[^A-Za-z0-9]+')\n","\n","def slugify_title(value: str) -> str:\n","    slug = _SLUG_PATTERN.sub('_', value or '').strip('_').lower()\n","    return slug or 'unnamed'\n","\n","def load_query_export(instance, query_title: str, expected_columns=None, drop_duplicates=False):\n","    expected_columns = expected_columns or []\n","    csv_path = instance['raw_export_dir'] / f\"{slugify_title(query_title)}.csv\"\n","\n","    if csv_path.exists():\n","        df = pd.read_csv(csv_path)\n","    else:\n","        print(f\"Warning: missing export for {query_title} at {csv_path}\")\n","        df = pd.DataFrame(columns=expected_columns)\n","\n","    df = df.drop(columns=[c for c in BASE_EXPORT_COLUMNS if c in df.columns], errors='ignore')\n","\n","    if df.empty and expected_columns:\n","        df = pd.DataFrame(columns=expected_columns)\n","\n","    for col in expected_columns:\n","        if col not in df.columns:\n","            df[col] = pd.NA\n","\n","    if drop_duplicates:\n","        df = df.drop_duplicates().reset_index(drop=True)\n","\n","    ordered_cols = expected_columns + [c for c in df.columns if c not in expected_columns]\n","    if ordered_cols:\n","        df = df[ordered_cols]\n","\n","    if 'Count' in df.columns:\n","        df['Count'] = pd.to_numeric(df['Count'], errors='coerce')\n","\n","    df.insert(0, 'Discovery Instance', instance['target'])\n","    return df\n","\n","def to_lookup(df, key_column: str, value_columns):\n","    lookup = {}\n","    value_columns = list(value_columns)\n","    if df is None or df.empty:\n","        return lookup\n","    for _, row in df.iterrows():\n","        raw_key = row.get(key_column)\n","        if not raw_key:\n","            continue\n","        key = str(raw_key).split('/')[-1].lower()\n","        if not key:\n","            continue\n","        values = []\n","        for col in value_columns:\n","            val = row.get(col)\n","            if isinstance(val, float) and pd.isna(val):\n","                val = None\n","            if col.lower() == 'count' and val is not None:\n","                try:\n","                    val = int(val)\n","                except (TypeError, ValueError):\n","                    try:\n","                        val = int(float(val))\n","                    except Exception:\n","                        val = 0\n","            values.append(val)\n","        lookup[key] = values\n","    return lookup\n","\n","# Scan ranges and excludes\n","scan_columns = ['ID', 'Label', 'Scan_Range', 'Level', 'Date_Rules']\n","scan_prod = load_query_export(twprod, 'Scheduled Scan Ranges', scan_columns)\n","print(twprod['target'])\n","display(scan_prod.head(5))\n","\n","scan_dev = load_query_export(twdev, 'Scheduled Scan Ranges', scan_columns)\n","print(twdev['target'])\n","display(scan_dev.head(5))\n","\n","exclude_columns = ['ID', 'Label', 'Scan_Range', 'Date_Rules']\n","ex_columns = exclude_columns  # alias for clarity\n","ex_prod = load_query_export(twprod, 'Exclude Ranges', ex_columns)\n","print(twprod['target'])\n","display(ex_prod.head(5))\n","\n","ex_dev = load_query_export(twdev, 'Exclude Ranges', ex_columns)\n","print(twdev['target'])\n","display(ex_dev.head(5))\n"]},{"cell_type":"code","execution_count":null,"id":"6e36a338-039a-4edd-8f71-e367e250dfe4","metadata":{},"outputs":[],"source":["# Outposts list and mapping\n","def get_endpoint(instance, ep):\n","    results = instance['app'].get(ep)\n","    df = pd.DataFrame(results.json()) if results else pd.DataFrame()\n","    if df.empty:\n","        df = pd.DataFrame(columns=['name','id','url','scope','enabled','exclude_ranges','scan_ranges','version','last_contact'])\n","    df.insert(0, 'Discovery Instance', instance['target'])\n","    return df\n","\n","outposts_prod = get_endpoint(twprod, '/discovery/outposts')\n","display(outposts_prod.head(5))\n","\n","outposts_dev = get_endpoint(twdev, '/discovery/outposts')\n","display(outposts_dev.head(5))\n"]},{"cell_type":"code","execution_count":null,"id":"e1e91225-32e7-4cec-a7c0-a18f42967f93","metadata":{"slideshow":{"slide_type":""},"tags":[]},"outputs":[],"source":["outpost_creds_prod = load_query_export(\n","    twprod,\n","    'Session Outpost Credentials',\n","    ['credential', 'uuid', 'outpost'],\n","    drop_duplicates=True,\n",")\n","print(twprod['target'])\n","display(outpost_creds_prod.head(5))\n"]},{"cell_type":"code","execution_count":null,"id":"7d29e7b4-ebd1-41d3-b775-57ade1c0ad78","metadata":{"slideshow":{"slide_type":""},"tags":[]},"outputs":[],"source":["outpost_creds_dev = load_query_export(\n","    twdev,\n","    'Session Outpost Credentials',\n","    ['credential', 'uuid', 'outpost'],\n","    drop_duplicates=True,\n",")\n","print(twdev['target'])\n","display(outpost_creds_dev.head(5))\n"]},{"cell_type":"code","execution_count":null,"id":"b33bbea6","metadata":{},"outputs":[],"source":["def build_credential_outpost_map(outposts_df, creds_df):\n","    outposts_df = outposts_df if isinstance(outposts_df, pd.DataFrame) else pd.DataFrame()\n","    creds_df = creds_df if isinstance(creds_df, pd.DataFrame) else pd.DataFrame()\n","\n","    def first_valid(*values):\n","        for value in values:\n","            if value is None or (isinstance(value, str) and not value.strip()):\n","                continue\n","            try:\n","                if pd.isna(value):\n","                    continue\n","            except TypeError:\n","                pass\n","            return value\n","        return None\n","\n","    id_to_url = {}\n","    for _, row in outposts_df.iterrows():\n","        op_id = first_valid(row.get('id'), row.get('outpost'), row.get('outpost_id'), row.get('uuid'))\n","        if op_id is None:\n","            continue\n","        id_to_url[str(op_id)] = row.get('url')\n","\n","    mapping = {}\n","    for _, row in creds_df.iterrows():\n","        uuid = first_valid(row.get('credential'), row.get('uuid'))\n","        opid = first_valid(row.get('outpost'))\n","        if uuid is None or opid is None:\n","            continue\n","        mapping[str(uuid).lower()] = {\n","            'id': str(opid),\n","            'url': id_to_url.get(str(opid))\n","        }\n","\n","    return mapping\n","\n","prod_map = build_credential_outpost_map(outposts_prod, outpost_creds_prod)\n","display(pd.DataFrame.from_dict(prod_map, orient='index').head(10))\n","dev_map = build_credential_outpost_map(outposts_dev, outpost_creds_dev)\n","display(pd.DataFrame.from_dict(dev_map, orient='index').head(10))\n"]},{"cell_type":"markdown","id":"e051b43f","metadata":{},"source":["## Load success/failure exports\n","\n","We gather counts for all time and for the last 7 days using the pre-generated CSV exports.\n"]},{"cell_type":"code","execution_count":null,"id":"6ff82094-0dba-490a-be25-26af430234da","metadata":{},"outputs":[],"source":["suxCreds_prod = load_query_export(\n","    twprod,\n","    'Credential Success (All Time)',\n","    ['SessionResult.credential_or_slave', 'uuid', 'SessionResult.session_type', 'SessionResult.outpost', 'Count'],\n",")\n","print(twprod['target'])\n","display(suxCreds_prod.head(5))\n","\n","suxCreds_prod_map = to_lookup(suxCreds_prod, 'uuid', ['SessionResult.session_type', 'Count'])\n","\n","suxCreds_dev = load_query_export(\n","    twdev,\n","    'Credential Success (All Time)',\n","    ['SessionResult.credential_or_slave', 'uuid', 'SessionResult.session_type', 'SessionResult.outpost', 'Count'],\n",")\n","print(twdev['target'])\n","display(suxCreds_dev.head(5))\n","\n","suxCreds_dev_map = to_lookup(suxCreds_dev, 'uuid', ['SessionResult.session_type', 'Count'])\n"]},{"cell_type":"code","execution_count":null,"id":"6c9d169a-4a40-4178-9338-e54163adce75","metadata":{},"outputs":[],"source":["suxDev_prod = load_query_export(\n","    twprod,\n","    'DeviceInfo Success (All Time)',\n","    ['DeviceInfo.last_credential', 'uuid', 'DeviceInfo.access_method', 'Count'],\n",")\n","print(twprod['target'])\n","display(suxDev_prod.head(5))\n","\n","suxDev_prod_map = to_lookup(suxDev_prod, 'uuid', ['DeviceInfo.access_method', 'Count'])\n","\n","suxDev_dev = load_query_export(\n","    twdev,\n","    'DeviceInfo Success (All Time)',\n","    ['DeviceInfo.last_credential', 'uuid', 'DeviceInfo.access_method', 'Count'],\n",")\n","print(twdev['target'])\n","display(suxDev_dev.head(5))\n","\n","suxDev_dev_map = to_lookup(suxDev_dev, 'uuid', ['DeviceInfo.access_method', 'Count'])\n"]},{"cell_type":"code","execution_count":null,"id":"94eaeeb6-6f9f-4a61-b5de-26fa94c31264","metadata":{},"outputs":[],"source":["failCreds_prod = load_query_export(\n","    twprod,\n","    'Credential Failure (All Time)',\n","    ['SessionResult.credential_or_slave', 'uuid', 'SessionResult.session_type', 'SessionResult.outpost', 'Count'],\n",")\n","print(twprod['target'])\n","display(failCreds_prod.head(5))\n","\n","failCreds_prod_map = to_lookup(failCreds_prod, 'uuid', ['SessionResult.session_type', 'Count'])\n","\n","failCreds_dev = load_query_export(\n","    twdev,\n","    'Credential Failure (All Time)',\n","    ['SessionResult.credential_or_slave', 'uuid', 'SessionResult.session_type', 'SessionResult.outpost', 'Count'],\n",")\n","print(twdev['target'])\n","display(failCreds_dev.head(5))\n","\n","failCreds_dev_map = to_lookup(failCreds_dev, 'uuid', ['SessionResult.session_type', 'Count'])\n"]},{"cell_type":"code","execution_count":null,"id":"fec83473-0985-470f-8fa8-f65ecef8acb8","metadata":{},"outputs":[],"source":["suxCreds7_prod = load_query_export(\n","    twprod,\n","    'Credential Success (7 Days)',\n","    ['SessionResult.credential_or_slave', 'uuid', 'SessionResult.session_type', 'SessionResult.outpost', 'Count'],\n",")\n","print(twprod['target'])\n","display(suxCreds7_prod.head(5))\n","\n","suxCreds7_prod_map = to_lookup(suxCreds7_prod, 'uuid', ['SessionResult.session_type', 'Count'])\n","\n","suxCreds7_dev = load_query_export(\n","    twdev,\n","    'Credential Success (7 Days)',\n","    ['SessionResult.credential_or_slave', 'uuid', 'SessionResult.session_type', 'SessionResult.outpost', 'Count'],\n",")\n","print(twdev['target'])\n","display(suxCreds7_dev.head(5))\n","\n","suxCreds7_dev_map = to_lookup(suxCreds7_dev, 'uuid', ['SessionResult.session_type', 'Count'])\n"]},{"cell_type":"code","execution_count":null,"id":"adc60c19-28f2-4ad3-b184-42d837342eb6","metadata":{},"outputs":[],"source":["suxDev7_prod = load_query_export(\n","    twprod,\n","    'DeviceInfo Success (7 Days)',\n","    ['DeviceInfo.last_credential', 'uuid', 'DeviceInfo.access_method', 'Count'],\n",")\n","print(twprod['target'])\n","display(suxDev7_prod.head(5))\n","\n","suxDev7_prod_map = to_lookup(suxDev7_prod, 'uuid', ['DeviceInfo.access_method', 'Count'])\n","\n","suxDev7_dev = load_query_export(\n","    twdev,\n","    'DeviceInfo Success (7 Days)',\n","    ['DeviceInfo.last_credential', 'uuid', 'DeviceInfo.access_method', 'Count'],\n",")\n","print(twdev['target'])\n","display(suxDev7_dev.head(5))\n","\n","suxDev7_dev_map = to_lookup(suxDev7_dev, 'uuid', ['DeviceInfo.access_method', 'Count'])\n"]},{"cell_type":"code","execution_count":null,"id":"73250b74","metadata":{},"outputs":[],"source":["failCreds7_prod = load_query_export(\n","    twprod,\n","    'Credential Failure (7 Days)',\n","    ['SessionResult.credential_or_slave', 'uuid', 'SessionResult.session_type', 'SessionResult.outpost', 'Count'],\n",")\n","print(twprod['target'])\n","display(failCreds7_prod.head(5))\n","\n","failCreds7_prod_map = to_lookup(failCreds7_prod, 'uuid', ['SessionResult.session_type', 'Count'])\n","\n","failCreds7_dev = load_query_export(\n","    twdev,\n","    'Credential Failure (7 Days)',\n","    ['SessionResult.credential_or_slave', 'uuid', 'SessionResult.session_type', 'SessionResult.outpost', 'Count'],\n",")\n","print(twdev['target'])\n","display(failCreds7_dev.head(5))\n","\n","failCreds7_dev_map = to_lookup(failCreds7_dev, 'uuid', ['SessionResult.session_type', 'Count'])\n"]},{"cell_type":"markdown","id":"1fba0425","metadata":{},"source":["## Build the report rows\n","\n","Loop through vault credentials, compute success/failure counts and percentages,\n","attach scheduling/exclusion coverage, and outpost info."]},{"cell_type":"code","execution_count":null,"id":"a67b86f5","metadata":{},"outputs":[],"source":["def parse_ranges(ranges):\n","    \"\"\"\n","    Accepts a string like '10.0.0.0/8,192.168.0.0/16,::/0' or a list of strings.\n","    Returns a list of ip_network objects, skipping invalids.\n","    \"\"\"\n","    if ranges is None or (isinstance(ranges, float) and pd.isna(ranges)):\n","        return []\n","\n","    if isinstance(ranges, str):\n","        parts = [p.strip() for p in ranges.replace(';', ',').split(',') if p.strip()]\n","    elif isinstance(ranges, list):\n","        parts = []\n","        for r in ranges:\n","            if r is None or (isinstance(r, float) and pd.isna(r)):\n","                continue\n","            parts.extend([p.strip() for p in str(r).replace(';', ',').split(',') if p.strip()])\n","    else:\n","        parts = [str(ranges).strip()]\n","\n","    # normalise common typos\n","    norm = []\n","    for p in parts:\n","        if p == '::0':\n","            p = '::/0'\n","        norm.append(p)\n","\n","    nets = []\n","    for p in norm:\n","        try:\n","            nets.append(ip_network(p, strict=False))\n","        except Exception:\n","            # skip malformed/non-CIDR entries\n","            continue\n","    return nets\n","\n","def to_rows(entries):\n","    \"\"\"\n","    Converts post_search(...) output to a list of row dicts using the first block's headings/results.\n","    Accepts a DataFrame, list[dict], or raw dict.\n","    \"\"\"\n","    if isinstance(entries, pd.DataFrame):\n","        # if they gave us a df of the 'first page', just return its records\n","        return entries.replace({pd.NA: None}).where(pd.notna(entries), None).to_dict(orient='records')\n","\n","    if isinstance(entries, list) and entries and isinstance(entries[0], dict):\n","        block = entries[0]\n","        if 'headings' in block and 'results' in block:\n","            df = pd.DataFrame(block['results'], columns=block['headings'])\n","            return df.replace({pd.NA: None}).where(pd.notna(df), None).to_dict(orient='records')\n","\n","    if isinstance(entries, dict) and 'headings' in entries and 'results' in entries:\n","        df = pd.DataFrame(entries['results'], columns=entries['headings'])\n","        return df.replace({pd.NA: None}).where(pd.notna(df), None).to_dict(orient='records')\n","\n","    # fallback: assume it's already list[dict]\n","    return entries if isinstance(entries, list) else []\n","\n","def labels_covering_ranges(entries, cred_ranges):\n","    \"\"\"\n","    Returns sorted unique labels whose Scan_Range overlaps any of the cred_ranges networks.\n","    entries: post_search(...) result or a DataFrame/list[dict] with columns: Label, Scan_Range\n","    cred_ranges: string '10.0.0.0/8,::/0' or list of CIDR strings\n","    \"\"\"\n","    labels = []\n","    cred_nets = parse_ranges(cred_ranges)\n","    if not cred_nets:\n","        return labels\n","\n","    rows = to_rows(entries)\n","    for row in rows:\n","        label = row['Label']\n","        scan_rs = row['Scan_Range']  # may be str or list\n","        scan_nets = parse_ranges(scan_rs)\n","        if not scan_nets or not label:\n","            continue\n","\n","        # overlap check (IPv4 vs IPv6 mismatches are naturally non-overlapping here)\n","        found = False\n","        for cn in cred_nets:\n","            for sn in scan_nets:\n","                # only compare same address family\n","                if cn.version != sn.version:\n","                    continue\n","                if cn.overlaps(sn):\n","                    found = True\n","                    break\n","            if found:\n","                break\n","\n","        if found:\n","            labels.append(label)\n","\n","    return sorted(set(labels))\n","\n","def build_cred_report(\n","    vault_creds,\n","    suxCreds, suxDev, failCreds,\n","    suxCreds7, suxDev7, failCreds7,\n","    scan_ranges, exclude_ranges,\n","    cred_outpost_map\n","):\n","    rows = []\n","\n","    for cred in vault_creds or []:\n","        #print(cred)\n","        if not isinstance(cred, dict):\n","            #print(\"Not instance, skipping\")\n","            continue\n","\n","        idx = cred[\"index\"]\n","        uuid = (cred[\"uuid\"] or \"\").strip()\n","        #print(f\"checking uuid: {uuid}\")\n","        if not uuid:\n","            #print(\"No UUID, skipping\")\n","            continue\n","\n","        uuid_key = uuid.split(\"/\")[-1].lower()\n","        label = cred[\"label\"]\n","        enabled = bool(cred[\"enabled\"])\n","        types = cred[\"types\"]\n","        usage = cred[\"usage\"]\n","\n","        # Best-effort username resolution\n","        username = (\n","            cred.get(\"username\")\n","            or cred.get(\"snmp.v3.securityname\")\n","            or cred.get(\"aws.access_key_id\")\n","            or cred.get(\"azure.application_id\")\n","        )\n","\n","        ip_range = cred.get(\"ip_range\")\n","        ip_exclusion = cred.get(\"ip_exclusion\")\n","        status = \"Enabled\" if enabled else \"Disabled\"\n","\n","        # Lookup from maps\n","        sessions  = suxCreds.get(uuid_key,  [None, 0])\n","        devinfos  = suxDev.get(uuid_key,    [None, 0])\n","        failure   = failCreds.get(uuid_key, [None, 0])\n","        sessions7 = suxCreds7.get(uuid_key, [None, 0])\n","        devinfos7 = suxDev7.get(uuid_key,   [None, 0])\n","        failure7  = failCreds7.get(uuid_key,[None, 0])\n","\n","        # Active if present in any mapping or any count present\n","        active = (\n","            uuid_key in suxCreds or uuid_key in suxDev or uuid_key in failCreds or\n","            uuid_key in suxCreds7 or uuid_key in suxDev7 or uuid_key in failCreds7 or\n","            any(x[1] for x in [sessions, devinfos, failure, sessions7, devinfos7, failure7])\n","        )\n","\n","        # Success/failure counts\n","        success_all = int(sessions[1] or 0) + int(devinfos[1] or 0)\n","        fails_all   = int(failure[1] or 0)\n","        total       = success_all + fails_all\n","        percent_all = (success_all / total) if total else 0.0\n","\n","        success7 = int(sessions7[1] or 0) + int(devinfos7[1] or 0)\n","        fails7   = int(failure7[1] or 0)\n","        total7   = success7 + fails7\n","        percent7 = (success7 / total7) if total7 else 0.0\n","\n","        # Scan coverage\n","        scheduled_scans = labels_covering_ranges(scan_ranges, ip_range)\n","        excluded_scans  = labels_covering_ranges(exclude_ranges, ip_range)\n","\n","        # Outpost info\n","        op_info    = cred_outpost_map.get(uuid_key, {})\n","        outpost_id = op_info.get(\"id\")\n","        outpost_url= op_info.get(\"url\")\n","\n","        proto = sessions[0] or failure[0] or types\n","\n","        if active:\n","            rows.append([\n","                label, idx, uuid, username, proto,\n","                success_all, fails_all, percent_all, percent7,\n","                status, usage, ip_range, ip_exclusion,\n","                scheduled_scans or None, excluded_scans or None,\n","                outpost_id, outpost_url\n","            ])\n","        else:\n","            rows.append([\n","                label, idx, uuid, username, types,\n","                0, 0, 0.0, 0.0,\n","                f\"Credential appears to not be in use ({status})\", usage,\n","                ip_range, ip_exclusion,\n","                scheduled_scans or None, excluded_scans or None,\n","                outpost_id, outpost_url\n","            ])\n","\n","    # Build DataFrame\n","    return pd.DataFrame(rows, columns=[\n","        \"label\", \"index\", \"uuid\", \"username\", \"protocol\",\n","        \"success_all\", \"fails_all\", \"percent_all\", \"percent7\",\n","        \"status\", \"usage\", \"ip_range\", \"ip_exclusion\",\n","        \"scheduled_scans\", \"excluded_scans\",\n","        \"outpost_id\", \"outpost_url\"\n","    ])\n","\n","headers = [\n","    'Discovery Instance', 'Credential', 'Index', 'UUID', 'Login ID', 'Protocol',\n","    'Successes', 'Failures', 'Success % All Time', 'Success % 7 Days', 'State',\n","    'Usage', 'Ranges', 'Excludes', 'Scheduled Scans', 'Exclusion Lists',\n","    'Outpost', 'Outpost URL'\n","]\n","\n","df_out_prod = build_cred_report(\n","    vault_prod,\n","    suxCreds_prod_map, suxDev_prod_map, failCreds_prod_map,\n","    suxCreds7_prod_map, suxDev7_prod_map, failCreds7_prod_map,\n","    scan_prod, ex_prod,\n","    prod_map\n",")\n","\n","# Build the dev report as well (you never created this)\n","df_out_dev = build_cred_report(\n","    vault_dev,\n","    suxCreds_dev_map, suxDev_dev_map, failCreds_dev_map,\n","    suxCreds7_dev_map, suxDev7_dev_map, failCreds7_dev_map,\n","    scan_dev, ex_dev,\n","    dev_map\n",")\n","\n","print(\"\\nProd preview:\")\n","display(df_out_prod.head(5))\n","print(\"\\nDev preview:\")\n","display(df_out_dev.head(5))"]},{"cell_type":"markdown","id":"716a14a4","metadata":{},"source":["## Save to CSV\n","\n","Writes the report to the standard output folder as used by the CLI."]},{"cell_type":"code","execution_count":null,"id":"06b575d3","metadata":{},"outputs":[],"source":["OUTPUT_CSV = str(twprod['output_dir'] / 'credential_success.csv')\n","df_out_prod.to_csv(OUTPUT_CSV, index=False)\n","print(f'Saved to {OUTPUT_CSV}')\n","\n","OUTPUT_CSV = str(twdev['output_dir'] / 'credential_success.csv')\n","df_out_dev.to_csv(OUTPUT_CSV, index=False)\n","print(f'Saved to {OUTPUT_CSV}')"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":5}