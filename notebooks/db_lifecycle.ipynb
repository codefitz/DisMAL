{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd6a9261",
   "metadata": {},
   "source": [
    "# Database Lifecycle Report (BMC Discovery)\n",
    "\n",
    "This notebook reproduces the DisMAL `db_lifecycle` report using the Discovery Data API.\n",
    "It reads configuration from `../config.yaml`, executes the TWQL that DisMAL uses,\n",
    "and writes a CSV to the same output structure as the CLI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec270552",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "We use `requests` for HTTP, `pandas` for tabular data, and `PyYAML` to read configuration.\n",
    "Uncomment the cell below to install them if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df10620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q requests pandas pyyaml\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from urllib.parse import urljoin\n",
    "import json, os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506e4c5b",
   "metadata": {},
   "source": [
    "## Select Appliance (optional)\n",
    "\n",
    "If your `config.yaml` defines multiple appliances under the `appliances:` list,\n",
    "set `APPLIANCE_NAME` to one of their names or use the numeric index.\n",
    "Defaults to the first appliance if neither is set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7448ebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "APPLIANCE_NAME = None   # e.g., 'prod' or 'dev'\n",
    "APPLIANCE_INDEX = 0     # integer index if not using name selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cd4255",
   "metadata": {},
   "source": [
    "## Configuration (from config.yaml)\n",
    "\n",
    "Reads settings from `../config.yaml` including target, token/token_file,\n",
    "API version, and SSL verification preference.\n",
    "Saves the CSV to `../output_<target>/db_lifecycle.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8421b00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robustly locate the project root (directory containing config.yaml)\n",
    "def _find_repo_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / 'config.yaml').exists():\n",
    "            return p\n",
    "    return start.parent\n",
    "\n",
    "repo_root = _find_repo_root(Path.cwd())\n",
    "config_path = repo_root / 'config.yaml'\n",
    "with open(config_path, 'r') as fh:\n",
    "    cfg = yaml.safe_load(fh) or {}\n",
    "\n",
    "apps = cfg.get('appliances') or []\n",
    "selected = None\n",
    "if isinstance(apps, list) and apps:\n",
    "    if APPLIANCE_NAME:\n",
    "        selected = next((a for a in apps if a.get('name') == APPLIANCE_NAME), None)\n",
    "        if selected is None:\n",
    "            raise ValueError(f\"No appliance named '{APPLIANCE_NAME}' in config.yaml\")\n",
    "    else:\n",
    "        try:\n",
    "            selected = apps[int(APPLIANCE_INDEX)]\n",
    "        except Exception:\n",
    "            selected = apps[0]\n",
    "\n",
    "target = ((selected or {}).get('target') or cfg.get('target') or '').strip()\n",
    "if not target:\n",
    "    raise ValueError('config.yaml missing \"target\"')\n",
    "BASE_URL = target if ('://' in target) else f'https://{target}'\n",
    "\n",
    "token = (((selected or {}).get('token') or cfg.get('token') or '').strip())\n",
    "token_file = (selected or {}).get('token_file') or cfg.get('token_file') or cfg.get('f_token')\n",
    "if not token and token_file:\n",
    "    tf_path = Path(token_file)\n",
    "    if not tf_path.is_absolute():\n",
    "        tf_path = repo_root / tf_path\n",
    "    with open(tf_path, 'r') as tf:\n",
    "        token = tf.read().strip()\n",
    "if not token:\n",
    "    raise ValueError('API token not found in config.yaml (token or token_file)')\n",
    "\n",
    "API_VERSION = str((selected or {}).get('api_version') or cfg.get('api_version') or 'v1.14')\n",
    "VERIFY_SSL = bool((selected or {}).get('verify_ssl', cfg.get('verify_ssl', True)))\n",
    "\n",
    "sanitized = target.replace('.', '_').replace(':', '_').replace('/', '_')\n",
    "output_dir = repo_root / f'output_{sanitized}'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Appliance     :', (selected or {}).get('name', '(single)'))\n",
    "print('Base URL      :', BASE_URL)\n",
    "print('API Version   :', API_VERSION)\n",
    "print('Verify SSL    :', VERIFY_SSL)\n",
    "print('Output folder :', output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c776fcc1",
   "metadata": {},
   "source": [
    "## Session and helpers\n",
    "\n",
    "Create a session with Authorization header and helpers to call the Data API.\n",
    "- `api_url(path)` builds endpoint URLs\n",
    "- `normalize_results(raw)` flattens list/table responses\n",
    "- `post_search(query, limit=0)` executes TWQL with pagination when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bc5ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "auth_value = token if token.lower().startswith('bearer ') else f'Bearer {token}'\n",
    "session.headers.update({'Authorization': auth_value, 'Accept': 'application/json'})\n",
    "session.verify = VERIFY_SSL\n",
    "\n",
    "def api_url(path: str) -> str:\n",
    "    base = BASE_URL.rstrip('/') + f'/api/{API_VERSION}/'\n",
    "    return urljoin(base, path.lstrip('/'))\n",
    "\n",
    "def normalize_results(raw):\n",
    "    rows = []\n",
    "    if isinstance(raw, dict):\n",
    "        res = raw.get('results')\n",
    "        if isinstance(res, dict):\n",
    "            headers = res.get('headers') or res.get('columns')\n",
    "            rws = res.get('rows') or res.get('data')\n",
    "            if isinstance(headers, list) and isinstance(rws, list):\n",
    "                return [dict(zip(headers, r)) for r in rws]\n",
    "        if isinstance(res, list):\n",
    "            rows = res\n",
    "        elif isinstance(raw, list):\n",
    "            rows = raw\n",
    "        else:\n",
    "            rows = []\n",
    "    elif isinstance(raw, list):\n",
    "        rows = raw\n",
    "    else:\n",
    "        rows = []\n",
    "    if rows and isinstance(rows[0], list):\n",
    "        headers = rows[0]\n",
    "        return [dict(zip(headers, r)) for r in rows[1:]]\n",
    "    return rows\n",
    "\n",
    "def post_search(query: str, *, limit: int | None = None, page_size: int = 500):\n",
    "    url = api_url('data/search')\n",
    "    rows_all = []\n",
    "    offset = 0\n",
    "    fetch_all = (limit == 0)\n",
    "    while True:\n",
    "        payload = {'query': query, 'format': 'object'}\n",
    "        if fetch_all:\n",
    "            payload['limit'] = page_size\n",
    "            if offset:\n",
    "                payload['offset'] = offset\n",
    "        elif limit is not None:\n",
    "            payload['limit'] = limit\n",
    "        r = session.post(url, json=payload)\n",
    "        if r.status_code >= 400:\n",
    "            print(f'Error {r.status_code} POST {url}: {r.text[:200]}')\n",
    "            try:\n",
    "                data = r.json()\n",
    "            except Exception:\n",
    "                data = []\n",
    "            return normalize_results(data)\n",
    "        try:\n",
    "            data = r.json()\n",
    "        except Exception:\n",
    "            data = []\n",
    "        rows = normalize_results(data)\n",
    "        if not fetch_all:\n",
    "            return rows\n",
    "        rows_all.extend(rows)\n",
    "        if not rows or len(rows) < page_size:\n",
    "            break\n",
    "        offset += page_size\n",
    "    return rows_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b896275d",
   "metadata": {},
   "source": [
    "## TWQL for Database Lifecycle\n",
    "\n",
    "This query mirrors DisMALâ€™s `queries.db_lifecycle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6bce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry_db_lifecycle = '''\n",
    "search Pattern\n",
    "where 'Relational Database Management Systems' in categories\n",
    "traverse Pattern:Maintainer:Element:SoftwareInstance\n",
    "    where #ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.retirement_date\n",
    "       or #ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_support_date\n",
    "       or #ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_ext_support_date\n",
    "show\n",
    "    type as \"SoftwareInstance.type\",\n",
    "    product_version as \"SoftwareInstance.product_version\",\n",
    "    (#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.retirement_date\n",
    "        and formatTime(#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.retirement_date, '%Y-%m-%d')) as 'End of Life',\n",
    "    (#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_support_date\n",
    "        and formatTime(#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_support_date, '%Y-%m-%d')) as 'End of Support',\n",
    "    (#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_ext_support_date\n",
    "        and formatTime(#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_ext_support_date, '%Y-%m-%d')) as 'End of Ext Support',\n",
    "    (#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_ext_support_date\n",
    "        and (#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_ext_support_date < currentTime() and 'EOES Exceeded')\n",
    "        or #ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_support_date\n",
    "            and (#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_support_date < currentTime() and 'EOS Exceeded')\n",
    "            or #ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.retirement_date\n",
    "                and (#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.retirement_date < currentTime() and 'EOL Exceeded')\n",
    "                or (#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.retirement_date and (#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.retirement_date < currentTime() + 182 * 864000000000 and 'EOL less than 6 months away')\n",
    "                    or #ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_support_date and (#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_support_date < currentTime() + 182 * 864000000000 and 'EOS less than 6 months away')\n",
    "                    or #ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_ext_support_date and (#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_ext_support_date < currentTime() + 182 * 864000000000 and 'EOES less than 6 months away'))\n",
    "                or (#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.retirement_date and 'EOL more than 6 months away'\n",
    "                    or #ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_support_date and 'EOS more than 6 months away'\n",
    "                    or #ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_ext_support_date and 'EOES more than 6 months away')) as 'Lifecycle Risk'\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4af0da8",
   "metadata": {},
   "source": [
    "## Execute query and load into pandas\n",
    "\n",
    "We request all rows (limit=0) with pagination and build a DataFrame.\n",
    "Columns are ordered to match DisMALâ€™s CSV header behavior (sorted keys)\n",
    "with 'Discovery Instance' inserted as the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a08212",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry_results = post_search(qry_db_lifecycle, limit=0)\n",
    "if not isinstance(qry_results, list):\n",
    "    qry_results = []\n",
    "\n",
    "#print(qry_results)\n",
    "\n",
    "df = pd.DataFrame(qry_results[0][\"results\"], columns=qry_results[0][\"headings\"])\n",
    "display(df.head(10))\n",
    "\n",
    "df.insert(0, 'Discovery Instance', target)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f92441",
   "metadata": {},
   "source": [
    "## Save to CSV\n",
    "\n",
    "Writes the CSV to the standard CLI output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1d2af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CSV = str(output_dir / 'db_lifecycle.csv')\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f'Saved to {OUTPUT_CSV}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94a519-1f44-4cad-8b2c-b2b330a468ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
