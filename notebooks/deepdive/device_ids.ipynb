{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "645dff05",
   "metadata": {},
   "source": [
    "# Device Identities (device_ids)\n",
    "\n",
    "Fetch device identity rows from BMC Discovery using the Tideway SDK (bulk search), build unique identities per originating endpoint, and save CSV to the standard DisMAL output folder.\n",
    "\n",
    "> **NOTE:** Due to limitations of the API, this may take a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55208880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q pandas pyyaml\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import json, os\n",
    "import sys\n",
    "try:\n",
    "    import tideway\n",
    "except ImportError:\n",
    "    print('The tideway SDK must be available in this environment.')\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6827aa",
   "metadata": {},
   "source": [
    "## Appliance selection (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be80b6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "APPLIANCE_NAME = None   # e.g., 'prod' or 'dev'\n",
    "APPLIANCE_INDEX = 1     # numeric index if not using name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6241b8a1",
   "metadata": {},
   "source": [
    "## Optional filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabff28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_NAME_FILTER = None  # e.g., 'host-name'\n",
    "INCLUDE_ENDPOINTS = []     # e.g., ['10.1.2.3']\n",
    "ENDPOINT_PREFIX = None     # e.g., '10.1.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa4ae64",
   "metadata": {},
   "source": [
    "## Load configuration and prepare Tideway appliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d53710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_repo_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / 'config.yaml').exists():\n",
    "            return p\n",
    "    return start.parent\n",
    "\n",
    "repo_root = _find_repo_root(Path.cwd())\n",
    "cfg_path = repo_root / 'config.yaml'\n",
    "cfg = yaml.safe_load(cfg_path.read_text()) or {}\n",
    "apps = cfg.get('appliances') or []\n",
    "selected = None\n",
    "if isinstance(apps, list) and apps:\n",
    "    if APPLIANCE_NAME:\n",
    "        selected = next((a for a in apps if a.get('name') == APPLIANCE_NAME), None)\n",
    "        if selected is None:\n",
    "            raise ValueError(f\"No appliance named '{APPLIANCE_NAME}' in config.yaml\")\n",
    "    else:\n",
    "        try:\n",
    "            selected = apps[int(APPLIANCE_INDEX)]\n",
    "        except Exception:\n",
    "            selected = apps[0]\n",
    "\n",
    "target = ((selected or {}).get('target') or cfg.get('target') or '').strip()\n",
    "if not target:\n",
    "    raise ValueError('config.yaml missing \\\"target\\\"')\n",
    "token = (((selected or {}).get('token') or cfg.get('token') or '').strip())\n",
    "token_file = (selected or {}).get('token_file') or cfg.get('token_file') or cfg.get('f_token')\n",
    "if not token and token_file:\n",
    "    tf = Path(token_file)\n",
    "    if not tf.is_absolute():\n",
    "        tf = repo_root / tf\n",
    "    token = tf.read_text().strip()\n",
    "if not token:\n",
    "    raise ValueError('API token not found in config.yaml (token or token_file)')\n",
    "\n",
    "# Create an appliance and detect API version\n",
    "app = tideway.appliance(target, token)\n",
    "about = app.about()\n",
    "if not getattr(about, 'ok', True):\n",
    "    print('About call failed:', getattr(about, 'status_code', 'unknown'))\n",
    "apivers = None\n",
    "try:\n",
    "    apivers = about.json().get('api_versions', [])\n",
    "except Exception:\n",
    "    apivers = []\n",
    "if apivers:\n",
    "    app = tideway.appliance(target, token, api_version=apivers[-1])\n",
    "\n",
    "data_ep = app.data()\n",
    "print('Connected to', target, 'API version', app.api_version if hasattr(app, 'api_version') else 'unknown')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2c0f03",
   "metadata": {},
   "source": [
    "## Query with Tideway (bulk search) and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1e92a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry_device_ids = (\n",
    "    \"\"\"\n",
    "search DiscoveryAccess\n",
    "show\n",
    "#::InferredElement:.name as 'InferredElement.name',\n",
    "#::InferredElement:.hostname as 'InferredElement.hostname',\n",
    "#::InferredElement:.local_fqdn as 'InferredElement.local_fqdn',\n",
    "#::InferredElement:.sysname as 'InferredElement.sysname',\n",
    "endpoint as 'DiscoveryAccess.endpoint',\n",
    "#DiscoveryAccess:Endpoint:Endpoint:Endpoint.endpoint as 'Endpoint.endpoint',\n",
    "#DiscoveryAccess:DiscoveryAccessResult:DiscoveryResult:DiscoveredIPAddressList.#List:List:Member:DiscoveredIPAddress.ip_addr as 'DiscoveredIPAddress.ip_addr',\n",
    "#::InferredElement:.__all_ip_addrs as 'InferredElement.__all_ip_addrs',\n",
    "#::InferredElement:.#DeviceWithInterface:DeviceInterface:InterfaceOfDevice:NetworkInterface.ip_addr as 'NetworkInterface.ip_addr',\n",
    "#::InferredElement:.#DeviceWithInterface:DeviceInterface:InterfaceOfDevice:NetworkInterface.fqdns as 'NetworkInterface.fqdns'\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "payload = data_ep.search({'query': qry_device_ids}, format='object', limit=0)\n",
    "\n",
    "# Light normalisation only when needed\n",
    "if hasattr(payload, 'json'):\n",
    "    payload = payload.json()\n",
    "\n",
    "if isinstance(payload, dict):                 # dict with \"results\"\n",
    "    payload = payload.get('results', [])\n",
    "\n",
    "if payload and isinstance(payload[0], list):  # header-row table -> records\n",
    "    headers, *rows = payload\n",
    "    payload = [dict(zip(headers, r)) for r in rows]\n",
    "\n",
  "rows = pd.json_normalize(payload)               # flattens nested fields better than DataFrame\n",
  "# Preview normalized results (5 rows)\n",
  "display(rows.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0c1581",
   "metadata": {},
   "source": [
    "## Filtering and identity build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678019f6-c67a-40d7-965a-4c875591b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter, select, and aggregate using pandas only (no custom helpers)\n",
    "\n",
    "# Build a working DataFrame reference\n",
    "df = rows.copy()\n",
    "# Show the initial working frame (5 rows)\n",
    "display(df.head(5))\n",
    "\n",
    "# Columns that may contain device names and IP addresses\n",
    "names_cols = ['InferredElement.name','InferredElement.hostname','InferredElement.local_fqdn','InferredElement.sysname','NetworkInterface.fqdns']\n",
    "ips_cols = ['DiscoveryAccess.endpoint','Endpoint.endpoint','DiscoveredIPAddress.ip_addr','InferredElement.__all_ip_addrs','NetworkInterface.ip_addr']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
  "id": "abf28a48-1032-4ccf-9ab7-70c1bedc7a13",
  "metadata": {},
  "outputs": [],
  "source": [
    "# Optional filter by device name substring (case-insensitive)\n",
    "# Ensure expected columns exist to avoid KeyError when absent\n",
    "for col in set(names_cols + ips_cols + ['DiscoveryAccess.endpoint']):\n",
    "    if col not in df.columns:\n",
    "        df[col] = pd.NA\n",
    "# Apply optional name filter across known name columns\n",
    "if DEVICE_NAME_FILTER:\n",
    "    needle = str(DEVICE_NAME_FILTER).lower()\n",
    "    name_mask = False\n",
    "    for col in names_cols:\n",
    "        # Convert values (including list-like) to string then search\n",
    "        col_str = df[col].astype(str).str.lower()\n",
    "        name_mask = name_mask | col_str.str.contains(needle, na=False)\n",
    "    df = df[name_mask]\n",
    "# Show the frame after name filter (5 rows)\n",
    "display(df.head(5))\n"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
  "id": "29f5d030-4b38-4613-8d48-bd73b1bfe6bc",
  "metadata": {},
  "outputs": [],
  "source": [
    "# Optional filters to restrict endpoints in scope\n",
    "ep_col = 'DiscoveryAccess.endpoint'\n",
    "if INCLUDE_ENDPOINTS:\n",
    "    df = df[df[ep_col].isin(INCLUDE_ENDPOINTS)]\n",
    "elif ENDPOINT_PREFIX:\n",
    "    df = df[df[ep_col].astype(str).str.startswith(str(ENDPOINT_PREFIX))]\n",
    "# Show the frame after endpoint filter (5 rows)\n",
    "print(f'Rows after filters: {len(df)}')\n",
    "display(df.head(5))\n"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
  "id": "3647d26f-0baa-4100-b09a-ddaeac1dd0f7",
  "metadata": {},
  "outputs": [],
  "source": [
    "# Build per-row lists of IPs and Names across their source columns\n",
    "df['ips_all'] = df.apply(lambda r: [x for col in ips_cols for x in (r[col] if isinstance(r[col], list) else ([] if pd.isna(r[col]) else [r[col]]))], axis=1)\n",
    "df['names_all'] = df.apply(lambda r: [x for col in names_cols for x in (r[col] if isinstance(r[col], list) else ([] if pd.isna(r[col]) else [r[col]]))], axis=1)\n",
    "# Preview the constructed list columns (5 rows)\n",
    "display(df[['ips_all','names_all']].head(5))\n"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
  "id": "e4af0b76-55b7-44e9-a01b-c528371e2494",
  "metadata": {},
  "outputs": [],
  "source": [
    "# Flatten lists and aggregate per endpoint using explode (handles nested lists)\n",
    "# We explode twice to cover list-of-lists cases commonly returned by the API\n",
    "df_ips = df[[ep_col, 'ips_all']].explode('ips_all').explode('ips_all')\n",
    "# Preview exploded IP rows (5 rows)\n",
    "display(df_ips.head(5))\n",
    "df_ips = df_ips[df_ips['ips_all'].notna()]\n",
    "ips_agg = df_ips.groupby(ep_col, dropna=True)['ips_all'].agg(lambda s: sorted(pd.unique(s.astype(str))))\n",
    "\n",
    "df_names = df[[ep_col, 'names_all']].explode('names_all').explode('names_all')\n",
    "# Preview exploded Name rows (5 rows)\n",
    "display(df_names.head(5))\n",
    "df_names = df_names[df_names['names_all'].notna()]\n",
    "names_agg = df_names.groupby(ep_col, dropna=True)['names_all'].agg(lambda s: sorted(pd.unique(s.astype(str))))\n",
    "\n",
    "agg_df = pd.concat([ips_agg, names_agg], axis=1).reset_index()\n",
    "# Preview aggregated result (5 rows)\n",
    "display(agg_df.head(5))\n"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
  "id": "2310c106-4e9b-4cd9-9bd1-92b665fc7fcc",
  "metadata": {},
  "outputs": [],
  "source": [
    "# Shape final output and preview\n",
    "out_df = agg_df.rename(columns={\n",
    "    'ips_all': 'List of IPs',\n",
    "    'names_all': 'List of Names'\n",
    "})\n",
    "out_df.insert(0, 'Discovery Instance', target)\n",
    "display(out_df.head(5))\n"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
  "id": "9c4909b7",
  "metadata": {},
  "outputs": [],
  "source": [
    "# Export\n",
    "csv_path = repo_root / f\"output_{target.replace('.', '_')}\" / 'device_ids.csv'\n",
    "csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "out_df.to_csv(csv_path, index=False)\n",
    "print('Saved to', csv_path)\n"
  ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
