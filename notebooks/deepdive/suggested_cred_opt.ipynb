{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Suggested Credential Optimization (BMC Discovery)\n",
    "\n",
    "Replicates the DisMAL `suggested_cred_opt` report by ranking vault credentials\n",
    "based on scope, ranges/exclusions, type, key/version hints, and recent success/failure.\n",
    "Outputs `suggested_cred_opt.csv` under `output_<target>`.\n",
    "\n",
    "> **NOTE:** This can take a while to run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reqs",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "We use `tideway` (SDK) for credentials, plus `requests`, `pandas`, and `PyYAML`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q tideway requests pandas pyyaml\n",
    "\n",
    "import os, sys, subprocess\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Tuple\n",
    "import pandas as pd\n",
    "import requests\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "select",
   "metadata": {},
   "source": [
    "## Select Appliance (optional)\n",
    "Set `APPLIANCE_NAME` or `APPLIANCE_INDEX` when `config.yaml` lists multiple appliances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appliance-vars",
   "metadata": {},
   "outputs": [],
   "source": [
    "APPLIANCE_NAME = None\n",
    "APPLIANCE_INDEX = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-md",
   "metadata": {},
   "source": [
    "## Configuration (from config.yaml)\n",
    "Locates repo root, reads target/token, initialises Tideway appliance, and prepares output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_repo_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / 'config.yaml').exists():\n",
    "            return p\n",
    "    return start.parent\n",
    "\n",
    "repo_root = _find_repo_root(Path.cwd())\n",
    "cfg = yaml.safe_load(open(repo_root / 'config.yaml', 'r')) or {}\n",
    "apps = cfg.get('appliances') or []\n",
    "selected = None\n",
    "if isinstance(apps, list) and apps:\n",
    "    if APPLIANCE_NAME:\n",
    "        selected = next((a for a in apps if a.get('name') == APPLIANCE_NAME), None)\n",
    "        if selected is None:\n",
    "            raise ValueError(f\"No appliance named '{APPLIANCE_NAME}' in config.yaml\")\n",
    "    else:\n",
    "        try:\n",
    "            selected = apps[int(APPLIANCE_INDEX)]\n",
    "        except Exception:\n",
    "            selected = apps[0]\n",
    "target = ((selected or {}).get('target') or cfg.get('target') or '').strip()\n",
    "if not target:\n",
    "    raise ValueError('config.yaml missing \"target\"')\n",
    "token = (((selected or {}).get('token') or cfg.get('token') or '').strip())\n",
    "token_file = (selected or {}).get('token_file') or cfg.get('token_file') or cfg.get('f_token')\n",
    "if not token and token_file:\n",
    "    tf_path = Path(token_file)\n",
    "    if not tf_path.is_absolute():\n",
    "        tf_path = repo_root / tf_path\n",
    "    token = open(tf_path, 'r').read().strip()\n",
    "if not token:\n",
    "    raise ValueError('API token not found in config.yaml (token or token_file)')\n",
    "API_VERSION = str((selected or {}).get('api_version') or cfg.get('api_version') or 'v1.14')\n",
    "VERIFY_SSL = bool((selected or {}).get('verify_ssl', cfg.get('verify_ssl', True)))\n",
    "sanitized = target.replace('.', '_').replace(':', '_').replace('/', '_')\n",
    "output_dir = repo_root / f'output_{sanitized}'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Tideway SDK\n",
    "try:\n",
    "    import tideway  # type: ignore\n",
    "except Exception:\n",
    "    print('Installing tideway via pip...')\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'tideway'])\n",
    "    import tideway  # retry\n",
    "\n",
    "API_VERSION_NUM = API_VERSION.lstrip('v')\n",
    "app = tideway.appliance(target, token, api_version=API_VERSION_NUM, ssl_verify=VERIFY_SSL)\n",
    "twsearch = app.data()\n",
    "twcreds = app.credentials()\n",
    "\n",
    "# Requests session for Data API + Outposts\n",
    "session = requests.Session()\n",
    "auth_value = token if token.lower().startswith('bearer ') else f'Bearer {token}'\n",
    "session.headers.update({'Authorization': auth_value, 'Accept': 'application/json'})\n",
    "session.verify = VERIFY_SSL\n",
    "BASE_URL = target if ('://' in target) else f'https://{target}'\n",
    "\n",
    "print('Base Host      :', target)\n",
    "print('API Version    :', API_VERSION)\n",
    "print('Verify SSL     :', VERIFY_SSL)\n",
    "print('Output folder  :', output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpers-md",
   "metadata": {},
   "source": [
    "## Helpers\n",
    "Unified post_search for TWQL, token parsing helpers, outpost mapping, and weighting rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpers",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urljoin\n",
    "\n",
    "def api_url(path: str) -> str:\n",
    "    base = BASE_URL.rstrip('/') + f'/api/{API_VERSION}/'\n",
    "    return urljoin(base, path.lstrip('/'))\n",
    "\n",
    "def post_search(query: str, *, limit: int | None = None, page_size: int = 500):\n",
    "    url = api_url('data/search')\n",
    "    headings = None\n",
    "    results = []\n",
    "    offset = 0\n",
    "    fetch_all = (limit == 0)\n",
    "    while True:\n",
    "        payload = {'query': query, 'format': 'object'}\n",
    "        if fetch_all:\n",
    "            payload['limit'] = page_size\n",
    "            if offset:\n",
    "                payload['offset'] = offset\n",
    "        elif limit is not None:\n",
    "            payload['limit'] = limit\n",
    "        r = session.post(url, json=payload)\n",
    "        if r.status_code >= 400:\n",
    "            print(f'Error {r.status_code} POST {url}: {r.text[:200]}')\n",
    "            return {'headings': [], 'results': []}\n",
    "        data = {}\n",
    "        try:\n",
    "            data = r.json()\n",
    "        except Exception:\n",
    "            data = {}\n",
    "        table = None\n",
    "        if isinstance(data, list):\n",
    "            for x in data:\n",
    "                if isinstance(x, dict) and 'headings' in x and 'results' in x:\n",
    "                    table = x; break\n",
    "        elif isinstance(data, dict) and 'headings' in data and 'results' in data:\n",
    "            table = data\n",
    "        if not table:\n",
    "            return {'headings': [], 'results': []}\n",
    "        if headings is None:\n",
    "            headings = table.get('headings', [])\n",
    "        rows = table.get('results') or []\n",
    "        results.extend(rows)\n",
    "        if not fetch_all or len(rows) < page_size:\n",
    "            break\n",
    "        offset += page_size\n",
    "    return {'headings': (headings or []), 'results': results}\n",
    "\n",
    "def get_vault_credentials() -> List[Dict[str, Any]]:\n",
    "    ep = twcreds.get_vault_credentials\n",
    "    try:\n",
    "        resp = ep() if callable(ep) else ep\n",
    "    except Exception:\n",
    "        resp = ep\n",
    "    try:\n",
    "        return resp.json() if hasattr(resp, 'json') else (resp or [])\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "def outpost_url_map() -> Dict[str, str]:\n",
    "    # Build uuid -> outpost URL using data query + outposts endpoint\n",
    "    tbl = post_search(\"search SessionResult show credential, credential as 'uuid', outpost process with unique(0)\", limit=0)\n",
    "    heads = tbl.get('headings', [])\n",
    "    rows = tbl.get('results', [])\n",
    "    col_uuid = heads.index('uuid') if 'uuid' in heads else None\n",
    "    col_outpost = heads.index('outpost') if 'outpost' in heads else None\n",
    "    uuid_to_opid = {}\n",
    "    if col_uuid is not None and col_outpost is not None:\n",
    "        for r in rows:\n",
    "            try:\n",
    "                uuid_to_opid[str(r[col_uuid])] = str(r[col_outpost])\n",
    "            except Exception:\n",
    "                pass\n",
    "    # Get outposts list\n",
    "    url = api_url('discovery/outposts?deleted=false')\n",
    "    try:\n",
    "        r = session.get(url)\n",
    "        ops = r.json() if r.ok else []\n",
    "    except Exception:\n",
    "        ops = []\n",
    "    id_to_url = {}\n",
    "    for op in (ops or []):\n",
    "        if not isinstance(op, dict):\n",
    "            continue\n",
    "        op_id = op.get('id') or op.get('outpost') or op.get('outpost_id') or op.get('uuid')\n",
    "        url = op.get('url')\n",
    "        if op_id and url:\n",
    "            id_to_url[str(op_id)] = url\n",
    "    return {u: id_to_url.get(opid) for u, opid in uuid_to_opid.items()}\n",
    "\n",
    "def _tokens_from_value(value) -> List[str]:\n",
    "    if isinstance(value, list):\n",
    "        tokens = []\n",
    "        for v in value:\n",
    "            if isinstance(v, str):\n",
    "                tokens.extend([x.strip() for x in v.split(',') if x.strip()])\n",
    "    elif isinstance(value, str):\n",
    "        tokens = [x.strip() for x in value.split(',') if x.strip()]\n",
    "    else:\n",
    "        tokens = []\n",
    "    return tokens\n",
    "\n",
    "def compute_weight(cred: Dict[str, Any]) -> int:\n",
    "    w = 100\n",
    "    label = cred.get('label')\n",
    "    # IP range\n",
    "    ip_tokens = _tokens_from_value(cred.get('ip_range'))\n",
    "    for t in ip_tokens:\n",
    "        if t in ('0.0.0.0/0', '::/0', '0.0.0.0/0,::/0'):\n",
    "            w = 4294967296\n",
    "        else:\n",
    "            w += 1\n",
    "    # Exclusions\n",
    "    ex_tokens = _tokens_from_value(cred.get('ip_exclusion'))\n",
    "    for t in ex_tokens:\n",
    "        if t in ('0.0.0.0/0', '::/0', '0.0.0.0/0,::/0'):\n",
    "            w = -4294967296\n",
    "        else:\n",
    "            w -= 1\n",
    "    # Types\n",
    "    for t in (cred.get('types') or []):\n",
    "        if t in ('aws','openstack','azure','web_basic','google'):\n",
    "            w += 1\n",
    "        elif t in ('ssh','powershell'):\n",
    "            w += 2\n",
    "        elif t == 'windows':\n",
    "            w += 3\n",
    "        elif t in ('vsphere','vcenter'):\n",
    "            w += 4\n",
    "        elif t == 'snmp':\n",
    "            w += 5\n",
    "        else:\n",
    "            w += 6\n",
    "    # Hints\n",
    "    if cred.get('ssh.key.set'):\n",
    "        w -= 1\n",
    "    if cred.get('snmp.version') == 'v3':\n",
    "        w -= 1\n",
    "    scopes = cred.get('scopes') or []\n",
    "    if isinstance(scopes, list) and len(scopes) > 0:\n",
    "        w -= 1\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "build-md",
   "metadata": {},
   "source": [
    "## Build suggested order and save\n",
    "Computes weights, factors in recent success/failure, assigns new indices, and writes CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build",
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = get_vault_credentials()\n",
    "op_map = outpost_url_map()\n",
    "rows = []\n",
    "weighted = []\n",
    "# Precompute base weight per credential\n",
    "for c in (creds or []):\n",
    "    try:\n",
    "        base_w = compute_weight(c)\n",
    "        weighted.append({'uuid': c.get('uuid'), 'label': c.get('label'), 'current_index': c.get('index'), 'weight': base_w, 'scopes': c.get('scopes') or []})\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "# Adjust weights by recent success/failure via Data API\n",
    "for w in weighted:\n",
    "    u = w['uuid']\n",
    "    if not u:\n",
    "        continue\n",
    "    # Successful sessions\n",
    "    q1 = f\"search SessionResult where success and (slave = '{u}' or credential = '{u}') show (credential or slave) as cred_uuid, session_type\"\n",
    "    t1 = post_search(q1, limit=0)\n",
    "    if t1.get('results'):\n",
    "        w['weight'] -= len(t1['results'])\n",
    "    # Successful deviceinfo (without session results)\n",
    "    q2 = f\"search DeviceInfo where method_success and (slave = '{u}' or credential = '{u}') and nodecount(traverse DiscoveryResult:DiscoveryAccessResult:DiscoveryAccess:DiscoveryAccess traverse DiscoveryAccess:Metadata:Detail:SessionResult) = 0 show (last_credential or last_slave) as cred_uuid, access_method as 'session_type'\"\n",
    "    t2 = post_search(q2, limit=0)\n",
    "    if t2.get('results'):\n",
    "        w['weight'] -= len(t2['results'])\n",
    "    # Failures\n",
    "    q3 = f\"search SessionResult where not success and (slave = '{u}' or credential = '{u}') show (credential or slave) as cred_uuid, session_type\"\n",
    "    t3 = post_search(q3, limit=0)\n",
    "    if t3.get('results'):\n",
    "        w['weight'] += len(t3['results'])\n",
    "\n",
    "# Sort and assign new indices\n",
    "weighted.sort(key=lambda x: x['weight'])\n",
    "for i, w in enumerate(weighted):\n",
    "    w['new_index'] = i\n",
    "\n",
    "# Build output rows\n",
    "for c in creds or []:\n",
    "    u = c.get('uuid')\n",
    "    w = next((x for x in weighted if x['uuid'] == u), None)\n",
    "    if not w:\n",
    "        continue\n",
    "    scope = c.get('scopes') or []\n",
    "    if isinstance(scope, list):\n",
    "        scope = ', '.join(scope)\n",
    "    url = op_map.get(str(u))\n",
    "    rows.append([c.get('label'), c.get('index'), w.get('weight'), w.get('new_index'), scope, url])\n",
    "\n",
    "headers = ['Discovery Instance','Credential','Current Index','Weighting','New Index','Scope','Outpost URL']\n",
    "df = pd.DataFrame(rows, columns=headers[1:])\n",
    "df.insert(0, 'Discovery Instance', target)\n",
    "display(df.head(20)) if not df.empty else print('No rows to display')\n",
    "\n",
    "OUT_CSV = str(output_dir / 'suggested_cred_opt.csv')\n",
    "df.to_csv(OUT_CSV, index=False)\n",
    "print(f'Saved to {OUT_CSV} (rows: {len(df)})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "footer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
