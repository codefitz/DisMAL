{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-title",
   "metadata": {},
   "source": [
    "# Devices Report (BMC Discovery)\n",
    "\n",
    "This notebook reproduces the DisMAL `devices` report using the Tideway Python library to run Discovery Data API searches.\n",
    "It reads connection details from `config.yaml`, supports an optional `devices_with_cred` filter,\n",
    "and writes a CSV under the standard `output_<target>` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requirements",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "We use `tideway` (local package in this repo or PyPI), `pandas`, and `PyYAML`.\n",
    "Uncomment the following to install in your environment if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q tideway pandas pyyaml\n",
    "\n",
    "import os, sys, json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from typing import Any, Dict, List\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "select-appliance",
   "metadata": {},
   "source": [
    "## Select Appliance (optional)\n",
    "\n",
    "If your `config.yaml` defines multiple appliances under the `appliances:` list,\n",
    "set `APPLIANCE_NAME` to one of their names (e.g., 'prod' or 'dev') or use the index.\n",
    "Defaults to the first appliance if neither is set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appliance-vars",
   "metadata": {},
   "outputs": [],
   "source": [
    "APPLIANCE_NAME = None   # e.g., 'prod' or 'dev'\n",
    "APPLIANCE_INDEX = 0     # integer index if not using name selection\n",
    "\n",
    "# Optional filter: if set to a credential UUID, runs devices_with_cred flow\n",
    "DEVICES_WITH_CRED_UUID = None  # e.g., '7636fe3b4bd69466ab487f0000010700'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-load",
   "metadata": {},
   "source": [
    "## Configuration (from config.yaml)\n",
    "\n",
    "Reads settings from `../config.yaml` including target, token/token_file,\n",
    "API version, and SSL verification preference.\n",
    "Saves the CSV to `../output_<target>/devices.csv` (or `devices_with_cred.csv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_repo_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / 'config.yaml').exists():\n",
    "            return p\n",
    "    return start.parent\n",
    "\n",
    "repo_root = _find_repo_root(Path.cwd())\n",
    "config_path = repo_root / 'config.yaml'\n",
    "with open(config_path, 'r') as fh:\n",
    "    cfg = yaml.safe_load(fh) or {}\n",
    "\n",
    "# Appliance selection\n",
    "apps = cfg.get('appliances') or []\n",
    "selected = None\n",
    "if isinstance(apps, list) and apps:\n",
    "    if APPLIANCE_NAME:\n",
    "        selected = next((a for a in apps if a.get('name') == APPLIANCE_NAME), None)\n",
    "        if selected is None:\n",
    "            raise ValueError(f\"No appliance named '{APPLIANCE_NAME}' in config.yaml\")\n",
    "    else:\n",
    "        try:\n",
    "            selected = apps[int(APPLIANCE_INDEX)]\n",
    "        except Exception:\n",
    "            selected = apps[0]\n",
    "\n",
    "target = ((selected or {}).get('target') or cfg.get('target') or '').strip()\n",
    "if not target:\n",
    "    raise ValueError('config.yaml missing \"target\"')\n",
    "\n",
    "# Token handling: inline token or token file\n",
    "token = (((selected or {}).get('token') or cfg.get('token') or '').strip())\n",
    "token_file = (selected or {}).get('token_file') or cfg.get('token_file') or cfg.get('f_token')\n",
    "if not token and token_file:\n",
    "    tf_path = Path(token_file)\n",
    "    if not tf_path.is_absolute():\n",
    "        tf_path = repo_root / tf_path\n",
    "    with open(tf_path, 'r') as tf:\n",
    "        token = tf.read().strip()\n",
    "if not token:\n",
    "    raise ValueError('API token not found in config.yaml (token or token_file)')\n",
    "\n",
    "# Version and SSL\n",
    "API_VERSION = str((selected or {}).get('api_version') or cfg.get('api_version') or 'v1.14')\n",
    "VERIFY_SSL = bool((selected or {}).get('verify_ssl', cfg.get('verify_ssl', True)))\n",
    "\n",
    "# Output path\n",
    "sanitized = target.replace('.', '_').replace(':', '_').replace('/', '_')\n",
    "output_dir = repo_root / f'output_{sanitized}'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Base Host      :', target)\n",
    "print('API Version    :', API_VERSION)\n",
    "print('Verify SSL     :', VERIFY_SSL)\n",
    "print('Output folder  :', output_dir)\n",
    "print('Token set      :', bool(token))\n",
    "\n",
    "# Prefer local Tideway package in this repo if available\n",
    "local_tideway = repo_root / 'Tideway'\n",
    "if local_tideway.exists():\n",
    "    sys.path.insert(0, str(local_tideway))\n",
    "\n",
    "import importlib\n",
    "tideway = importlib.import_module('tideway')\n",
    "\n",
    "API_VERSION_NUM = API_VERSION.lstrip('v')\n",
    "app = tideway.appliance(target, token, api_version=API_VERSION_NUM, ssl_verify=VERIFY_SSL)\n",
    "twsearch = app.data()\n",
    "twcreds = app.credentials()\n",
    "\n",
    "# Quick probe (optional)\n",
    "try:\n",
    "    about = app.api_about\n",
    "    print('Appliance reachable:', about.status_code)\n",
    "except Exception as e:\n",
    "    print('Warning: failed to contact appliance /api/about:', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpers",
   "metadata": {},
   "source": [
    "## Helpers (Tideway search, normalization, credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpers-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_table_to_json(table_like: List[List[Any]]) -> List[Dict[str, Any]]:\n",
    "    if not table_like or not isinstance(table_like, list):\n",
    "        return []\n",
    "    if not table_like or not isinstance(table_like[0], list):\n",
    "        return []\n",
    "    headers = table_like[0]\n",
    "    rows = table_like[1:]\n",
    "    out = []\n",
    "    for r in rows:\n",
    "        try:\n",
    "            out.append(dict(zip(headers, r)))\n",
    "        except Exception:\n",
    "            # length mismatch or malformed row; skip\n",
    "            continue\n",
    "    return out\n",
    "\n",
    "def to_rows(payload: Any) -> List[Dict[str, Any]]:\n",
    "    # Tideway bulk object format returns a list: [ [headers...], [row...], ... ]\n",
    "    if isinstance(payload, list):\n",
    "        if payload and isinstance(payload[0], list):\n",
    "            return list_table_to_json(payload)\n",
    "        # Already list of dicts\n",
    "        if payload and isinstance(payload[0], dict):\n",
    "            return payload\n",
    "        return []\n",
    "    if hasattr(payload, 'json'):\n",
    "        try:\n",
    "            js = payload.json()\n",
    "        except Exception:\n",
    "            return []\n",
    "        # Normalize same as above\n",
    "        if isinstance(js, list):\n",
    "            if js and isinstance(js[0], list):\n",
    "                return list_table_to_json(js)\n",
    "            if js and isinstance(js[0], dict):\n",
    "                return js\n",
    "        if isinstance(js, dict) and 'results' in js and 'headings' in js:\n",
    "            table_like = [js['headings']] + list(js.get('results') or [])\n",
    "            return list_table_to_json(table_like)\n",
    "        return []\n",
    "    if isinstance(payload, dict) and 'results' in payload and 'headings' in payload:\n",
    "        table_like = [payload['headings']] + list(payload.get('results') or [])\n",
    "        return list_table_to_json(table_like)\n",
    "    return []\n",
    "\n",
    "def tw_search_all(search, query: str, limit: int = 500) -> List[Dict[str, Any]]:\n",
    "    # Use format='object' so headings are included; bulk=True by default to collect all\n",
    "    resp = search.search({'query': query}, format='object', limit=limit)\n",
    "    return to_rows(resp)\n",
    "\n",
    "def get_json(resp_or_obj: Any) -> Any:\n",
    "    if hasattr(resp_or_obj, 'json'):\n",
    "        try:\n",
    "            return resp_or_obj.json()\n",
    "        except Exception:\n",
    "            return {}\n",
    "    return resp_or_obj\n",
    "\n",
    "def get_credential_map(twcreds_handle) -> Dict[str, Dict[str, Any]]:\n",
    "    resp = twcreds_handle.get_vault_credentials\n",
    "    items = get_json(resp) or []\n",
    "    mapping: Dict[str, Dict[str, Any]] = {}\n",
    "    if isinstance(items, list):\n",
    "        for c in items:\n",
    "            if not isinstance(c, dict):\n",
    "                continue\n",
    "            uuid = str(c.get('uuid') or '').split('/')[-1]\n",
    "            if not uuid:\n",
    "                continue\n",
    "            mapping[uuid] = {\n",
    "                'label': c.get('label'),\n",
    "                'username': c.get('username')\n",
    "                            or c.get('snmp.v3.securityname')\n",
    "                            or c.get('aws.access_key_id')\n",
    "                            or c.get('azure.application_id'),\n",
    "                'index': c.get('index'),\n",
    "            }\n",
    "    return mapping\n",
    "\n",
    "def flatten_list(value):\n",
    "    if value is None:\n",
    "        return []\n",
    "    if isinstance(value, list):\n",
    "        out = []\n",
    "        for v in value:\n",
    "            if isinstance(v, list):\n",
    "                out.extend(v)\n",
    "            else:\n",
    "                out.append(v)\n",
    "        return out\n",
    "    return [value]\n",
    "\n",
    "def pick_latest(rows: List[Dict[str, Any]], key: str) -> Dict[str, Any]:\n",
    "    def _key(r):\n",
    "        v = r.get(key)\n",
    "        try:\n",
    "            return int(v) if v is not None else -1\n",
    "        except Exception:\n",
    "            return -1\n",
    "    return max(rows, key=_key) if rows else {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "queries",
   "metadata": {},
   "source": [
    "## Queries\n",
    "\n",
    "These TWQL queries mirror the DisMAL devices flow and the optional devices_with_cred lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "queries-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trimmed last discovery access view with key fields needed for devices summary\n",
    "qry_last_disco = '''\n",
    "search DiscoveryAccess where endtime\n",
    "ORDER BY discovery_endtime DESC\n",
    "show\n",
    "endpoint as 'DiscoveryAccess.endpoint',\n",
    "#DiscoveryAccess:DiscoveryAccessResult:DiscoveryResult:DeviceInfo.hostname as 'DeviceInfo.hostname',\n",
    "#Member:List:List:DiscoveryRun.label as 'DiscoveryRun.label',\n",
    "friendlyTime(discovery_starttime) as 'DiscoveryAccess.scan_starttime',\n",
    "friendlyTime(discovery_endtime) as 'DiscoveryAccess.scan_endtime',\n",
    "discovery_endtime as 'DiscoveryAccess.scan_endtime_raw',\n",
    "whenWasThat(discovery_endtime) as 'DiscoveryAccess.when_last_scan',\n",
    "(#DiscoveryAccess:DiscoveryAccessResult:DiscoveryResult:DeviceInfo.last_access_method in ['windows', 'rcmd']\n",
    "    and #DiscoveryAccess:DiscoveryAccessResult:DiscoveryResult:DeviceInfo.last_slave\n",
    "        or #DiscoveryAccess:DiscoveryAccessResult:DiscoveryResult:DeviceInfo.probed_os and 'Probe'\n",
    "            or #DiscoveryAccess:DiscoveryAccessResult:DiscoveryResult:DeviceInfo.last_access_method) as 'DiscoveryAccess.current_access',\n",
    "(kind(#Associate:Inference:InferredElement:)\n",
    "    or inferred_kind\n",
    "        or #DiscoveryAccess:DiscoveryAccessResult:DiscoveryResult:DeviceInfo.kind) as 'DiscoveryAccess.node_kind',\n",
    "(#DiscoveryAccess:Metadata:Detail:SessionResult.credential and success\n",
    "    or #DiscoveryAccess:DiscoveryAccessResult:DiscoveryResult:DeviceInfo.last_credential\n",
    "    or #DiscoveryAccess:DiscoveryAccessResult:DiscoveryResult:DeviceInfo.last_slave\n",
    "    or #DiscoveryAccess:DiscoveryAccessResult:DiscoveryResult:DeviceInfo.__preserved_last_credential) as 'DeviceInfo.last_credential',\n",
    "#DiscoveryAccess:DiscoveryAccessResult:DiscoveryResult:DeviceInfo.os_version as 'DeviceInfo.os_version',\n",
    "(nodecount(traverse DiscoveryAccess:DiscoveryAccessResult:DiscoveryResult:DeviceInfo\n",
    "  traverse flags(include_destroyed) Primary:Inference:InferredElement: where not destroyed(#)) > 0) as 'DiscoveryAccess.host_node_updated',\n",
    "end_state as 'DiscoveryAccess.end_state',\n",
    "result as 'DiscoveryAccess.result'\n",
    "'''\n",
    "\n",
    "# devices_with_cred flow\n",
    "qry_sessions_for_cred = lambda uuid: f\"\"\"\n",
    "search SessionResult where credential = '{uuid}'\n",
    "show\n",
    "(#Detail:Metadata:DiscoveryAccess:DiscoveryAccess.#Associate:Inference:InferredElement:.name\n",
    "  or #Detail:Metadata:DiscoveryAccess:DiscoveryAccess.#DiscoveryAccess:DiscoveryAccessResult:DiscoveryResult:DeviceInfo.hostname) as 'device_name',\n",
    "(kind(#Detail:Metadata:DiscoveryAccess:DiscoveryAccess.#Associate:Inference:InferredElement:)\n",
    "  or #Detail:Metadata:DiscoveryAccess:DiscoveryAccess.inferred_kind\n",
    "  or #Detail:Metadata:DiscoveryAccess:DiscoveryAccess.#DiscoveryAccess:DiscoveryAccessResult:DiscoveryResult:DeviceInfo.kind) as 'inferred_node',\n",
    "#Detail:Metadata:DiscoveryAccess:DiscoveryAccess.endpoint as 'scanned_endpoint',\n",
    "credential as 'credential',\n",
    "success as 'success',\n",
    "message as 'message',\n",
    "friendlyTime(time_index) as 'date_time',\n",
    "#Detail:Metadata:DiscoveryAccess:DiscoveryAccess.#id as 'node_id'\n",
    "\"\"\"\n",
    "\n",
    "qry_di_for_cred = lambda uuid: f\"\"\"\n",
    "search DeviceInfo where last_credential = '{uuid}' or last_slave = '{uuid}' or __preserved_last_credential = '{uuid}'\n",
    "ORDER BY hostname\n",
    "show\n",
    "(hostname or sysname) as 'device_name',\n",
    "kind as 'inferred_node',\n",
    "#DiscoveryResult:DiscoveryAccessResult:DiscoveryResult:DiscoveryAccess.endpoint as 'scanned_endpoint',\n",
    "#DiscoveryResult:DiscoveryAccessResult:DiscoveryResult:DiscoveryAccess.#id as 'da_node_id',\n",
    "#DiscoveryResult:DiscoveryAccessResult:DiscoveryResult:DiscoveryAccess.reason as 'message',\n",
    "method_success as 'success',\n",
    "method_failure as 'failure',\n",
    "friendlyTime(request_time) as 'date_time'\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run-devices",
   "metadata": {},
   "source": [
    "## Run Report\n",
    "\n",
    "When `DEVICES_WITH_CRED_UUID` is set, runs the devices_with_cred flow; otherwise generates the consolidated devices report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup ---\n",
    "cred_map = get_credential_map(twcreds)\n",
    "\n",
    "print(\"\\n=== Setup ===\")\n",
    "print(f\"- Target: {target}\")\n",
    "print(f\"- Credentials loaded: {len(cred_map)}\")\n",
    "\n",
    "# Expect DEVICES_WITH_CRED_UUID to be defined (or None/\"\")\n",
    "cred_uuid = DEVICES_WITH_CRED_UUID if DEVICES_WITH_CRED_UUID else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2733b68-9cfa-4e31-8052-89cbf9598307",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Credential Filter ===\" if cred_uuid else \"\\n=== No Credential Filter ===\")\n",
    "if cred_uuid:\n",
    "    cred_detail_resp = twcreds.get_vault_credential(cred_uuid)\n",
    "    cred_detail = get_json(cred_detail_resp) or {}\n",
    "    print(f\"- Credential UUID: {cred_uuid}\")\n",
    "    print(f\"- Label: {cred_detail.get('label', cred_uuid)}\")\n",
    "    print(f\"- Index: {cred_detail.get('index')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f79ea2f-cf39-451b-8c31-2a12e5144cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Build Identities ===\")\n",
    "\n",
    "qry_device_ids = '''\n",
    "                    search DiscoveryAccess\n",
    "                    show\n",
    "                    #::InferredElement:.name as 'InferredElement.name',\n",
    "                    #::InferredElement:.hostname as 'InferredElement.hostname',\n",
    "                    #::InferredElement:.local_fqdn as 'InferredElement.local_fqdn',\n",
    "                    #::InferredElement:.sysname as 'InferredElement.sysname',\n",
    "                    endpoint as 'DiscoveryAccess.endpoint',\n",
    "                    #DiscoveryAccess:Endpoint:Endpoint:Endpoint.endpoint as 'Endpoint.endpoint',\n",
    "                    #DiscoveryAccess:DiscoveryAccessResult:DiscoveryResult:DiscoveredIPAddressList.#List:List:Member:DiscoveredIPAddress.ip_addr as 'DiscoveredIPAddress.ip_addr',\n",
    "                    #::InferredElement:.__all_ip_addrs as 'InferredElement.__all_ip_addrs',\n",
    "                    #::InferredElement:.#DeviceWithInterface:DeviceInterface:InterfaceOfDevice:NetworkInterface.ip_addr as 'NetworkInterface.ip_addr',\n",
    "                    #::InferredElement:.#DeviceWithInterface:DeviceInterface:InterfaceOfDevice:NetworkInterface.fqdns as 'NetworkInterface.fqdns'\n",
    "                    '''\n",
    "\n",
    "id_rows = tw_search_all(twsearch, qry_device_ids) or []\n",
    "print(f\"- Identity rows: {len(id_rows)}\")\n",
    "\n",
    "endpoint_map = {}  # ep -> {\"ips\": set(), \"names\": set()}\n",
    "ip_fields = [\n",
    "    'DiscoveryAccess.endpoint', 'Endpoint.endpoint',\n",
    "    'DiscoveredIPAddress.ip_addr', 'InferredElement.__all_ip_addrs',\n",
    "    'NetworkInterface.ip_addr'\n",
    "]\n",
    "name_fields = [\n",
    "    'InferredElement.name', 'InferredElement.hostname',\n",
    "    'InferredElement.local_fqdn', 'InferredElement.sysname',\n",
    "    'NetworkInterface.fqdns'\n",
    "]\n",
    "\n",
    "for rec in id_rows:\n",
    "    ep = rec.get('DiscoveryAccess.endpoint')\n",
    "    if not ep:\n",
    "        continue\n",
    "    data = endpoint_map.setdefault(ep, {'ips': set(), 'names': set()})\n",
    "    for f in ip_fields:\n",
    "        data['ips'].update([v for v in flatten_list(rec.get(f)) if v])\n",
    "    for f in name_fields:\n",
    "        data['names'].update([v for v in flatten_list(rec.get(f)) if v])\n",
    "\n",
    "identities = []\n",
    "for ep, sets in endpoint_map.items():\n",
    "    ips = sorted(set(sets['ips']))\n",
    "    names = sorted(set(sets['names']))\n",
    "    identities.append({'originating_endpoint': ep, 'list_of_ips': ips, 'list_of_names': names})\n",
    "\n",
    "print(f\"- Unique endpoints: {len(endpoint_map)}\")\n",
    "print(f\"- Identities: {len(identities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4598ee93-d53b-49ee-b4f7-7e6793366078",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Fetch Last Discovery Access (Filtered) ===\" if cred_uuid else \"\\n=== Fetch Last Discovery Access ===\")\n",
    "\n",
    "ld_rows = tw_search_all(twsearch, qry_last_disco) or []\n",
    "\n",
    "if cred_uuid:\n",
    "    want = str(cred_uuid).split('/')[-1].lower()\n",
    "    ld_rows = [\n",
    "        r for r in ld_rows\n",
    "        if r.get('DeviceInfo.last_credential')\n",
    "        and str(r.get('DeviceInfo.last_credential')).split('/')[-1].lower() == want\n",
    "    ]\n",
    "\n",
    "print(f\"- Last Discovery rows: {len(ld_rows)}\")\n",
    "\n",
    "by_ep = {}\n",
    "for r in ld_rows:\n",
    "    ep = r.get('DiscoveryAccess.endpoint')\n",
    "    if not ep:\n",
    "        continue\n",
    "    by_ep.setdefault(ep, []).append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48de3ecf-4720-42e6-8c21-d1977ef5dcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "print(\"\\n=== Assemble Results ===\")\n",
    "\n",
    "rows_out = []\n",
    "\n",
    "for ident in identities:\n",
    "    relevant = []\n",
    "    for ip in ident.get('list_of_ips') or []:\n",
    "        relevant.extend(by_ep.get(ip, []))\n",
    "\n",
    "    if not relevant:\n",
    "        #print(f\"{ident.get('originating_endpoint')} not relevant\")\n",
    "        continue\n",
    "\n",
    "    # summary\n",
    "    #print(f\"- endpoint={ident.get('originating_endpoint')} | ips={len(ident.get('list_of_ips') or [])} | matches={len(relevant)}\")\n",
    "\n",
    "    # tiny sample (first 3 rows, selected fields only)\n",
    "    sample_fields = [\"DiscoveryAccess.endpoint\", \"DeviceInfo.hostname\", \"DiscoveryRun.label\"]\n",
    "    for r in islice(relevant, 3):\n",
    "        mini = {k: r.get(k) for k in sample_fields}\n",
    "        #print(\"  \", json.dumps(mini, ensure_ascii=False))\n",
    "\n",
    "    def to_str_set(val):\n",
    "        \"\"\"Flatten lists/tuples, drop None/empty, cast to str, return a set.\"\"\"\n",
    "        if isinstance(val, (list, tuple)):\n",
    "            return {str(x) for x in val if x}\n",
    "        return {str(val)} if val else set()\n",
    "\n",
    "    # Build unique values safely\n",
    "    all_device_names = sorted({\n",
    "        s for r in relevant for s in to_str_set(r.get('DeviceInfo.hostname'))\n",
    "    })\n",
    "    \n",
    "    all_endpoints = sorted({\n",
    "        s for r in relevant for s in to_str_set(r.get('DiscoveryAccess.endpoint'))\n",
    "    })\n",
    "    \n",
    "    all_discovery_runs = sorted({\n",
    "        s for r in relevant for s in to_str_set(r.get('DiscoveryRun.label'))\n",
    "    })\n",
    "\n",
    "    # credentials used across relevant rows\n",
    "    all_creds = []\n",
    "    for r in relevant:\n",
    "        cu = r.get('DeviceInfo.last_credential')\n",
    "        if cu:\n",
    "            cu_s = str(cu).split('/')[-1].lower()\n",
    "            cm = cred_map.get(cu_s, {})\n",
    "            all_creds.append(f\"{cm.get('label') or cu_s} ({cu_s})\")\n",
    "    all_creds = sorted({v for v in all_creds if v})\n",
    "\n",
    "    # latest and latest successful\n",
    "    latest = pick_latest(relevant, 'DiscoveryAccess.scan_endtime_raw')\n",
    "    succ_rows = [r for r in relevant if r.get('DiscoveryAccess.host_node_updated')]\n",
    "    latest_succ = pick_latest(succ_rows, 'DiscoveryAccess.scan_endtime_raw') if succ_rows else {}\n",
    "\n",
    "    last_scanned_ip = latest.get('DiscoveryAccess.endpoint')\n",
    "    last_identity = latest.get('DeviceInfo.hostname') or (all_device_names[0] if all_device_names else None)\n",
    "    last_kind = latest.get('DiscoveryAccess.node_kind')\n",
    "\n",
    "    last_cred_uuid = latest.get('DeviceInfo.last_credential')\n",
    "    last_cred_uuid = str(last_cred_uuid).split('/')[-1].lower() if last_cred_uuid else None\n",
    "    cred_info = cred_map.get(last_cred_uuid or '', {})\n",
    "\n",
    "    ls_identity = latest_succ.get('DeviceInfo.hostname') if latest_succ else None\n",
    "    ls_ip = latest_succ.get('DiscoveryAccess.endpoint') if latest_succ else None\n",
    "    ls_cred = latest_succ.get('DeviceInfo.last_credential') if latest_succ else None\n",
    "    ls_cred = str(ls_cred).split('/')[-1].lower() if ls_cred else None\n",
    "    ls_cred_info = cred_map.get(ls_cred or '', {})\n",
    "\n",
    "    rows_out.append([\n",
    "        last_scanned_ip,\n",
    "        (ident.get('list_of_names') or [None])[0] or last_identity,\n",
    "        last_kind,\n",
    "        all_device_names or None,\n",
    "        all_endpoints or None,\n",
    "        all_creds or None,\n",
    "        all_discovery_runs or None,\n",
    "        last_cred_uuid,\n",
    "        cred_info.get('label'),\n",
    "        cred_info.get('username'),\n",
    "        latest.get('DiscoveryAccess.scan_starttime'),\n",
    "        latest.get('DiscoveryRun.label'),\n",
    "        latest.get('DiscoveryAccess.end_state'),\n",
    "        latest.get('DiscoveryAccess.result'),\n",
    "        latest.get('DiscoveryAccess.current_access'),\n",
    "        ls_identity,\n",
    "        ls_ip,\n",
    "        ls_cred,\n",
    "        ls_cred_info.get('label'),\n",
    "        ls_cred_info.get('username'),\n",
    "        latest_succ.get('DiscoveryAccess.scan_starttime') if latest_succ else None,\n",
    "        latest_succ.get('DiscoveryRun.label') if latest_succ else None,\n",
    "        latest_succ.get('DiscoveryAccess.end_state') if latest_succ else None,\n",
    "    ])\n",
    "\n",
    "headers = [\n",
    "    'last_scanned_ip',\n",
    "    'last_identity',\n",
    "    'last_kind',\n",
    "    'all_device_names',\n",
    "    'all_endpoints',\n",
    "    'all_credentials_used',\n",
    "    'all_discovery_runs',\n",
    "    'last_credential',\n",
    "    'last_credential_label',\n",
    "    'last_credential_username',\n",
    "    'last_start_time',\n",
    "    'last_run',\n",
    "    'last_endstate',\n",
    "    'last_result',\n",
    "    'last_access_method',\n",
    "    'last_successful_identity',\n",
    "    'last_successful_ip',\n",
    "    'last_successful_credential',\n",
    "    'last_successful_credential_label',\n",
    "    'last_successful_credential_username',\n",
    "    'last_successful_start_time',\n",
    "    'last_successful_run',\n",
    "    'last_successful_endstate',\n",
    "]\n",
    "df_out = pd.DataFrame(rows_out, columns=headers)\n",
    "display(df_out.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191f08ab-a09a-4c6d-9532-ebce163aa476",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.insert(0, 'Discovery Instance', target)\n",
    "\n",
    "print(f\"- Rows assembled: {len(rows_out)}\")\n",
    "print(f\"- Output shape: {df_out.shape}\")\n",
    "\n",
    "REPORT_NAME = 'devices'\n",
    "display(df_out.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-csv",
   "metadata": {},
   "source": [
    "## Save to CSV\n",
    "\n",
    "Writes the report to the standard output folder in the project root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-csv-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CSV = str(output_dir / f'{REPORT_NAME}.csv')\n",
    "df_out.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f'Saved to {OUTPUT_CSV}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d326e92d-8577-4de7-9e19-54505b322165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
