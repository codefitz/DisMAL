{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-title",
   "metadata": {},
   "source": [
    "# Discovery Run Analysis (BMC Discovery)\n",
    "\n",
    "This notebook reproduces the DisMAL `discovery_run_analysis` report using the Tideway library only.\n",
    "It summarizes discovery runs with ranges, schedules, outpost names, totals, active and dropped endpoints, and scan kinds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requirements",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "Uncomment the next cell to install dependencies in your environment if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q tideway pandas pyyaml\n",
    "\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "from typing import Any, List, Dict\n",
    "import pandas as pd\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "select-appliance",
   "metadata": {},
   "source": [
    "## Select Appliance (optional)\n",
    "\n",
    "If `config.yaml` has multiple appliances, set by name or index. Defaults to the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appliance-vars",
   "metadata": {},
   "outputs": [],
   "source": [
    "APPLIANCE_NAME = None   # e.g., 'prod' or 'dev'\n",
    "APPLIANCE_INDEX = 0     # integer index if not using name selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-load",
   "metadata": {},
   "source": [
    "## Configuration (from config.yaml)\n",
    "\n",
    "Finds `config.yaml`, loads target and token, and prepares the output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_repo_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / 'config.yaml').exists():\n",
    "            return p\n",
    "    return start.parent\n",
    "\n",
    "repo_root = _find_repo_root(Path.cwd())\n",
    "config_path = repo_root / 'config.yaml'\n",
    "with open(config_path, 'r') as fh:\n",
    "    cfg = yaml.safe_load(fh) or {}\n",
    "\n",
    "apps = cfg.get('appliances') or []\n",
    "selected = None\n",
    "if isinstance(apps, list) and apps:\n",
    "    if APPLIANCE_NAME:\n",
    "        selected = next((a for a in apps if a.get('name') == APPLIANCE_NAME), None)\n",
    "        if selected is None:\n",
    "            raise ValueError(f\"No appliance named '{APPLIANCE_NAME}' in config.yaml\")\n",
    "    else:\n",
    "        try:\n",
    "            selected = apps[int(APPLIANCE_INDEX)]\n",
    "        except Exception:\n",
    "            selected = apps[0]\n",
    "\n",
    "target = ((selected or {}).get('target') or cfg.get('target') or '').strip()\n",
    "if not target:\n",
    "    raise ValueError('config.yaml missing \"target\"')\n",
    "\n",
    "token = (((selected or {}).get('token') or cfg.get('token') or '').strip())\n",
    "token_file = (selected or {}).get('token_file') or cfg.get('token_file') or cfg.get('f_token')\n",
    "if not token and token_file:\n",
    "    tf_path = Path(token_file)\n",
    "    if not tf_path.is_absolute():\n",
    "        tf_path = repo_root / tf_path\n",
    "    with open(tf_path, 'r') as tf:\n",
    "        token = tf.read().strip()\n",
    "if not token:\n",
    "    raise ValueError('API token not found in config.yaml (token or token_file)')\n",
    "\n",
    "API_VERSION = str((selected or {}).get('api_version') or cfg.get('api_version') or 'v1.14')\n",
    "VERIFY_SSL = bool((selected or {}).get('verify_ssl', cfg.get('verify_ssl', True)))\n",
    "\n",
    "sanitized = target.replace('.', '_').replace(':', '_').replace('/', '_')\n",
    "output_dir = repo_root / f'output_{sanitized}'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Base Host     :', target)\n",
    "print('API Version   :', API_VERSION)\n",
    "print('Verify SSL    :', VERIFY_SSL)\n",
    "print('Output folder :', output_dir)\n",
    "\n",
    "# Prefer local Tideway package if present\n",
    "local_tideway = repo_root / 'Tideway'\n",
    "if local_tideway.exists():\n",
    "    sys.path.insert(0, str(local_tideway))\n",
    "import importlib\n",
    "tideway = importlib.import_module('tideway')\n",
    "API_VERSION_NUM = API_VERSION.lstrip('v')\n",
    "app = tideway.appliance(target, token, api_version=API_VERSION_NUM, ssl_verify=VERIFY_SSL)\n",
    "twsearch = app.data()\n",
    "try:\n",
    "    about = app.api_about\n",
    "    print('Appliance reachable:', about.status_code)\n",
    "except Exception as e:\n",
    "    print('Warning: failed to contact appliance /api/about:', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpers",
   "metadata": {},
   "source": [
    "## Helpers\n",
    "\n",
    "Normalize Data API results and run object-format searches in bulk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpers-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_table_to_json(table_like: List[List[Any]]):\n",
    "    if not table_like or not isinstance(table_like, list):\n",
    "        return []\n",
    "    if not table_like or not isinstance(table_like[0], list):\n",
    "        return []\n",
    "    headers = table_like[0]\n",
    "    rows = table_like[1:]\n",
    "    out = []\n",
    "    for r in rows:\n",
    "        try:\n",
    "            out.append(dict(zip(headers, r)))\n",
    "        except Exception:\n",
    "            continue\n",
    "    return out\n",
    "\n",
    "def to_rows(payload: Any):\n",
    "    if isinstance(payload, list):\n",
    "        if payload and isinstance(payload[0], list):\n",
    "            return list_table_to_json(payload)\n",
    "        if payload and isinstance(payload[0], dict):\n",
    "            return payload\n",
    "        return []\n",
    "    if hasattr(payload, 'json'):\n",
    "        try:\n",
    "            js = payload.json()\n",
    "        except Exception:\n",
    "            return []\n",
    "        if isinstance(js, list) and js and isinstance(js[0], list):\n",
    "            return list_table_to_json(js)\n",
    "        if isinstance(js, list) and js and isinstance(js[0], dict):\n",
    "            return js\n",
    "        if isinstance(js, dict) and 'headings' in js and 'results' in js:\n",
    "            return list_table_to_json([js['headings']] + list(js.get('results') or []))\n",
    "        return []\n",
    "    if isinstance(payload, dict) and 'headings' in payload and 'results' in payload:\n",
    "        return list_table_to_json([payload['headings']] + list(payload.get('results') or []))\n",
    "    return []\n",
    "\n",
    "def tw_search_all(search, query: str, limit: int = 500):\n",
    "    resp = search.search({'query': query}, format='object', limit=limit)\n",
    "    return to_rows(resp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "query",
   "metadata": {},
   "source": [
    "## Query\n",
    "\n",
    "TWQL used by the DisMAL report to summarize run ranges and outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "query-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry_dra = '''\n",
    "search DiscoveryRun as DiscoveryRun\n",
    "  with (traverse :::ScanRange as ScanRange),\n",
    "       (traverse :::DroppedEndpoints as DroppedEndpoints),\n",
    "       (traverse :::DiscoveryAccess as DiscoveryAccess)\n",
    "  show valid_ranges as 'Explicit Ranges', label as 'Scan Label',\n",
    "       range_summary as 'Range Summary', outpost_name as 'Outpost Name',\n",
    "       #ScanRange.label as 'Label', #ScanRange.scan_kind as 'Scan Kind',\n",
    "       (#ScanRange.range_strings or #ScanRange.provider) as 'Range',\n",
    "       recurrenceDescription(#ScanRange.schedule) as 'Schedule',\n",
    "       total as 'Total Endpoints',\n",
    "       (result_success or 0) + (result_skipped or 0) + (result_error or 0) +\n",
    "       (result_no_access or 0) + (result_no_response or 0) as 'Active Endpoints',\n",
    "       (result_dropped or 0) as 'Dropped',\n",
    "       unique(#DiscoveryAccess.scan_kind) as 'Scan Kinds'\n",
    "  processwith show valid_ranges, label, endtime as 'End Time',\n",
    "       range_summary, outpost_name, @4, @5, @6, @7, total, @9, @10,\n",
    "       @11 as 'Scan Kinds'\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run",
   "metadata": {},
   "source": [
    "## Run and Preview\n",
    "\n",
    "Fetch rows, insert the Discovery Instance column, and preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = tw_search_all(twsearch, qry_dra)\n",
    "print('Rows:', len(rows))\n",
    "df = pd.DataFrame(rows) if rows else pd.DataFrame()\n",
    "if not df.empty:\n",
    "    df.insert(0, 'Discovery Instance', target)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save",
   "metadata": {},
   "source": [
    "## Save to CSV\n",
    "\n",
    "Writes `discovery_run_analysis.csv` to the standard output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CSV = str(output_dir / 'discovery_run_analysis.csv')\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f'Saved to {OUTPUT_CSV}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c503d1b-d502-4789-b9f2-3995cf3265e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
