{"cells":[{"cell_type":"markdown","id":"intro-title","metadata":{},"source":["# Host Utilisation (BMC Discovery)\n","\n","This notebook reproduces the DisMAL `host_utilisation` report using the raw CSV exports generated by DisMAL.\n","It loads data from `raw_exports/<appliance>/host_utilisation.csv` for preview and optional re-export to the standard output folders.\n"]},{"cell_type":"markdown","id":"requirements","metadata":{},"source":["## Requirements\n","\n","We rely on `pandas` for tabular wrangling and `PyYAML` for configuration.\n","Uncomment the next cell to install them in your environment if needed.\n"]},{"cell_type":"code","execution_count":null,"id":"imports","metadata":{},"outputs":[],"source":["# %pip install -q pandas pyyaml\n","\n","import re\n","from pathlib import Path\n","\n","import pandas as pd\n","import yaml\n"]},{"cell_type":"markdown","id":"81e3be29-4277-46ca-8878-4521ae9c2c8b","metadata":{},"source":["## Configuration (from config.yaml)\n","\n","Loads target details, resolves the output folder, and points to the matching raw export directory for each appliance.\n"]},{"cell_type":"code","execution_count":null,"id":"7e370f45-0be9-44bb-a9b2-3cff8d5081a6","metadata":{},"outputs":[],"source":["from pathlib import Path\n","import re\n","import yaml\n","\n","def load_config_params(\n","    start: Path,\n","    appliance_name: str = None,\n","    appliance_index: int = 0,\n",") -> dict:\n","    def _find_repo_root(start: Path) -> Path:\n","        for p in [start] + list(start.parents):\n","            if (p / 'config.yaml').exists():\n","                return p\n","        return start.parent\n","\n","    def _slugify(value: str) -> str:\n","        return re.sub(r'[^A-Za-z0-9]+', '_', value).strip('_').lower() or 'default'\n","\n","    repo_root = _find_repo_root(start)\n","    config_path = repo_root / 'config.yaml'\n","\n","    with open(config_path, 'r') as fh:\n","        cfg = yaml.safe_load(fh) or {}\n","\n","    apps = cfg.get('appliances') or []\n","    selected = None\n","    if isinstance(apps, list) and apps:\n","        if appliance_name:\n","            selected = next((a for a in apps if a.get('name') == appliance_name), None)\n","            if selected is None:\n","                raise ValueError(f\"No appliance named '{appliance_name}' in config.yaml\")\n","        else:\n","            try:\n","                selected = apps[int(appliance_index)]\n","            except Exception:\n","                selected = apps[0]\n","\n","    target = ((selected or {}).get('target') or cfg.get('target') or '').strip()\n","    if not target:\n","        raise ValueError('config.yaml missing \"target\"')\n","\n","    token = (((selected or {}).get('token') or cfg.get('token') or '').strip())\n","    token_file = (selected or {}).get('token_file') or cfg.get('token_file') or cfg.get('f_token')\n","    if not token and token_file:\n","        tf_path = Path(token_file)\n","        if not tf_path.is_absolute():\n","            tf_path = repo_root / tf_path\n","        with open(tf_path, 'r') as tf:\n","            token = tf.read().strip()\n","    if not token:\n","        token = None\n","\n","    api_version = str((selected or {}).get('api_version') or cfg.get('api_version') or 'v1.14')\n","    verify_ssl = bool((selected or {}).get('verify_ssl', cfg.get('verify_ssl', True)))\n","\n","    sanitized = target.replace('.', '_').replace(':', '_').replace('/', '_')\n","    output_dir = repo_root / f'output_{sanitized}'\n","    output_dir.mkdir(parents=True, exist_ok=True)\n","\n","    export_name = ((selected or {}).get('name') or appliance_name or sanitized)\n","    raw_export_dir = repo_root / 'raw_exports' / _slugify(export_name)\n","\n","    return {\n","        \"repo_root\": repo_root,\n","        \"config_path\": config_path,\n","        \"cfg\": cfg,\n","        \"selected\": selected,\n","        \"target\": target,\n","        \"token\": token,\n","        \"api_version\": api_version,\n","        \"verify_ssl\": verify_ssl,\n","        \"output_dir\": output_dir,\n","        \"raw_export_dir\": raw_export_dir,\n","    }\n"]},{"cell_type":"code","execution_count":null,"id":"63fd189a-2d5b-4d1f-87f6-cc4cd73ff98d","metadata":{},"outputs":[],"source":["def init_appliance(appliance_name: str = \"prod\"):\n","    params = load_config_params(Path.cwd(), appliance_name=appliance_name)\n","\n","    target = params[\"target\"]\n","    api_version = params[\"api_version\"]\n","    verify_ssl = params[\"verify_ssl\"]\n","    output_dir = params[\"output_dir\"]\n","    raw_export_dir = params[\"raw_export_dir\"]\n","\n","    print('Appliance Name :', appliance_name)\n","    print('Target         :', target)\n","    print('API Version    :', api_version)\n","    print('Verify SSL     :', verify_ssl)\n","    print('Raw CSV folder :', raw_export_dir)\n","    print('Output folder  :', output_dir)\n","\n","    return {\n","        \"params\": params,\n","        \"target\": target,\n","        \"api_version\": api_version,\n","        \"verify_ssl\": verify_ssl,\n","        \"output_dir\": output_dir,\n","        \"raw_export_dir\": raw_export_dir,\n","        \"appliance_name\": appliance_name,\n","    }\n"]},{"cell_type":"markdown","id":"32226c05-690a-4ac1-abb5-a25492eae585","metadata":{},"source":["# Initialise Instances"]},{"cell_type":"code","execution_count":null,"id":"86529108-775c-4179-b22f-bd8805fc9854","metadata":{},"outputs":[],"source":["print(\"Initialise Prod:\")\n","twprod = init_appliance(\"prod\")\n","\n","print(\"Initialise Dev:\")\n","twdev = init_appliance(\"dev\")"]},{"cell_type":"code","execution_count":null,"id":"a1983862-454f-489b-9792-153cf01a6ea2","metadata":{},"outputs":[],"source":["BASE_EXPORT_COLUMNS = ['Appliance Target', 'Appliance Name', 'Query Title']\n","COLUMN_RENAMES = {\n","    'Host.hostname': 'Host Name',\n","    'Host.hostname_hash': 'Host Name Hash',\n","    'Host.os': 'Operating System',\n","    'Host.os_type': 'OS Type',\n","    'Host.virtual': 'Virtual',\n","    'Host.cloud': 'Cloud',\n","    'DiscoveryAccess.endpoint': 'Endpoint',\n","    'Host.running_software_instances': 'Running Software Instances',\n","    'Host.candidate_software_instances': 'Candidate Software Instances',\n","    'Host.running_processes': 'Running Processes',\n","    'Host.running_services': 'Running Services',\n","}\n","NUMERIC_COLUMNS = [\n","    'Running Software Instances',\n","    'Candidate Software Instances',\n","    'Running Processes',\n","    'Running Services',\n","]\n","\n","_SLUG_PATTERN = re.compile(r'[^A-Za-z0-9]+')\n","\n","def slugify_title(value: str) -> str:\n","    slug = _SLUG_PATTERN.sub('_', value or '').strip('_').lower()\n","    return slug or 'unnamed'\n","\n","def load_host_utilisation(instance, query_title: str = 'Host Utilisation'):\n","    csv_path = instance['raw_export_dir'] / f\"{slugify_title(query_title)}.csv\"\n","    if not csv_path.exists():\n","        raise FileNotFoundError(f'Missing export for {query_title}: {csv_path}')\n","\n","    df = pd.read_csv(csv_path)\n","    df = df.drop(columns=[c for c in BASE_EXPORT_COLUMNS if c in df.columns], errors='ignore')\n","\n","    for source_col, display_col in COLUMN_RENAMES.items():\n","        if source_col not in df.columns:\n","            df[source_col] = pd.NA\n","    df = df.rename(columns=COLUMN_RENAMES)\n","\n","    for col in NUMERIC_COLUMNS:\n","        if col in df.columns:\n","            df[col] = pd.to_numeric(df[col], errors='coerce')\n","\n","    df.insert(0, 'Discovery Instance', instance['target'])\n","    ordered = ['Discovery Instance'] + list(COLUMN_RENAMES.values())\n","    remaining = [c for c in df.columns if c not in ordered]\n","    df = df[[c for c in ordered if c in df.columns] + remaining]\n","    return df\n"]},{"cell_type":"markdown","id":"a67d0fe6-bb17-4947-9194-ff559f4d249d","metadata":{},"source":["## Load and Preview\n","\n","Load the raw export CSVs and preview the first few rows.\n"]},{"cell_type":"code","execution_count":null,"id":"d84a847d-20cf-47ee-96f4-c6a0a2ee06bb","metadata":{},"outputs":[],"source":["host_prod = load_host_utilisation(twprod)\n","print(twprod['target'])\n","display(host_prod.head(5))\n","\n","host_dev = load_host_utilisation(twdev)\n","print(twdev['target'])\n","display(host_dev.head(5))\n"]},{"cell_type":"markdown","id":"1d6f526d-78a1-4c17-9b3f-44522f573577","metadata":{},"source":["## Prepare output and save CSV\n","\n","Insert 'Discovery Instance' as the first column and save to `output_<target>/exclude_ranges.csv` to mirror DisMAL CLI output."]},{"cell_type":"code","execution_count":null,"id":"55a931cd-7ebd-4a6b-b94e-606bd828c11a","metadata":{},"outputs":[],"source":["from pathlib import Path\n","import pandas as pd\n","\n","def save(df: pd.DataFrame, output_dir: Path, filename: str):\n","    output_csv = str(output_dir / f\"{filename}.csv\")\n","    df.to_csv(output_csv, index=False)\n","    print(f\"Saved to {output_csv}\")\n","\n","save(host_prod, twprod['output_dir'], \"host_utilisation\")\n","save(host_dev, twdev['output_dir'], \"host_utilisation\")\n"]},{"cell_type":"markdown","id":"notes","metadata":{},"source":["---\n","### Notes\n","- Ensure the raw export CSVs are up-to-date before running this notebook.\n","- Counts are coerced to numeric when present; missing values are preserved as `NaN`.\n","- Adjust the query definition in `queries/dismal_queries.xml` if you need additional fields.\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":5}