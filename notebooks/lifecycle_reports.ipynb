{"cells":[{"cell_type":"markdown","id":"8feb1960","metadata":{},"source":["# Lifecycle Reports (BMC Discovery)\n","\n","This notebook reproduces the DisMAL lifecycle exports using the raw CSVs generated by the CLI.\n","It reads `raw_exports/<appliance>/database_lifecycle_report.csv`, `*_os_lifecycle_report.csv`, and `*_software_lifecycle_report.csv` for preview and optional re-export to the standard output folders.\n"]},{"cell_type":"code","execution_count":null,"id":"87c4995e-712b-4623-95e8-a50a28c0aaad","metadata":{},"outputs":[],"source":["# TODO: Fix report headers\n"]},{"cell_type":"markdown","id":"d6f361a3","metadata":{},"source":["This workflow consolidates the database, operating system, and software lifecycle reports from the pre-generated raw exports.\n"]},{"cell_type":"markdown","id":"b21ada1a","metadata":{},"source":["## Requirements"]},{"cell_type":"code","execution_count":null,"id":"151f4630","metadata":{},"outputs":[],"source":["# %pip install -q pandas pyyaml\n","\n","import re\n","from pathlib import Path\n","\n","import pandas as pd\n","import yaml\n"]},{"cell_type":"markdown","id":"683b6a21-dd09-4e30-ab8d-d426372eabac","metadata":{},"source":["## Configuration (from config.yaml)\n","\n","Reads settings from `../config.yaml` including target, token/token_file,\n","API version, and SSL verification preference.\n","Saves the CSV to `../output_<target>/credential_success.csv`."]},{"cell_type":"code","execution_count":null,"id":"34e85a2a-c17f-4315-a463-174cfa1d8a5d","metadata":{},"outputs":[],"source":["from pathlib import Path\n","import re\n","import yaml\n","\n","def load_config_params(\n","    start: Path,\n","    appliance_name: str = None,\n","    appliance_index: int = 0,\n",") -> dict:\n","    def _find_repo_root(start: Path) -> Path:\n","        for p in [start] + list(start.parents):\n","            if (p / 'config.yaml').exists():\n","                return p\n","        return start.parent\n","\n","    def _slugify(value: str) -> str:\n","        return re.sub(r'[^A-Za-z0-9]+', '_', value).strip('_').lower() or 'default'\n","\n","    repo_root = _find_repo_root(start)\n","    config_path = repo_root / 'config.yaml'\n","\n","    with open(config_path, 'r') as fh:\n","        cfg = yaml.safe_load(fh) or {}\n","\n","    apps = cfg.get('appliances') or []\n","    selected = None\n","    if isinstance(apps, list) and apps:\n","        if appliance_name:\n","            selected = next((a for a in apps if a.get('name') == appliance_name), None)\n","            if selected is None:\n","                raise ValueError(f\"No appliance named '{appliance_name}' in config.yaml\")\n","        else:\n","            try:\n","                selected = apps[int(appliance_index)]\n","            except Exception:\n","                selected = apps[0]\n","\n","    target = ((selected or {}).get('target') or cfg.get('target') or '').strip()\n","    if not target:\n","        raise ValueError('config.yaml missing \"target\"')\n","\n","    token = (((selected or {}).get('token') or cfg.get('token') or '').strip())\n","    token_file = (selected or {}).get('token_file') or cfg.get('token_file') or cfg.get('f_token')\n","    if not token and token_file:\n","        tf_path = Path(token_file)\n","        if not tf_path.is_absolute():\n","            tf_path = repo_root / tf_path\n","        with open(tf_path, 'r') as tf:\n","            token = tf.read().strip()\n","    if not token:\n","        token = None\n","\n","    api_version = str((selected or {}).get('api_version') or cfg.get('api_version') or 'v1.14')\n","    verify_ssl = bool((selected or {}).get('verify_ssl', cfg.get('verify_ssl', True)))\n","\n","    sanitized = target.replace('.', '_').replace(':', '_').replace('/', '_')\n","    output_dir = repo_root / f'output_{sanitized}'\n","    output_dir.mkdir(parents=True, exist_ok=True)\n","\n","    export_name = ((selected or {}).get('name') or appliance_name or sanitized)\n","    raw_export_dir = repo_root / 'raw_exports' / _slugify(export_name)\n","\n","    return {\n","        \"repo_root\": repo_root,\n","        \"config_path\": config_path,\n","        \"cfg\": cfg,\n","        \"selected\": selected,\n","        \"target\": target,\n","        \"token\": token,\n","        \"api_version\": api_version,\n","        \"verify_ssl\": verify_ssl,\n","        \"output_dir\": output_dir,\n","        \"raw_export_dir\": raw_export_dir,\n","    }\n"]},{"cell_type":"code","execution_count":null,"id":"bf568d77-4355-43fe-badb-3027492ecbbc","metadata":{},"outputs":[],"source":["def init_appliance(appliance_name: str = \"prod\"):\n","    params = load_config_params(Path.cwd(), appliance_name=appliance_name)\n","\n","    target = params[\"target\"]\n","    api_version = params[\"api_version\"]\n","    verify_ssl = params[\"verify_ssl\"]\n","    output_dir = params[\"output_dir\"]\n","    raw_export_dir = params[\"raw_export_dir\"]\n","\n","    print('Appliance Name :', appliance_name)\n","    print('Target         :', target)\n","    print('API Version    :', api_version)\n","    print('Verify SSL     :', verify_ssl)\n","    print('Raw CSV folder :', raw_export_dir)\n","    print('Output folder  :', output_dir)\n","\n","    return {\n","        \"params\": params,\n","        \"target\": target,\n","        \"api_version\": api_version,\n","        \"verify_ssl\": verify_ssl,\n","        \"output_dir\": output_dir,\n","        \"raw_export_dir\": raw_export_dir,\n","        \"appliance_name\": appliance_name,\n","    }\n"]},{"cell_type":"markdown","id":"da017020-43fb-43b0-bc99-5cf2576638c0","metadata":{},"source":["print('Initialise Prod:')\n","twprod = init_appliance('prod')\n","\n","print('Initialise Dev:')\n","twdev = init_appliance('dev')\n"]},{"cell_type":"code","execution_count":null,"id":"bd360553-6b3b-41e1-bfd2-2702cf169435","metadata":{},"outputs":[],"source":["print(\"Initialise Prod:\")\n","twprod = init_appliance(\"prod\")\n","\n","print(\"Initialise Dev:\")\n","twdev = init_appliance(\"dev\")"]},{"cell_type":"code","execution_count":null,"id":"61d39733-f3b3-46d7-b410-a821efa355d0","metadata":{},"outputs":[],"source":["LIFECYCLE_EXPORTS = [\n","    {'title': 'Database Lifecycle Report', 'filename': 'database_lifecycle_report.csv', 'output': 'database_lifecycle'},\n","    {'title': 'OS Lifecycle Report', 'filename': 'os_lifecycle_report.csv', 'output': 'os_lifecycle'},\n","    {'title': 'Software Lifecycle Report', 'filename': 'software_lifecycle_report.csv', 'output': 'software_lifecycle'},\n","    {'title': 'Hardware Lifecycle Report', 'filename': 'hardware_eol_report.csv', 'output': 'hardware_lifecycle'},\n","]\n","\n","BASE_EXPORT_COLUMNS = ['Appliance Target', 'Appliance Name', 'Query Title']\n","\n","def load_lifecycle_export(instance, meta):\n","    csv_path = instance['raw_export_dir'] / meta['filename']\n","    if not csv_path.exists():\n","        raise FileNotFoundError(f\"Missing export {csv_path}\")\n","\n","    df = pd.read_csv(csv_path)\n","    df = df.drop(columns=[c for c in BASE_EXPORT_COLUMNS if c in df.columns], errors='ignore')\n","    df.insert(0, 'Discovery Instance', instance['target'])\n","    return df\n","\n","def preview_exports(instance):\n","    frames = {}\n","    for meta in LIFECYCLE_EXPORTS:\n","        print(f\"=== {meta['title']} ===\")\n","        df = load_lifecycle_export(instance, meta)\n","        frames[meta['output']] = df\n","        print(instance['target'])\n","        print(f\"Rows returned: {len(df)}\")\n","        if not df.empty:\n","            display(df.head(10))\n","    return frames\n","\n","def save_exports(frames, instance):\n","    for meta in LIFECYCLE_EXPORTS:\n","        df = frames.get(meta['output'])\n","        if df is None:\n","            continue\n","        output_csv = instance['output_dir'] / f\"{meta['output']}.csv\"\n","        df.to_csv(output_csv, index=False)\n","        print(f\"Saved to {output_csv}\")\n"]},{"cell_type":"markdown","id":"b794a0ce","metadata":{},"source":["## Session and helpers"]},{"cell_type":"code","execution_count":null,"id":"d95fa833","metadata":{},"outputs":[],"source":["prod_frames = preview_exports(twprod)\n","dev_frames = preview_exports(twdev)\n"]},{"cell_type":"code","execution_count":null,"id":"4062be5d","metadata":{},"outputs":[],"source":["print('Saving lifecycle exports (prod)')\n","save_exports(prod_frames, twprod)\n","print('Saving lifecycle exports (dev)')\n","save_exports(dev_frames, twdev)\n"]},{"cell_type":"markdown","id":"0c88de32","metadata":{},"source":["---\n","### Notes\n","- Ensure the raw export CSVs are refreshed before running the notebook so the lifecycle data remains current.\n","- Update `LIFECYCLE_EXPORTS` if new lifecycle queries are added to the export workflow.\n","- Previews are limited to the first 10 rows for readability; adjust `preview_exports` if you need more context.\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.7"}},"nbformat":4,"nbformat_minor":5}