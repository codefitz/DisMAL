{"cells":[{"cell_type":"markdown","id":"727eb3a8","metadata":{"id":"title"},"source":["# Open Ports (CSV Exports)\n","\n","This notebook rebuilds the DisMAL `open_ports` report from raw Discovery CSV exports.\n","It reads appliance entries from `config.yaml`, loops over matching export folders,\n","and writes the per-instance CSVs without calling the Discovery API.\n"]},{"cell_type":"markdown","id":"03422db6","metadata":{"id":"requirements"},"source":["## Requirements\n","\n","We rely on `pandas` and `PyYAML` for data wrangling. Uncomment below to install them if needed.\n"]},{"cell_type":"code","execution_count":null,"id":"32227220","metadata":{"id":"imports"},"outputs":[],"source":["# %pip install -q pandas pyyaml\n","\n","from pathlib import Path\n","from typing import Any, Dict, Iterable, List, Optional\n","\n","import pandas as pd\n","import yaml\n"]},{"cell_type":"markdown","id":"72ee0685","metadata":{"id":"configuration"},"source":["## Configuration\n","\n","Adjust these values to control which instances are processed and where outputs are written.\n"]},{"cell_type":"code","execution_count":null,"id":"ddcc0d2b","metadata":{"id":"config"},"outputs":[],"source":["# Root folder containing raw_exports/<instance> subdirectories\n","RAW_EXPORT_ROOT = Path(\"../../raw_exports\")\n","\n","# Optional filters (set INCLUDE_INSTANCES to something like [\"prod\"] to limit processing)\n","INCLUDE_INSTANCES: Optional[Iterable[str]] = None\n","EXCLUDE_INSTANCES: Iterable[str] = ()\n","\n","# Optional override for outputs (per appliance sub-folder is created automatically)\n","OUTPUT_BASE_DIR = None  # e.g., Path(\"../../csv_outputs\")\n","OUTPUT_FILENAME = \"open_ports.csv\"\n"]},{"cell_type":"code","execution_count":null,"id":"6ac41445","metadata":{"id":"paths_config"},"outputs":[],"source":["def find_repo_root(start: Path) -> Path:\n","    for candidate in [start] + list(start.parents):\n","        if (candidate / \"config.yaml\").exists() or (candidate / \".git\").is_dir():\n","            return candidate\n","    return start\n","\n","NOTEBOOK_DIR = Path.cwd()\n","REPO_ROOT = find_repo_root(NOTEBOOK_DIR)\n","CONFIG_PATH = REPO_ROOT / \"config.yaml\"\n","\n","if not CONFIG_PATH.exists():\n","    raise FileNotFoundError(f\"config.yaml not found at {CONFIG_PATH}\")\n","\n","with CONFIG_PATH.open(\"r\", encoding=\"utf-8\") as fh:\n","    cfg = yaml.safe_load(fh) or {}\n","\n","appliance_entries = cfg.get(\"appliances\") or []\n","if isinstance(appliance_entries, dict):\n","    appliance_entries = [appliance_entries]\n","\n","if not appliance_entries:\n","    fallback_target = cfg.get(\"target\")\n","    fallback_name = cfg.get(\"name\") or (fallback_target or \"default\")\n","    appliance_entries = [{\"name\": fallback_name, \"target\": fallback_target}]\n","\n","available_appliances: List[Dict[str, Any]] = []\n","for entry in appliance_entries:\n","    name = str(entry.get(\"name\") or \"\").strip()\n","    target = str(entry.get(\"target\") or \"\").strip()\n","    if not name:\n","        continue\n","    available_appliances.append({\"name\": name, \"target\": target or name})\n","\n","if not available_appliances:\n","    raise ValueError(\"No appliances with a name found in config.yaml\")\n","\n","exports_root = RAW_EXPORT_ROOT if RAW_EXPORT_ROOT.is_absolute() else (NOTEBOOK_DIR / RAW_EXPORT_ROOT).resolve()\n","if not exports_root.exists():\n","    raise FileNotFoundError(f\"Raw export root not found: {exports_root}\")\n","\n","include_set = {str(v).strip() for v in (INCLUDE_INSTANCES or []) if str(v).strip()}\n","exclude_set = {str(v).strip() for v in (EXCLUDE_INSTANCES or []) if str(v).strip()}\n","\n","available_dirs = {path.name: path for path in exports_root.iterdir() if path.is_dir()}\n","\n","selected_appliances: List[Dict[str, Any]] = []\n","skipped_missing: List[str] = []\n","skipped_filtered: List[str] = []\n","\n","for appliance in available_appliances:\n","    name = appliance[\"name\"]\n","    if include_set and name not in include_set:\n","        skipped_filtered.append(name)\n","        continue\n","    if name in exclude_set:\n","        skipped_filtered.append(name)\n","        continue\n","    export_dir = available_dirs.get(name)\n","    if not export_dir:\n","        skipped_missing.append(name)\n","        continue\n","    selected_appliances.append({\n","        \"name\": name,\n","        \"target\": appliance.get(\"target\") or name,\n","        \"export_dir\": export_dir,\n","    })\n","\n","print(f\"Repo root         : {REPO_ROOT}\")\n","print(f\"Config path       : {CONFIG_PATH}\")\n","print(f\"Exports root      : {exports_root}\")\n","print(f\"Config appliances : {[a['name'] for a in available_appliances]}\")\n","print(f\"Export directories: {sorted(available_dirs)}\")\n","print(f\"Selected          : {[a['name'] for a in selected_appliances]}\")\n","if skipped_missing:\n","    print(f\"Missing export dirs: {skipped_missing}\")\n","if skipped_filtered:\n","    print(f\"Skipped by filter  : {skipped_filtered}\")\n","\n","if not selected_appliances:\n","    raise RuntimeError(\"No appliances selected for processing â€“ check raw exports and filters.\")\n"]},{"cell_type":"code","execution_count":null,"id":"fcf6e076","metadata":{"id":"helpers"},"outputs":[],"source":["METADATA_COLUMNS = [\"Appliance Target\", \"Appliance Name\", \"Query Title\"]\n","\n","CSV_FILENAME = \"open_ports_default_services.csv\"\n","\n","REQUIRED_COLUMNS = [\n","    \"DiscoveryAccess.endpoint\",\n","    \"OpenPort.port\",\n","    \"OpenPort.protocol\",\n","    \"OpenPort.service\",\n","    \"DeviceInfo.hostname\",\n","    \"DiscoveryAccess.node_kind\",\n","    \"DiscoveryAccess.scan_starttime\",\n","    \"DiscoveryAccess.scan_endtime\",\n","    \"DiscoveryRun.label\",\n","]\n","\n","from pandas.errors import EmptyDataError\n","\n","\n","def load_csv(path: Path) -> pd.DataFrame:\n","    if not path.exists():\n","        print(f\"Missing CSV: {path}\")\n","        return pd.DataFrame()\n","    try:\n","        return pd.read_csv(path, low_memory=False)\n","    except EmptyDataError:\n","        print(f\"Empty CSV: {path}\")\n","        return pd.DataFrame()\n","\n","\n","def drop_metadata(df: pd.DataFrame) -> pd.DataFrame:\n","    return df.drop(columns=[c for c in METADATA_COLUMNS if c in df.columns], errors=\"ignore\")\n","\n","\n","def ensure_columns(df: pd.DataFrame, columns: List[str]) -> pd.DataFrame:\n","    for col in columns:\n","        if col not in df.columns:\n","            df[col] = None\n","    return df\n"]},{"cell_type":"code","execution_count":null,"id":"7fe802ca","metadata":{"id":"processing"},"outputs":[],"source":["def build_output_dir(target: str) -> Path:\n","    sanitized = (target or \"unknown\").replace(\".\", \"_\").replace(\":\", \"_\").replace(\"/\", \"_\")\n","    if OUTPUT_BASE_DIR is None:\n","        return REPO_ROOT / f\"output_{sanitized}\"\n","    base_root = OUTPUT_BASE_DIR if isinstance(OUTPUT_BASE_DIR, Path) else Path(OUTPUT_BASE_DIR)\n","    return base_root.expanduser().resolve() / f\"output_{sanitized}\"\n","\n","\n","def process_instance(instance: Dict[str, Any]) -> Dict[str, Any]:\n","    name = instance[\"name\"]\n","    target = instance.get(\"target\") or name\n","    export_dir: Path = instance[\"export_dir\"]\n","    print(f\"=== Processing {name} ({target}) ===\")\n","\n","    output_dir = build_output_dir(target)\n","    output_dir.mkdir(parents=True, exist_ok=True)\n","\n","    csv_path = export_dir / CSV_FILENAME\n","    df = drop_metadata(load_csv(csv_path))\n","    df = ensure_columns(df, REQUIRED_COLUMNS)\n","\n","    if df.empty:\n","        print(\"No open port rows found.\")\n","    else:\n","        print(f\"Rows loaded: {len(df)}\")\n","\n","    other_cols = sorted([c for c in df.columns if c not in {\"Discovery Instance\"}])\n","\n","    df_out = df.copy()\n","    df_out.insert(0, \"Discovery Instance\", target)\n","    df_out = df_out[[\"Discovery Instance\"] + other_cols]\n","\n","    output_csv = output_dir / OUTPUT_FILENAME\n","    df_out.to_csv(output_csv, index=False)\n","\n","    print(f\"Saved to {output_csv}\")\n","    display(df_out.head(20))\n","\n","    return {\n","        \"instance\": name,\n","        \"target\": target,\n","        \"output_path\": output_csv,\n","        \"rows\": int(len(df_out)),\n","        \"status\": \"ok\",\n","    }\n"]},{"cell_type":"code","execution_count":null,"id":"aa0861ea","metadata":{"id":"run_all"},"outputs":[],"source":["results: List[Dict[str, Any]] = []\n","for appliance in selected_appliances:\n","    outcome = process_instance(appliance)\n","    results.append(outcome)\n","\n","summary_df = pd.DataFrame(results)\n","if \"output_path\" in summary_df.columns:\n","    summary_df[\"output_path\"] = summary_df[\"output_path\"].map(lambda p: str(p) if p is not None else None)\n","display(summary_df)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":5}