{"cells":[{"cell_type":"markdown","id":"e617cbf9","metadata":{"id":"title"},"source":["# Outpost Credentials (CSV Exports)\n","\n","This notebook rebuilds the DisMAL `outpost_creds` report from raw Discovery CSV exports.\n","It reads appliance entries from `config.yaml`, processes the credential/outpost exports,\n","and writes the per-instance CSV without calling the Discovery API.\n"]},{"cell_type":"markdown","id":"a2c34da9","metadata":{"id":"requirements"},"source":["## Requirements\n","\n","We rely on `pandas` and `PyYAML`. Uncomment below to install them if needed.\n"]},{"cell_type":"code","execution_count":null,"id":"6c45f504","metadata":{"id":"imports"},"outputs":[],"source":["# %pip install -q pandas pyyaml\n","\n","from pathlib import Path\n","from typing import Any, Dict, Iterable, List, Optional\n","\n","import pandas as pd\n","import yaml\n"]},{"cell_type":"markdown","id":"2152010c","metadata":{"id":"configuration"},"source":["## Configuration\n","\n","Adjust these values to control which instances are processed and where outputs are written.\n"]},{"cell_type":"code","execution_count":null,"id":"d30c3ae2","metadata":{"id":"config"},"outputs":[],"source":["# Root folder containing raw_exports/<instance> subdirectories\n","RAW_EXPORT_ROOT = Path(\"../../raw_exports\")\n","\n","# Optional filters (set INCLUDE_INSTANCES to something like [\"prod\"] to limit processing)\n","INCLUDE_INSTANCES: Optional[Iterable[str]] = None\n","EXCLUDE_INSTANCES: Iterable[str] = ()\n","\n","# Optional override for outputs (per appliance sub-folder is created automatically)\n","OUTPUT_BASE_DIR = None  # e.g., Path(\"../../csv_outputs\")\n","OUTPUT_FILENAME = \"outpost_creds.csv\"\n"]},{"cell_type":"code","execution_count":null,"id":"93729e9e","metadata":{"id":"paths_config"},"outputs":[],"source":["def find_repo_root(start: Path) -> Path:\n","    for candidate in [start] + list(start.parents):\n","        if (candidate / \"config.yaml\").exists() or (candidate / \".git\").is_dir():\n","            return candidate\n","    return start\n","\n","NOTEBOOK_DIR = Path.cwd()\n","REPO_ROOT = find_repo_root(NOTEBOOK_DIR)\n","CONFIG_PATH = REPO_ROOT / \"config.yaml\"\n","\n","if not CONFIG_PATH.exists():\n","    raise FileNotFoundError(f\"config.yaml not found at {CONFIG_PATH}\")\n","\n","with CONFIG_PATH.open(\"r\", encoding=\"utf-8\") as fh:\n","    cfg = yaml.safe_load(fh) or {}\n","\n","appliance_entries = cfg.get(\"appliances\") or []\n","if isinstance(appliance_entries, dict):\n","    appliance_entries = [appliance_entries]\n","\n","if not appliance_entries:\n","    fallback_target = cfg.get(\"target\")\n","    fallback_name = cfg.get(\"name\") or (fallback_target or \"default\")\n","    appliance_entries = [{\"name\": fallback_name, \"target\": fallback_target}]\n","\n","available_appliances: List[Dict[str, Any]] = []\n","for entry in appliance_entries:\n","    name = str(entry.get(\"name\") or \"\").strip()\n","    target = str(entry.get(\"target\") or \"\").strip()\n","    if not name:\n","        continue\n","    available_appliances.append({\"name\": name, \"target\": target or name})\n","\n","if not available_appliances:\n","    raise ValueError(\"No appliances with a name found in config.yaml\")\n","\n","exports_root = RAW_EXPORT_ROOT if RAW_EXPORT_ROOT.is_absolute() else (NOTEBOOK_DIR / RAW_EXPORT_ROOT).resolve()\n","if not exports_root.exists():\n","    raise FileNotFoundError(f\"Raw export root not found: {exports_root}\")\n","\n","include_set = {str(v).strip() for v in (INCLUDE_INSTANCES or []) if str(v).strip()}\n","exclude_set = {str(v).strip() for v in (EXCLUDE_INSTANCES or []) if str(v).strip()}\n","\n","available_dirs = {path.name: path for path in exports_root.iterdir() if path.is_dir()}\n","\n","selected_appliances: List[Dict[str, Any]] = []\n","skipped_missing: List[str] = []\n","skipped_filtered: List[str] = []\n","\n","for appliance in available_appliances:\n","    name = appliance[\"name\"]\n","    if include_set and name not in include_set:\n","        skipped_filtered.append(name)\n","        continue\n","    if name in exclude_set:\n","        skipped_filtered.append(name)\n","        continue\n","    export_dir = available_dirs.get(name)\n","    if not export_dir:\n","        skipped_missing.append(name)\n","        continue\n","    selected_appliances.append({\n","        \"name\": name,\n","        \"target\": appliance.get(\"target\") or name,\n","        \"export_dir\": export_dir,\n","    })\n","\n","print(f\"Repo root         : {REPO_ROOT}\")\n","print(f\"Config path       : {CONFIG_PATH}\")\n","print(f\"Exports root      : {exports_root}\")\n","print(f\"Config appliances : {[a['name'] for a in available_appliances]}\")\n","print(f\"Export directories: {sorted(available_dirs)}\")\n","print(f\"Selected          : {[a['name'] for a in selected_appliances]}\")\n","if skipped_missing:\n","    print(f\"Missing export dirs: {skipped_missing}\")\n","if skipped_filtered:\n","    print(f\"Skipped by filter  : {skipped_filtered}\")\n","\n","if not selected_appliances:\n","    raise RuntimeError(\"No appliances selected for processing â€“ check raw exports and filters.\")\n"]},{"cell_type":"code","execution_count":null,"id":"679ceb95","metadata":{"id":"helpers"},"outputs":[],"source":["METADATA_COLUMNS = [\"Appliance Target\", \"Appliance Name\", \"Query Title\"]\n","\n","OUTPOSTS_FILENAME = \"outposts_with_ips.csv\"\n","CREDENTIALS_FILENAME = \"session_outpost_credentials.csv\"\n","FALLBACK_CREDENTIALS_FILENAME = \"outpost_credentials.csv\"\n","\n","from pandas.errors import EmptyDataError\n","\n","\n","def load_csv(path: Path) -> pd.DataFrame:\n","    if not path.exists():\n","        print(f\"Missing CSV: {path}\")\n","        return pd.DataFrame()\n","    try:\n","        return pd.read_csv(path, low_memory=False)\n","    except EmptyDataError:\n","        print(f\"Empty CSV: {path}\")\n","        return pd.DataFrame()\n","\n","\n","def drop_metadata(df: pd.DataFrame) -> pd.DataFrame:\n","    return df.drop(columns=[c for c in METADATA_COLUMNS if c in df.columns], errors=\"ignore\")\n","\n","\n","def coerce_unique(df: pd.DataFrame, col: str) -> pd.DataFrame:\n","    if col in df.columns:\n","        series = df[col]\n","        try:\n","            df[col] = series.astype(str).str.strip()\n","        except Exception:\n","            df[col] = series.apply(lambda v: str(v).strip() if v is not None else None)\n","    return df\n"]},{"cell_type":"code","execution_count":null,"id":"5c6a8ebb","metadata":{"id":"processing"},"outputs":[],"source":["def build_output_dir(target: str) -> Path:\n","    sanitized = (target or \"unknown\").replace(\".\", \"_\").replace(\":\", \"_\").replace(\"/\", \"_\")\n","    if OUTPUT_BASE_DIR is None:\n","        return REPO_ROOT / f\"output_{sanitized}\"\n","    base_root = OUTPUT_BASE_DIR if isinstance(OUTPUT_BASE_DIR, Path) else Path(OUTPUT_BASE_DIR)\n","    return base_root.expanduser().resolve() / f\"output_{sanitized}\"\n","\n","\n","def load_outposts(export_dir: Path) -> pd.DataFrame:\n","    outposts = drop_metadata(load_csv(export_dir / OUTPOSTS_FILENAME))\n","    if outposts.empty and (export_dir / OUTPOSTS_FILENAME).exists():\n","        print(\"Outposts export present but empty.\")\n","    outposts = outposts.rename(columns={\n","        \"Outpost.id\": \"outpost_id\",\n","        \"Outpost.uuid\": \"outpost_uuid\",\n","        \"Outpost.name\": \"outpost_name\",\n","        \"Outpost.url\": \"outpost_url\",\n","    })\n","    if \"outpost_id\" not in outposts.columns and \"outpost_uuid\" in outposts.columns:\n","        outposts[\"outpost_id\"] = outposts[\"outpost_uuid\"]\n","    return outposts\n","\n","\n","def load_credential_map(export_dir: Path) -> pd.DataFrame:\n","    primary = drop_metadata(load_csv(export_dir / CREDENTIALS_FILENAME))\n","    if primary.empty:\n","        print(\"Primary session_outpost_credentials.csv empty or missing; falling back to outpost_credentials.csv\")\n","        primary = drop_metadata(load_csv(export_dir / FALLBACK_CREDENTIALS_FILENAME))\n","    rename_map = {\n","        \"Credential\": \"credential_uuid\",\n","        \"credential\": \"credential_uuid\",\n","        \"uuid\": \"credential_uuid\",\n","        \"Outpost\": \"outpost_id\",\n","        \"outpost\": \"outpost_id\",\n","        \"Outpost Id\": \"outpost_id\",\n","        \"outpost_id\": \"outpost_id\",\n","    }\n","    primary = primary.rename(columns=rename_map)\n","    if \"credential_uuid\" not in primary.columns:\n","        for candidate in [\"credential\", \"Credential\", \"uuid\"]:\n","            if candidate in primary.columns:\n","                primary[\"credential_uuid\"] = primary[candidate]\n","                break\n","    if \"outpost_id\" not in primary.columns:\n","        for candidate in [\"Outpost Id\", \"Outpost\", \"outpost\"]:\n","            if candidate in primary.columns:\n","                primary[\"outpost_id\"] = primary[candidate]\n","                break\n","    keep_cols = [c for c in [\"credential_uuid\", \"outpost_id\"] if c in primary.columns]\n","    if not keep_cols:\n","        return pd.DataFrame(columns=[\"credential_uuid\", \"outpost_id\"])\n","    primary = primary[keep_cols]\n","    primary = primary.replace({\"credential_uuid\": {\"None\": None, \"\": None}, \"outpost_id\": {\"None\": None, \"\": None}})\n","    subset_cols = [c for c in [\"credential_uuid\", \"outpost_id\"] if c in primary.columns]\n","    if subset_cols:\n","        primary = primary.dropna(subset=subset_cols, how=\"any\")\n","    primary = primary.drop_duplicates()\n","    if \"credential_uuid\" in primary.columns:\n","        primary = coerce_unique(primary, \"credential_uuid\")\n","    if \"outpost_id\" in primary.columns:\n","        primary = coerce_unique(primary, \"outpost_id\")\n","    return primary\n","\n","\n","def process_instance(instance: Dict[str, Any]) -> Dict[str, Any]:\n","    name = instance[\"name\"]\n","    target = instance.get(\"target\") or name\n","    export_dir: Path = instance[\"export_dir\"]\n","    print(f\"=== Processing {name} ({target}) ===\")\n","\n","    output_dir = build_output_dir(target)\n","    output_dir.mkdir(parents=True, exist_ok=True)\n","\n","    outposts = load_outposts(export_dir)\n","    creds_map = load_credential_map(export_dir)\n","\n","    if outposts.empty:\n","        print(\"No outposts found; writing empty output\")\n","    if creds_map.empty:\n","        print(\"No credential associations found.\")\n","\n","    if creds_map.empty:\n","        merged = pd.DataFrame(columns=[\"outpost_id\", \"credential_uuid\"])\n","    elif outposts.empty or \"outpost_id\" not in outposts.columns:\n","        merged = creds_map.copy()\n","        merged[\"outpost_id\"] = merged.get(\"outpost_id\")\n","    else:\n","        merge_key = \"outpost_id\" if \"outpost_id\" in outposts.columns else None\n","        if merge_key:\n","            merged = creds_map.merge(outposts, how=\"left\", left_on=\"outpost_id\", right_on=merge_key)\n","        else:\n","            merged = creds_map.copy()\n","\n","    merged = merged.rename(columns={\n","        \"outpost_url\": \"Outpost URL\",\n","        \"outpost_id\": \"Outpost Id\",\n","        \"outpost_name\": \"Outpost Name\",\n","        \"credential_uuid\": \"Credential UUID\",\n","    })\n","    output_cols = [\n","        \"Outpost URL\",\n","        \"Outpost Id\",\n","        \"Outpost Name\",\n","        \"Credential UUID\",\n","    ]\n","    for col in output_cols:\n","        if col not in merged.columns:\n","            merged[col] = None\n","\n","    df_out = merged[output_cols].drop_duplicates().reset_index(drop=True)\n","    df_out.insert(0, \"Discovery Instance\", target)\n","\n","    output_csv = output_dir / OUTPUT_FILENAME\n","    df_out.to_csv(output_csv, index=False)\n","\n","    print(f\"Output rows: {len(df_out)} | Saved to {output_csv}\")\n","    display(df_out.head(10))\n","\n","    return {\n","        \"instance\": name,\n","        \"target\": target,\n","        \"output_path\": output_csv,\n","        \"rows\": int(len(df_out)),\n","        \"status\": \"ok\",\n","    }\n"]},{"cell_type":"code","execution_count":null,"id":"d0fb03d1","metadata":{"id":"run_all"},"outputs":[],"source":["results: List[Dict[str, Any]] = []\n","for appliance in selected_appliances:\n","    outcome = process_instance(appliance)\n","    results.append(outcome)\n","\n","summary_df = pd.DataFrame(results)\n","if \"output_path\" in summary_df.columns:\n","    summary_df[\"output_path\"] = summary_df[\"output_path\"].map(lambda p: str(p) if p is not None else None)\n","display(summary_df)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":5}