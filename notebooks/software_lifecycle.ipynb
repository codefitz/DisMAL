{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-title",
   "metadata": {},
   "source": [
    "# Software Lifecycle Report (BMC Discovery)\n",
    "\n",
    "This notebook reproduces the DisMAL `software_lifecycle` (si_lifecycle) report using the Discovery Data API.\n",
    "It reads configuration from `../config.yaml`, executes the TWQL used by DisMAL,\n",
    "and writes a CSV to the same output structure as the CLI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requirements",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "We use `requests` for HTTP, `pandas` for tabular data, and `PyYAML` to read configuration.\n",
    "Uncomment the cell below to install them if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q requests pandas pyyaml\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from urllib.parse import urljoin\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "select-appliance",
   "metadata": {},
   "source": [
    "## Select Appliance (optional)\n",
    "\n",
    "If your `config.yaml` defines multiple appliances under the `appliances:` list,\n",
    "set `APPLIANCE_NAME` to one of their names or use the numeric index.\n",
    "Defaults to the first appliance if neither is set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appliance-vars",
   "metadata": {},
   "outputs": [],
   "source": [
    "APPLIANCE_NAME = None   # e.g., 'prod' or 'dev'\n",
    "APPLIANCE_INDEX = 1     # integer index if not using name selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-load",
   "metadata": {},
   "source": [
    "## Configuration (from config.yaml)\n",
    "\n",
    "Reads settings from `../config.yaml` including target, token/token_file,\n",
    "API version, and SSL verification preference.\n",
    "Saves the CSV to `../output_<target>/software_lifecycle.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robustly locate the project root (directory containing config.yaml)\n",
    "def _find_repo_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / 'config.yaml').exists():\n",
    "            return p\n",
    "    return start.parent\n",
    "\n",
    "repo_root = _find_repo_root(Path.cwd())\n",
    "config_path = repo_root / 'config.yaml'\n",
    "with open(config_path, 'r') as fh:\n",
    "    cfg = yaml.safe_load(fh) or {}\n",
    "\n",
    "apps = cfg.get('appliances') or []\n",
    "selected = None\n",
    "if isinstance(apps, list) and apps:\n",
    "    if APPLIANCE_NAME:\n",
    "        selected = next((a for a in apps if a.get('name') == APPLIANCE_NAME), None)\n",
    "        if selected is None:\n",
    "            raise ValueError(f\"No appliance named '{APPLIANCE_NAME}' in config.yaml\")\n",
    "    else:\n",
    "        try:\n",
    "            selected = apps[int(APPLIANCE_INDEX)]\n",
    "        except Exception:\n",
    "            selected = apps[0]\n",
    "\n",
    "target = ((selected or {}).get('target') or cfg.get('target') or '').strip()\n",
    "if not target:\n",
    "    raise ValueError('config.yaml missing \"target\"')\n",
    "BASE_URL = target if ('://' in target) else f'https://{target}'\n",
    "\n",
    "token = (((selected or {}).get('token') or cfg.get('token') or '').strip())\n",
    "token_file = (selected or {}).get('token_file') or cfg.get('token_file') or cfg.get('f_token')\n",
    "if not token and token_file:\n",
    "    tf_path = Path(token_file)\n",
    "    if not tf_path.is_absolute():\n",
    "        tf_path = repo_root / tf_path\n",
    "    with open(tf_path, 'r') as tf:\n",
    "        token = tf.read().strip()\n",
    "if not token:\n",
    "    raise ValueError('API token not found in config.yaml (token or token_file)')\n",
    "\n",
    "API_VERSION = str((selected or {}).get('api_version') or cfg.get('api_version') or 'v1.14')\n",
    "VERIFY_SSL = bool((selected or {}).get('verify_ssl', cfg.get('verify_ssl', True)))\n",
    "\n",
    "sanitized = target.replace('.', '_').replace(':', '_').replace('/', '_')\n",
    "output_dir = repo_root / f'output_{sanitized}'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Appliance     :', (selected or {}).get('name', '(single)'))\n",
    "print('Base URL      :', BASE_URL)\n",
    "print('API Version   :', API_VERSION)\n",
    "print('Verify SSL    :', VERIFY_SSL)\n",
    "print('Output folder :', output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "session-helpers",
   "metadata": {},
   "source": [
    "## Session and helpers\n",
    "\n",
    "Create a session with Authorization header and helpers to call the Data API.\n",
    "- `api_url(path)` builds endpoint URLs\n",
    "- `post_search(query, limit=0)` executes TWQL with pagination when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "session-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "auth_value = token if token.lower().startswith('bearer ') else f'Bearer {token}'\n",
    "session.headers.update({'Authorization': auth_value, 'Accept': 'application/json'})\n",
    "session.verify = VERIFY_SSL\n",
    "\n",
    "def api_url(path: str) -> str:\n",
    "    base = BASE_URL.rstrip('/') + f'/api/{API_VERSION}/'\n",
    "    return urljoin(base, path.lstrip('/'))\n",
    "\n",
    "def post_search(query: str, *, limit: int | None = None, page_size: int = 500):\n",
    "    url = api_url('data/search')\n",
    "    headings = None\n",
    "    results = []\n",
    "    offset = 0\n",
    "    fetch_all = (limit == 0)\n",
    "    while True:\n",
    "        payload = {'query': query, 'format': 'object'}\n",
    "        if fetch_all:\n",
    "            payload['limit'] = page_size\n",
    "            if offset:\n",
    "                payload['offset'] = offset\n",
    "        elif limit is not None:\n",
    "            payload['limit'] = limit\n",
    "        r = session.post(url, json=payload)\n",
    "        if r.status_code >= 400:\n",
    "            print(f'Error {r.status_code} POST {url}: {r.text[:200]}')\n",
    "            return {'headings': [], 'results': []}\n",
    "        try:\n",
    "            data = r.json()\n",
    "        except Exception:\n",
    "            data = []\n",
    "        # Find the table-like object with 'headings' and 'results'\n",
    "        table = None\n",
    "        if isinstance(data, list):\n",
    "            for x in data:\n",
    "                if isinstance(x, dict) and 'headings' in x and 'results' in x:\n",
    "                    table = x\n",
    "                    break\n",
    "        elif isinstance(data, dict) and 'headings' in data and 'results' in data:\n",
    "            table = data\n",
    "        if not table:\n",
    "            # Nothing usable returned\n",
    "            return {'headings': [], 'results': []}\n",
    "        if headings is None:\n",
    "            headings = table.get('headings', [])\n",
    "        page_rows = table.get('results') or []\n",
    "        results.extend(page_rows)\n",
    "        if not fetch_all or len(page_rows) < page_size:\n",
    "            break\n",
    "        offset += page_size\n",
    "    return {'headings': (headings or []), 'results': results}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twql",
   "metadata": {},
   "source": [
    "## TWQL for Software Lifecycle\n",
    "\n",
    "This query mirrors DisMALâ€™s `queries.software_lifecycle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "query-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry_software_lifecycle = '''\n",
    "search SoftwareInstance\n",
    "where\n",
    "#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.retirement_date\n",
    "    or #ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_support_date\n",
    "        or #ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_ext_support_date\n",
    "show\n",
    "type,\n",
    "product_version,\n",
    "(#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.retirement_date\n",
    "    and formatTime(#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.retirement_date, '%Y-%m-%d')) as 'End of Life',\n",
    "(#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_support_date\n",
    "    and formatTime(#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_support_date, '%Y-%m-%d')) as 'End of Support',\n",
    "(#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_ext_support_date\n",
    "    and formatTime(#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_ext_support_date, '%Y-%m-%d')) as 'End of Ext Support',\n",
    "(#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_ext_support_date\n",
    "    and (#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_ext_support_date < currentTime()\n",
    "    and 'EOES Exceeded')\n",
    "    or #ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_support_date\n",
    "        and (#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_support_date < currentTime()\n",
    "        and 'EOS Exceeded')\n",
    "        or #ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.retirement_date\n",
    "            and (#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.retirement_date < currentTime()\n",
    "            and 'EOL Exceeded')\n",
    "            or (#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.retirement_date\n",
    "                and (#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.retirement_date < currentTime() + 182 * 864000000000\n",
    "                and 'EOL less than 6 months away')\n",
    "                or #ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_support_date\n",
    "                    and (#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_support_date < currentTime() + 182 * 864000000000\n",
    "                    and 'EOS less than 6 months away')\n",
    "                    or #ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_ext_support_date\n",
    "                        and (#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_ext_support_date < currentTime() + 182 * 864000000000\n",
    "                        and 'EOES less than 6 months away'))\n",
    "                        or (#ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.retirement_date\n",
    "                            and 'EOL more than 6 months away'\n",
    "                            or #ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_support_date\n",
    "                                and 'EOS more than 6 months away'\n",
    "                                or #ElementWithDetail:SupportDetail:SoftwareDetail:SupportDetail.end_ext_support_date\n",
    "                                    and 'EOES more than 6 months away')) as 'Lifecycle Risk'\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exec",
   "metadata": {},
   "source": [
    "## Execute query and load into pandas\n",
    "\n",
    "We request all rows (limit=0) with pagination and build a DataFrame.\n",
    "Columns are ordered to match DisMALâ€™s CSV header behavior, with 'Discovery Instance' inserted as the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exec-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = post_search(qry_software_lifecycle, limit=0)\n",
    "headings = res.get('headings', []) if isinstance(res, dict) else []\n",
    "rows = res.get('results', []) if isinstance(res, dict) else []\n",
    "df = pd.DataFrame(rows, columns=headings) if rows else pd.DataFrame()\n",
    "display(df.head(10)) if not df.empty else print('No rows returned')\n",
    "\n",
    "if not df.empty:\n",
    "    df.insert(0, 'Discovery Instance', target)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save",
   "metadata": {},
   "source": [
    "## Save to CSV\n",
    "\n",
    "Writes the CSV to the standard CLI output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CSV = str(output_dir / 'software_lifecycle.csv')\n",
    "if not df.empty:\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(f'Saved to {OUTPUT_CSV}')\n",
    "else:\n",
    "    # Create empty with headers for consistency\n",
    "    pd.DataFrame(columns=['Discovery Instance'] + list(headings)).to_csv(OUTPUT_CSV, index=False)\n",
    "    print(f'No data; created empty file at {OUTPUT_CSV}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "footer-empty",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
